<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Rishijeet Mishra]]></title>
  <link href="https://rishijeet.github.io/atom.xml" rel="self"/>
  <link href="https://rishijeet.github.io/"/>
  <updated>2024-07-03T10:56:57+05:30</updated>
  <id>https://rishijeet.github.io/</id>
  <author>
    <name><![CDATA[Rishijeet Mishra]]></name>
    <email><![CDATA[rishijeet@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Role of GPUs in Large Language Models (LLMs): Types, Requirements & Costs]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/the-role-of-gpus-in-large-language-models-llms/"/>
    <updated>2024-07-03T10:32:17+05:30</updated>
    <id>https://rishijeet.github.io/blog/the-role-of-gpus-in-large-language-models-llms</id>
    <content type="html"><![CDATA[<p>Large Language Models (LLMs) like GPT-3, BERT, and T5 have revolutionized natural language processing (NLP). However, training and fine-tuning these models require substantial computational resources. Graphics Processing Units (GPUs) are critical in this context, providing the necessary power to handle the vast amounts of data and complex calculations involved. In this blog, we will explore why GPUs are essential for LLMs, the types of GPUs required, and the associated costs.</p>

<p><img src="https://rishijeet.github.io/images/2024/nvidia_a100.jpg" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Why-GPUs-are-Essential-for-LLMs"></a>
<h3>Why GPUs are Essential for LLMs</h3>

<ul>
<li> <strong>Parallel Processing</strong>

<ul>
<li>GPUs excel at parallel processing, allowing them to handle multiple computations simultaneously. This capability is
crucial for training LLMs, which involve large-scale matrix multiplications and operations on high-dimensional tensors.</li>
</ul>
</li>
<li> <strong>High Throughput</strong>

<ul>
<li>GPUs offer high computational throughput, significantly speeding up the training process. This is vital for LLMs,
which require processing vast datasets and performing numerous iterations to achieve optimal performance.</li>
</ul>
</li>
<li> <strong>Memory Bandwidth</strong>

<ul>
<li>Training LLMs involves frequent data transfer between the processor and memory. GPUs provide high memory bandwidth,
facilitating the rapid movement of large amounts of data, which is essential for efficient training.</li>
</ul>
</li>
<li> <strong>Optimized Libraries</strong>

<ul>
<li>Many deep learning frameworks (e.g., TensorFlow, PyTorch) offer GPU-optimized libraries, enabling efficient
implementation of complex neural network operations and reducing training time.</li>
</ul>
</li>
</ul>


<!--more-->


<p><img src="https://rishijeet.github.io/images/2024/nvidia_time_sol.svg" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Types-of-GPUs-Required-for-LLMs"></a>
<h3>Types of GPUs Required for LLMs</h3>

<p>Different LLM tasks have varying computational requirements, and the choice of GPU depends on the model size, dataset size, and specific application. Here are some common GPU types used for LLMs:</p>

<p><strong>NVIDIA A100:</strong></p>

<ul>
<li><strong>Overview:</strong> The NVIDIA A100 is designed for high-performance computing and AI workloads. It is based on the Ampere architecture and offers exceptional performance for training and inference of LLMs.</li>
<li><strong>Key Features:</strong>

<ul>
<li>6912 CUDA cores</li>
<li>40 GB or 80 GB HBM2 memory</li>
<li>Up to 1.6 TB/s memory bandwidth</li>
<li>Multi-instance GPU (MIG) technology for partitioning into smaller, independent GPUs</li>
</ul>
</li>
<li><strong>Cost:</strong> Approximately $10,000 - $15,000 per GPU</li>
</ul>


<p><strong>NVIDIA V100:</strong></p>

<ul>
<li><strong>Overview:</strong> The NVIDIA V100, based on the Volta architecture, is a widely used GPU for deep learning and AI. It
provides excellent performance for training large-scale models.</li>
<li><strong>Key Features:</strong>

<ul>
<li>5120 CUDA cores</li>
<li>16 GB or 32 GB HBM2 memory</li>
<li>Up to 900 GB/s memory bandwidth</li>
<li>Tensor Cores for accelerating matrix operations</li>
</ul>
</li>
<li><strong>Cost:</strong> Approximately $8,000 - $12,000 per GPU</li>
</ul>


<p><strong>NVIDIA T4:</strong></p>

<ul>
<li><strong>Overview:</strong> The NVIDIA T4 is optimized for inference and low-power applications. It offers a good balance of
performance and cost, making it suitable for deploying LLMs.</li>
<li><strong>Key Features:</strong>

<ul>
<li>2560 CUDA cores</li>
<li>16 GB GDDR6 memory</li>
<li>Up to 320 GB/s memory bandwidth</li>
<li>Low power consumption (70W)</li>
</ul>
</li>
<li><strong>Cost:</strong> Approximately $2,000 - $3,000 per GPU</li>
</ul>


<p><strong>NVIDIA RTX 3090:</strong></p>

<ul>
<li><strong>Overview:</strong> The NVIDIA RTX 3090 is a consumer-grade GPU that provides high performance for deep learning tasks.
It is based on the Ampere architecture and is popular among researchers and enthusiasts.</li>
<li><strong>Key Features:</strong>

<ul>
<li>10496 CUDA cores</li>
<li>24 GB GDDR6X memory</li>
<li>Up to 936 GB/s memory bandwidth</li>
</ul>
</li>
<li><strong>Cost:</strong> Approximately $1,500 - $2,500 per GPU</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2024/nvidia_perf.svg" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Cost-Considerations"></a>
<h3>Cost Considerations</h3>

<p>The cost of GPUs varies based on their performance, memory capacity, and features. Here are some factors to consider when budgeting for GPUs in LLM projects:</p>

<p><strong>Performance Needs:</strong></p>

<ul>
<li>Higher-end GPUs like the NVIDIA A100 and V100 are suitable for large-scale training but come at a higher cost.
For smaller tasks or inference, more affordable options like the T4 or RTX 3090 might suffice.</li>
</ul>


<p><strong>Scalability:</strong></p>

<ul>
<li>Consider the scalability of your setup. If you plan to scale up your operations, investing in higher-end GPUs
might provide better long-term value due to their superior performance and efficiency.</li>
</ul>


<p><strong>Cloud vs. On-Premise:</strong></p>

<ul>
<li>Cloud providers (e.g., AWS, Google Cloud, Azure) offer GPU instances, allowing you to pay for usage rather than
upfront costs. This can be cost-effective for short-term projects or when starting.</li>
</ul>


<p><strong>Total Cost of Ownership:</strong></p>

<ul>
<li>Factor in additional costs such as electricity, cooling, and maintenance when running GPUs on-premise. These
operational costs can add up, especially for high-power GPUs.</li>
</ul>


<p>While NVIDIA is the dominant player in the GPU market, there are indeed other companies that produce GPUs. However, NVIDIA&rsquo;s significant presence in the deep learning and AI sectors often overshadows these competitors. Let&rsquo;s explore some of these companies, their offerings, and why they are less frequently discussed in the context of LLMs.</p>

<a name="Other-GPU-Manufacturers"></a>
<h3>Other GPU Manufacturers</h3>

<p><strong>AMD (Advanced Micro Devices):</strong></p>

<ul>
<li><strong>Overview:</strong> AMD is a well-known player in the GPU market, offering both consumer and professional-grade GPUs
under the Radeon and Radeon Pro brands.</li>
<li><strong>Key Products:</strong>

<ul>
<li><strong>Radeon RX Series:</strong> Consumer GPUs aimed at gaming but also used for deep learning tasks.</li>
<li><strong>Radeon Pro Series:</strong> Professional GPUs designed for content creation, CAD, and scientific computing.</li>
</ul>
</li>
<li><strong>Why Less Prominent for LLMs:</strong> AMD GPUs are generally not as optimized for deep learning frameworks as NVIDIA&rsquo;s.
CUDA, NVIDIA&rsquo;s parallel computing platform, is widely supported and has become the industry standard, giving NVIDIA an edge in the AI space.</li>
</ul>


<p><strong>Intel:</strong></p>

<ul>
<li><strong>Overview:</strong> Intel, primarily known for its CPUs, has also ventured into the GPU market with its Xe graphics
architecture.</li>
<li><strong>Key Products:</strong>

<ul>
<li><strong>Intel Iris Xe:</strong> Integrated and discrete GPUs aimed at mainstream computing tasks.</li>
<li><strong>Intel Xeon Phi:</strong> Co-processors designed for high-performance computing tasks, including AI and machine learning.</li>
</ul>
</li>
<li><strong>Why Less Prominent for LLMs:</strong> Intel&rsquo;s GPUs are relatively new entrants to the market and lack the extensive ecosystem and software support that NVIDIA GPUs enjoy. Additionally, Intel&rsquo;s focus has traditionally been on CPUs, making their GPUs less prominent in the AI and deep learning communities.</li>
</ul>


<p><strong>Google (TPUs - Tensor Processing Units):</strong></p>

<ul>
<li><strong>Overview:</strong> Google developed TPUs specifically for accelerating machine learning workloads. These are not
traditional GPUs but are worth mentioning due to their specialized role in AI.</li>
<li><strong>Key Products:</strong>

<ul>
<li><strong>TPU v4:</strong> The latest generation of TPUs, designed for both training and inference of large models.</li>
</ul>
</li>
<li><strong>Why Less Prominent for General Use:</strong> TPUs are primarily available through Google Cloud and are tailored for Google&rsquo;s ecosystem. They are not as widely accessible as NVIDIA GPUs for general-purpose deep learning tasks.</li>
</ul>


<p><strong>Huawei (Ascend):</strong></p>

<ul>
<li><strong>Overview:</strong> Huawei produces AI processors under the Ascend brand, designed for deep learning and AI workloads.</li>
<li><strong>Key Products:</strong>

<ul>
<li><strong>Ascend 910:</strong> A high-performance AI processor aimed at training large models.</li>
</ul>
</li>
<li><strong>Why Less Prominent:</strong> Huawei&rsquo;s market presence is more regional, and their products are not as widely adopted globally compared to NVIDIA&rsquo;s offerings.</li>
</ul>


<a name="Why-NVIDIA-Dominates-the-LLM-Space"></a>
<h3>Why NVIDIA Dominates the LLM Space</h3>

<p><strong>CUDA Ecosystem:</strong></p>

<ul>
<li><strong>Software Support:</strong> CUDA has become the de facto standard for parallel computing in deep learning. Most deep
learning frameworks, such as TensorFlow and PyTorch, are highly optimized for CUDA.</li>
<li><strong>Libraries and Tools:</strong> NVIDIA provides a rich set of libraries (cuDNN, NCCL, TensorRT) and tools that simplify the development and deployment of deep learning models.</li>
</ul>


<p><strong>Performance:</strong></p>

<ul>
<li><strong>Specialized Hardware:</strong> NVIDIA&rsquo;s GPUs are equipped with Tensor Cores specifically designed for accelerating
deep learning tasks, providing superior performance for training large models.</li>
<li><strong>Scalability:</strong> NVIDIA&rsquo;s NVLink and multi-GPU setups enable efficient scaling of deep learning workloads, essential for training LLMs.</li>
</ul>


<p><strong>Industry Adoption:</strong></p>

<ul>
<li><strong>Research and Development:</strong> Many leading research institutions and tech companies use NVIDIA GPUs, resulting in
a wealth of community knowledge, tutorials, and research papers centered around NVIDIA hardware.</li>
<li><strong>Cloud Integration:</strong> Major cloud providers (AWS, Google Cloud, Azure) offer extensive support for NVIDIA GPUs, making them accessible for scalable deep learning applications.</li>
</ul>


<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>GPUs are indispensable for training and fine-tuning Large Language Models due to their parallel processing capabilities, high throughput, and optimized performance for deep learning tasks. Selecting the right GPU involves balancing performance needs, budget constraints, and scalability requirements. High-end GPUs like the NVIDIA A100 and V100 are ideal for large-scale training, while more affordable options like the T4 and RTX 3090 are suitable for smaller tasks and inference.</p>

<p>By understanding the different types of GPUs and their costs, you can make informed decisions that align with your LLM project goals, ensuring efficient and cost-effective model development and deployment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Types of Large Language Models (LLMs)]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/understanding-types-of-large-language-models-llms/"/>
    <updated>2024-07-03T10:13:27+05:30</updated>
    <id>https://rishijeet.github.io/blog/understanding-types-of-large-language-models-llms</id>
    <content type="html"><![CDATA[<p>Large Language Models (LLMs) have revolutionized the field of natural language processing (NLP) with their ability to understand, generate, and interact with human language. These models are built using deep learning techniques and have been trained on vast amounts of text data. In this blog, we will explore the different types of LLMs, their architectures, and their applications.</p>

<a name="L-3c-strong-3e-Generative-Pre-2d-trained-Transformers--28-GPT-29--3c--2f-strong-3e-"></a>
<h3><strong>Generative Pre-trained Transformers (GPT)</strong></h3>

<a name="Overview"></a>
<h4>Overview</h4>

<p>GPT models, developed by OpenAI, are among the most popular LLMs. They use a transformer-based architecture and are designed to generate human-like text. The models are pre-trained on a large corpus of text and then fine-tuned for specific tasks.</p>

<p><img src="https://rishijeet.github.io/images/2024/gpt.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Key-Features"></a>
<h4>Key Features</h4>

<ul>
<li><strong>Transformer Architecture:</strong> Utilizes self-attention mechanisms to process input text efficiently.</li>
<li><strong>Pre-training and Fine-tuning:</strong> Initially pre-trained on diverse text data and then fine-tuned for specific tasks like language translation, summarization, and question answering.</li>
<li><strong>Generative Capabilities:</strong> Can generate coherent and contextually relevant text based on a given prompt.</li>
</ul>


<!--more-->


<a name="Applications"></a>
<h4>Applications</h4>

<ul>
<li>Chatbots and virtual assistants</li>
<li>Text completion and generation</li>
<li>Content creation</li>
</ul>


<a name="L-3c-strong-3e-Bidirectional-Encoder-Representations-from-Transformers--28-BERT-29--3c--2f-strong-3e-"></a>
<h3><strong>Bidirectional Encoder Representations from Transformers (BERT)</strong></h3>

<a name="Overview"></a>
<h4>Overview</h4>

<p>BERT, developed by Google, is designed for understanding the context of words in a sentence. Unlike GPT, which generates text, BERT excels at tasks requiring a deep understanding of text, such as question answering and sentiment analysis.</p>

<p><img src="https://rishijeet.github.io/images/2024/bert.jpg" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Key-Features"></a>
<h4>Key Features</h4>

<ul>
<li><strong>Bidirectional Training:</strong> BERT reads text in both directions (left-to-right and right-to-left) to capture context more effectively.</li>
<li><strong>Masked Language Modeling (MLM):</strong> Trained by predicting masked words in a sentence, enabling it to understand the context of each word.</li>
<li><strong>Next Sentence Prediction (NSP):</strong> Helps the model understand the relationship between sentences.</li>
</ul>


<a name="Applications"></a>
<h4>Applications</h4>

<ul>
<li>Question answering systems</li>
<li>Sentiment analysis</li>
<li>Text classification</li>
</ul>


<a name="L-3c-strong-3e-T5--28-Text-2d-to-2d-Text-Transfer-Transformer-29--3c--2f-strong-3e-"></a>
<h3><strong>T5 (Text-to-Text Transfer Transformer)</strong></h3>

<a name="Overview"></a>
<h4>Overview</h4>

<p>T5, also developed by Google, treats every NLP task as a text-to-text problem. This means both the input and the output are text strings, making it highly versatile for various tasks.</p>

<p><img src="https://rishijeet.github.io/images/2024/t5.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Key-Features"></a>
<h4>Key Features</h4>

<ul>
<li><strong>Unified Framework:</strong> Simplifies the model by converting all tasks into a text-to-text format.</li>
<li><strong>Pre-training on Diverse Tasks:</strong> Pre-trained on a mixture of unsupervised and supervised tasks, enabling it to generalize well.</li>
<li><strong>Flexibility:</strong> Can be fine-tuned for a wide range of tasks such as translation, summarization, and classification.</li>
</ul>


<a name="Applications"></a>
<h4>Applications</h4>

<ul>
<li>Machine translation</li>
<li>Text summarization</li>
<li>Sentence paraphrasing</li>
</ul>


<a name="L-3c-strong-3e-XLNet-3c--2f-strong-3e-"></a>
<h3><strong>XLNet</strong></h3>

<a name="Overview"></a>
<h4>Overview</h4>

<p>XLNet, developed by Google and Carnegie Mellon University, aims to improve upon BERT by addressing its limitations. It uses a permutation-based training method to capture bidirectional context without masking.</p>

<p><img src="https://rishijeet.github.io/images/2024/xlnet.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Key-Features"></a>
<h4>Key Features</h4>

<ul>
<li><strong>Permutation Language Modeling:</strong> Instead of masking, XLNet predicts all tokens in a sentence in random order, preserving context for each word.</li>
<li><strong>Autoregressive Method:</strong> Combines the strengths of autoregressive models (like GPT) with bidirectional context.</li>
<li><strong>Improved Performance:</strong> Outperforms BERT on several NLP benchmarks.</li>
</ul>


<a name="Applications"></a>
<h4>Applications</h4>

<ul>
<li>Reading comprehension</li>
<li>Text classification</li>
<li>Sentence completion</li>
</ul>


<a name="L-3c-strong-3e-Robustly-Optimized-BERT-Pretraining-Approach--28-RoBERTa-29--3c--2f-strong-3e-"></a>
<h3><strong>Robustly Optimized BERT Pretraining Approach (RoBERTa)</strong></h3>

<a name="Overview"></a>
<h4>Overview</h4>

<p>RoBERTa, developed by Facebook AI, is an optimized version of BERT. It focuses on improving BERT&rsquo;s performance by making changes to the training procedure.</p>

<p><img src="https://rishijeet.github.io/images/2024/roberta.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Key-Features"></a>
<h4>Key Features</h4>

<ul>
<li><strong>Larger Training Data:</strong> Trained on more data and for longer periods compared to BERT.</li>
<li><strong>Dynamic Masking:</strong> Uses a different masking pattern for each epoch during training.</li>
<li><strong>No NSP Task:</strong> Removes the next sentence prediction task, focusing solely on masked language modeling.</li>
</ul>


<a name="Applications"></a>
<h4>Applications</h4>

<ul>
<li>Sentiment analysis</li>
<li>Named entity recognition</li>
<li>Text classification</li>
</ul>


<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>Large Language Models have significantly advanced the field of NLP, offering powerful tools for understanding and generating human language. Each type of LLM has its strengths and is suited for different applications. As these models continue to evolve, they promise to unlock new possibilities in various domains, from enhancing virtual assistants to enabling more sophisticated language understanding systems.</p>

<p>Understanding the differences between these models helps in selecting the right tool for specific tasks and leveraging their full potential. Whether it&rsquo;s the generative prowess of GPT, the contextual understanding of BERT, or the versatility of T5, LLMs are reshaping how we interact with and utilize language in the digital age.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advanced Apache Kafka Anatomy: Delving Deep into the Core Components]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/advanced-apache-kafka-anatomy-delving-deep-into-the-core-components/"/>
    <updated>2024-06-27T09:55:12+05:30</updated>
    <id>https://rishijeet.github.io/blog/advanced-apache-kafka-anatomy-delving-deep-into-the-core-components</id>
    <content type="html"><![CDATA[<p>Apache Kafka has become a cornerstone of modern data architectures, renowned for its ability to handle high-throughput, low-latency data streams. While its fundamental concepts are widely understood, a deeper dive into Kafka’s advanced components and features reveals the true power and flexibility of this distributed event streaming platform. This blog aims to unravel the advanced anatomy of Apache Kafka, offering insights into its core components, configurations, and best practices for optimizing performance.</p>

<a name="Core-Components-of-Kafka"></a>
<h2>Core Components of Kafka</h2>

<a name="Brokers"></a>
<h3>Brokers</h3>

<p><strong>Brokers</strong> are the backbone of a Kafka cluster, responsible for managing data storage, processing requests from clients, and replicating data to ensure fault tolerance.</p>

<p><img src="https://rishijeet.github.io/images/2024/kafka_broker.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>Leader and Follower Roles</strong>: Each topic partition has a leader broker that handles all read and write requests for that partition, while follower brokers replicate the leader’s data to ensure high availability.</li>
<li><strong>Scalability</strong>: Kafka’s design allows for easy scaling by adding more brokers to distribute the load and improve throughput.</li>
</ul>


<a name="Topics-and-Partitions"></a>
<h3>Topics and Partitions</h3>

<p><strong>Topics</strong> are categories to which records are published. Each topic can be divided into multiple partitions, which are the basic unit of parallelism and scalability in Kafka.</p>

<ul>
<li><strong>Partitioning Strategy</strong>: Proper partitioning is crucial for load balancing and ensuring efficient data distribution across the cluster. Common strategies include key-based partitioning and round-robin distribution.</li>
<li><strong>Replication</strong>: Partitions can be replicated across multiple brokers to provide redundancy and high availability. The replication factor determines the number of copies of a partition in the cluster.</li>
</ul>


<!--more-->


<a name="Producers"></a>
<h3>Producers</h3>

<p><strong>Producers</strong> are responsible for publishing records to Kafka topics.</p>

<p><img src="https://rishijeet.github.io/images/2024/kafka_producers.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>Acknowledgments</strong>: Configurable acknowledgment settings (<code>acks</code>) determine how many broker acknowledgments the producer requires before considering a request complete (<code>acks=0</code>, <code>acks=1</code>, or <code>acks=all</code>).</li>
<li><strong>Batching and Compression</strong>: Producers can batch multiple records into a single request to improve throughput and enable data compression to reduce the size of the data being transferred.</li>
</ul>


<a name="Consumers"></a>
<h3>Consumers</h3>

<p><strong>Consumers</strong> subscribe to topics and process the records published to them.</p>

<ul>
<li><strong>Consumer Groups</strong>: Consumers operate as part of a group, where each consumer in a group reads from a unique set of partitions. This allows for parallel processing and ensures that records are processed by a single consumer.</li>
<li><strong>Offset Management</strong>: Consumers track their position in each partition by maintaining offsets, which can be automatically committed at intervals or manually managed for precise control over record processing.</li>
</ul>


<a name="ZooKeeper"></a>
<h3>ZooKeeper</h3>

<p><strong>ZooKeeper</strong> is a critical component in Kafka&rsquo;s ecosystem, used for cluster coordination and configuration management.</p>

<ul>
<li><strong>Leader Election</strong>: ZooKeeper helps manage the leader election process for partition leaders and the Kafka controller.</li>
<li><strong>Metadata Storage</strong>: Stores metadata about the Kafka cluster, including broker information, topic configurations, and access control lists.</li>
</ul>


<a name="Advanced-Kafka-Features"></a>
<h2>Advanced Kafka Features</h2>

<a name="Kafka-Connect"></a>
<h3>Kafka Connect</h3>

<p><strong>Kafka Connect</strong> is a robust framework for integrating Kafka with external systems.</p>

<p><img src="https://rishijeet.github.io/images/2024/kafka_connect.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>Source Connectors</strong>: Import data from external systems (e.g., databases, file systems) into Kafka topics.</li>
<li><strong>Sink Connectors</strong>: Export data from Kafka topics to external systems (e.g., databases, data lakes).</li>
</ul>


<a name="Kafka-Streams"></a>
<h3>Kafka Streams</h3>

<p><strong>Kafka Streams</strong> is a powerful library for building stream processing applications on top of Kafka.</p>

<p><img src="https://rishijeet.github.io/images/2024/kafka_streams.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>KStream and KTable</strong>: Core abstractions for modeling streams of records and tables of changelog records, respectively.</li>
<li><strong>Stateful Processing</strong>: Enables operations like joins, aggregations, and windowing, with support for local state stores and fault-tolerant state management.</li>
</ul>


<a name="Schema-Registry"></a>
<h3>Schema Registry</h3>

<p><strong>Schema Registry</strong> is a centralized service for managing and validating schemas used by Kafka producers and consumers.</p>

<p><img src="https://rishijeet.github.io/images/2024/schema-registry-and-kafka.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>Avro, JSON, and Protobuf</strong>: Supports multiple schema formats, ensuring data consistency and compatibility across different applications.</li>
<li><strong>Schema Evolution</strong>: Facilitates schema versioning and evolution, allowing for backward and forward compatibility.</li>
</ul>


<a name="Best-Practices-for-Kafka-Performance-Optimization"></a>
<h2>Best Practices for Kafka Performance Optimization</h2>

<a name="Configuring-Brokers"></a>
<h3>Configuring Brokers</h3>

<ul>
<li><strong>Heap Size</strong>: Set an appropriate heap size for Kafka brokers to prevent memory issues. Typically, 4-8 GB is recommended.</li>
<li><strong>Log Retention</strong>: Configure log retention policies (<code>log.retention.hours</code>, <code>log.retention.bytes</code>) to manage disk usage and comply with data retention requirements.</li>
</ul>


<a name="Optimizing-Producers"></a>
<h3>Optimizing Producers</h3>

<ul>
<li><strong>Batch Size and Linger</strong>: Adjust <code>batch.size</code> and <code>linger.ms</code> to balance latency and throughput. Larger batch sizes and longer linger times can improve throughput at the cost of increased latency.</li>
<li><strong>Compression Type</strong>: Enable compression (<code>compression.type</code>) to reduce network bandwidth usage. Common options include <code>gzip</code>, <code>snappy</code>, and <code>lz4</code>.</li>
</ul>


<a name="Tuning-Consumers"></a>
<h3>Tuning Consumers</h3>

<ul>
<li><strong>Fetch Size</strong>: Configure <code>fetch.min.bytes</code> and <code>fetch.max.wait.ms</code> to control the amount of data fetched in each request and the maximum wait time, balancing latency and throughput.</li>
<li><strong>Offset Commit Frequency</strong>: Adjust <code>auto.commit.interval.ms</code> for automatic offset commits or implement manual offset management for finer control over record processing.</li>
</ul>


<a name="Ensuring-High-Availability"></a>
<h3>Ensuring High Availability</h3>

<ul>
<li><strong>Replication Factor</strong>: Set an appropriate replication factor for topics to ensure data redundancy and fault tolerance. A replication factor of 3 is common in production environments.</li>
<li><strong>ISR (In-Sync Replicas)</strong>: Monitor the number of in-sync replicas (<code>min.insync.replicas</code>) to ensure that there are enough replicas to maintain data consistency and durability.</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Apache Kafka’s advanced anatomy reveals a powerful and flexible system capable of handling the most demanding data streaming requirements. By understanding its core components, leveraging advanced features like Kafka Connect and Kafka Streams, and adhering to best practices for performance optimization, you can harness the full potential of Kafka in your data architecture. Whether you’re building real-time analytics, event-driven microservices, or data integration pipelines, Kafka provides the foundation for scalable, resilient, and high-performance data streaming solutions.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Exploring gRPC: The Next Generation of Remote Procedure Calls]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/exploring-grpc-the-next-generation-of-remote-procedure-calls/"/>
    <updated>2024-06-26T09:54:48+05:30</updated>
    <id>https://rishijeet.github.io/blog/exploring-grpc-the-next-generation-of-remote-procedure-calls</id>
    <content type="html"><![CDATA[<p>In the realm of distributed systems and microservices, effective communication between services is paramount. For many years, REST (Representational State Transfer) has been the dominant paradigm for building APIs. However, gRPC (gRPC Remote Procedure Calls) is emerging as a powerful alternative, offering several advantages over traditional REST APIs. In this blog, we&rsquo;ll explore what gRPC is, how it works, and why it might be a better choice than REST for certain applications.</p>

<a name="What-is-gRPC-3f-"></a>
<h2>What is gRPC?</h2>

<p>gRPC, originally developed by Google, is an open-source framework that enables high-performance remote procedure calls (RPC). It leverages HTTP/2 for transport, Protocol Buffers (Protobuf) as the interface definition language (IDL), and provides features like bi-directional streaming, authentication, and load balancing out-of-the-box.</p>

<p><img src="https://rishijeet.github.io/images/2024/grpc.png" height="300" width="900" alt="Alt text" /><em>Source: gRPC</em></p>

<a name="Key-Components-of-gRPC"></a>
<h3>Key Components of gRPC</h3>

<ul>
<li><strong>Protocol Buffers (Protobuf)</strong>: A language-neutral, platform-neutral, extensible mechanism for serializing
structured data. It serves as both the IDL and the message format.</li>
<li><strong>HTTP/2</strong>: The transport protocol used by gRPC, which provides benefits like multiplexing, flow control, header
compression, and low-latency communication.</li>
<li><strong>Stub</strong>: Generated client code that provides the same methods as the server, making remote calls appear as local
method calls.</li>
</ul>


<a name="How-gRPC-Works"></a>
<h3>How gRPC Works</h3>

<ul>
<li><strong>Define the Service</strong>: Use Protobuf to define the service and its methods, along with the request and response
message types.</li>
<li><strong>Generate Code</strong>: Use the Protobuf compiler to generate client and server code in your preferred programming
languages.</li>
<li><strong>Implement the Service</strong>: Write the server-side logic to handle the defined methods.</li>
<li><strong>Call the Service</strong>: Use the generated client code to call the methods on the server as if they were local functions.</li>
</ul>


<!--more-->


<a name="Example-Protobuf-Definition"></a>
<h3>Example Protobuf Definition</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='protobuf'><span class='line'><span class="na">syntax</span> <span class="o">=</span> <span class="s">&quot;proto3&quot;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">service</span> <span class="n">Greeter</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">rpc</span> <span class="n">SayHello</span> <span class="p">(</span><span class="n">HelloRequest</span><span class="p">)</span> <span class="k">returns</span> <span class="p">(</span><span class="n">HelloReply</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kd">message</span> <span class="nc">HelloRequest</span> <span class="p">{</span>
</span><span class='line'>  <span class="kt">string</span> <span class="na">name</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kd">message</span> <span class="nc">HelloReply</span> <span class="p">{</span>
</span><span class='line'>  <span class="kt">string</span> <span class="kd">message</span> <span class="err">= 1;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Why-gRPC-is-Better-Than-REST"></a>
<h2>Why gRPC is Better Than REST</h2>

<a name="Performance"></a>
<h3>Performance</h3>

<ul>
<li><strong>HTTP/2 Benefits</strong>: gRPC uses HTTP/2, which supports multiplexing (multiple requests over a single connection), header compression, and server push, leading to more efficient use of network resources and lower latency compared to HTTP/1.1 used by REST.</li>
<li><strong>Binary Protocol</strong>: Protobuf is a binary format, making it more compact and faster to serialize/deserialize than JSON, which is text-based.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2024/grpc_rest.png" height="300" width="900" alt="Alt text" /><em>Source: Refine</em></p>

<a name="Strongly-Typed-Contracts"></a>
<h3>Strongly Typed Contracts</h3>

<ul>
<li><strong>Protobuf IDL</strong>: The use of Protobuf enforces a strict contract between the client and server, reducing the chances of runtime errors due to type mismatches and ensuring that APIs are well-documented and versioned.</li>
</ul>


<a name="Bi-2d-Directional-Streaming"></a>
<h3>Bi-Directional Streaming</h3>

<ul>
<li><strong>Streaming Support</strong>: gRPC natively supports various types of streaming:

<ul>
<li><strong>Unary RPC</strong>: Single request, single response.</li>
<li><strong>Server Streaming RPC</strong>: Single request, multiple responses.</li>
<li><strong>Client Streaming RPC</strong>: Multiple requests, single response.</li>
<li><strong>Bi-Directional Streaming RPC</strong>: Multiple requests and responses, allowing for real-time, duplex communication.</li>
</ul>
</li>
</ul>


<a name="Code-Generation"></a>
<h3>Code Generation</h3>

<ul>
<li><strong>Automated Stub Generation</strong>: The Protobuf compiler generates client and server code, reducing boilerplate and ensuring consistency between client and server implementations. This accelerates development and minimizes human error.</li>
</ul>


<a name="Built-2d-In-Features"></a>
<h3>Built-In Features</h3>

<ul>
<li><strong>Authentication and Security</strong>: gRPC supports authentication, load balancing, retries, and more out-of-the-box, providing robust tools for building secure and resilient services.</li>
<li><strong>Interoperability</strong>: gRPC supports multiple languages and platforms, making it easy to integrate with existing systems and ensuring broad compatibility.</li>
</ul>


<a name="Ecosystem-and-Tooling"></a>
<h3>Ecosystem and Tooling</h3>

<ul>
<li><strong>Rich Ecosystem</strong>: gRPC is supported by a wide range of tools and libraries, facilitating monitoring, debugging, and performance tuning. Tools like Envoy Proxy and Istio further enhance its capabilities in microservices environments.</li>
</ul>


<a name="When-to-Use-gRPC"></a>
<h2>When to Use gRPC</h2>

<p>While gRPC offers many advantages, it may not be suitable for every use case. Here are some scenarios where gRPC shines:</p>

<ul>
<li><strong>Low-Latency, High-Throughput Systems</strong>: Applications requiring high performance and efficient network utilization.</li>
<li><strong>Microservices</strong>: Complex systems with many inter-service communications benefit from gRPC&rsquo;s efficiency and robust features.</li>
<li><strong>Real-Time Applications</strong>: Use cases needing bi-directional streaming, such as chat applications, real-time analytics, and IoT systems.</li>
<li><strong>Polyglot Environments</strong>: Systems built using multiple programming languages, leveraging gRPC&rsquo;s cross-language support.</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>gRPC represents a significant evolution in API design and inter-service communication, offering numerous benefits over traditional REST APIs. Its performance advantages, strongly typed contracts, streaming capabilities, and rich ecosystem make it an excellent choice for modern distributed systems and microservices architectures. While REST remains a viable option for many applications, developers should consider gRPC when building performance-critical, scalable, and real-time systems.</p>

<p>By understanding the strengths and appropriate use cases for gRPC, you can make informed decisions about when to adopt this powerful technology in your own projects.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Event-Driven Architecture: Unlocking Modern Application Potential]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/event-driven-architecture-unlocking-modern-application-potential/"/>
    <updated>2024-06-26T09:27:40+05:30</updated>
    <id>https://rishijeet.github.io/blog/event-driven-architecture-unlocking-modern-application-potential</id>
    <content type="html"><![CDATA[<p>In today&rsquo;s fast-paced digital landscape, real-time data processing and responsive systems are becoming increasingly crucial. Traditional request-response architectures often struggle to keep up with the demands of modern applications, which require scalable, resilient, and decoupled systems. Enter event-based architecture—a paradigm that addresses these challenges by enabling systems to react to changes and events as they happen.</p>

<p>In this blog, we&rsquo;ll explore the key concepts, benefits, and components of modern event-based architecture, along with practical examples and best practices for implementation.</p>

<a name="What-is-Event-2d-Based-Architecture-3f-"></a>
<h2>What is Event-Based Architecture?</h2>

<p>Event-based architecture is a design pattern in which system components communicate by producing and consuming events. An event is a significant change in state or an occurrence that is meaningful to the system, such as a user action, a data update, or an external trigger. Instead of directly calling methods or services, components publish events to an event bus, and other components subscribe to these events to perform actions in response.</p>

<p><img src="https://rishijeet.github.io/images/2024/glossary-eda.svg" height="300" width="900" alt="Alt text" /><em>Source: Hazelcast</em></p>

<a name="Components-of-Modern-Event-2d-Based-Architecture"></a>
<h2>Components of Modern Event-Based Architecture</h2>

<a name="Event-Producers"></a>
<h3>Event Producers</h3>

<p>Event producers are responsible for generating events. These can be user interfaces, IoT devices, data ingestion services, or any other source that generates meaningful events. Producers publish events to the event bus without needing to know who will consume them.</p>

<a name="Event-Consumers"></a>
<h3>Event Consumers</h3>

<p>Event consumers subscribe to specific events and react to them. Consumers can perform various actions, such as updating databases, triggering workflows, sending notifications, or invoking other services. Each consumer processes events independently, allowing for parallel and asynchronous processing.</p>

<a name="Event-Bus"></a>
<h3>Event Bus</h3>

<p>The event bus is the backbone of an event-based architecture. It routes events from producers to consumers, ensuring reliable and scalable communication. Common implementations of an event bus include message brokers like Apache Kafka, RabbitMQ, and Amazon SNS/SQS.</p>

<a name="Event-Streams-and-Storage"></a>
<h3>Event Streams and Storage</h3>

<p>Event streams are continuous flows of events that can be processed in real-time or stored for batch processing and historical analysis. Stream processing frameworks like Apache Kafka Streams, Apache Flink, and Apache Storm enable real-time processing of event streams.</p>

<a name="Event-Processing-and-Transformation"></a>
<h3>Event Processing and Transformation</h3>

<p>Event processing involves filtering, aggregating, and transforming events to derive meaningful insights and trigger actions. Complex Event Processing (CEP) engines and stream processing frameworks are often used to handle sophisticated event processing requirements.</p>

<!--more-->


<a name="Practical-Example"></a>
<h2>Practical Example</h2>

<p>Let&rsquo;s map the modern event-based architecture to a coffee shop scenario with four key services: Product Service, Counter Service, Barista Service, and Kitchen Service. This analogy will help visualize how event-based systems work in a real-world context.</p>

<p><img src="https://rishijeet.github.io/images/2024/coffeeshop.svg" height="300" width="900" alt="Alt text" /><em>Source: <a href="https://github.com/thangchung/go-coffeeshop">Github</a></em></p>

<a name="Services-in-the-Coffee-Shop"></a>
<h3>Services in the Coffee Shop</h3>

<ul>
<li><strong>Product Service</strong>: Manages the menu and availability of items.</li>
<li><strong>Counter Service</strong>: Handles customer orders and payments.</li>
<li><strong>Barista Service</strong>: Prepares coffee and other beverages.</li>
<li><strong>Kitchen Service</strong>: Prepares food items like pastries and sandwiches.</li>
</ul>


<a name="Event-Flow-in-the-Coffee-Shop"></a>
<h3>Event Flow in the Coffee Shop</h3>

<a name="Customer-Places-an-Order"></a>
<h4>Customer Places an Order</h4>

<ul>
<li><strong>Order Received</strong>: A customer places an order at the counter. The Counter Service generates an &ldquo;OrderPlaced&rdquo; event
containing details of the order.</li>
<li><strong>Inventory Check</strong>: The Product Service subscribes to &ldquo;OrderPlaced&rdquo; events to verify the availability of items. If
an item is out of stock, it can trigger an &ldquo;ItemOutOfStock&rdquo; event to update the menu.</li>
</ul>


<a name="Order-Processing"></a>
<h4>Order Processing</h4>

<ul>
<li><strong>Beverage Preparation</strong>: The Barista Service subscribes to &ldquo;OrderPlaced&rdquo; events to start preparing beverages. Once
a beverage is ready, it generates an &ldquo;BeverageReady&rdquo; event.</li>
<li><strong>Food Preparation</strong>: The Kitchen Service subscribes to &ldquo;OrderPlaced&rdquo; events to start preparing food items. Once a
food item is ready, it generates an &ldquo;FoodReady&rdquo; event.</li>
</ul>


<a name="Customer-Notification"></a>
<h4>Customer Notification</h4>

<ul>
<li><strong>Order Ready Notification</strong>: The Counter Service subscribes to &ldquo;BeverageReady&rdquo; and &ldquo;FoodReady&rdquo; events. When all
items in an order are ready, it generates an &ldquo;OrderReady&rdquo; event and notifies the customer.</li>
</ul>


<a name="Detailed-Event-Flow"></a>
<h3>Detailed Event Flow</h3>

<p><strong>Order Placed</strong>:
    - A customer orders a cappuccino and a sandwich at the counter.
    - The Counter Service generates an &ldquo;OrderPlaced&rdquo; event:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;orderId&quot;</span><span class="p">:</span> <span class="s2">&quot;12345&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;items&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>        <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;beverage&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;cappuccino&quot;</span><span class="p">},</span>
</span><span class='line'>        <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;food&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;sandwich&quot;</span><span class="p">}</span>
</span><span class='line'>    <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Inventory Check</strong>:
    - The Product Service receives the &ldquo;OrderPlaced&rdquo; event and checks inventory.
    - If the cappuccino is out of stock, it generates an &ldquo;ItemOutOfStock&rdquo; event.
    - If all items are available, no further action is taken by the Product Service.</p>

<p><strong>Beverage Preparation</strong>:
    - The Barista Service receives the &ldquo;OrderPlaced&rdquo; event and starts preparing the cappuccino.
    - Once the cappuccino is ready, it generates a &ldquo;BeverageReady&rdquo; event:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;orderId&quot;</span><span class="p">:</span> <span class="s2">&quot;12345&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;item&quot;</span><span class="p">:</span> <span class="s2">&quot;cappuccino&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Food Preparation</strong>:
    - The Kitchen Service receives the &ldquo;OrderPlaced&rdquo; event and starts preparing the sandwich.
    - Once the sandwich is ready, it generates a &ldquo;FoodReady&rdquo; event:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;orderId&quot;</span><span class="p">:</span> <span class="s2">&quot;12345&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;item&quot;</span><span class="p">:</span> <span class="s2">&quot;sandwich&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Order Ready Notification</strong>:
    - The Counter Service receives both &ldquo;BeverageReady&rdquo; and &ldquo;FoodReady&rdquo; events.
    - Once all items for order 12345 are ready, it generates an &ldquo;OrderReady&rdquo; event and notifies the customer:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;orderId&quot;</span><span class="p">:</span> <span class="s2">&quot;12345&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;ready&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Best-Practices-for-Implementing-Event-2d-Based-Architecture"></a>
<h2>Best Practices for Implementing Event-Based Architecture</h2>

<ul>
<li><strong>Design for Idempotency</strong>: Ensure that event consumers can handle duplicate events gracefully, as network issues
might cause events to be delivered multiple times.</li>
<li><strong>Use Schemas</strong>: Define clear schemas for events to ensure consistent and reliable communication between producers
and consumers.</li>
<li><strong>Monitor and Log</strong>: Implement robust monitoring and logging to track event flows, detect anomalies, and
troubleshoot issues.</li>
<li><strong>Handle Event Ordering</strong>: If event order is important, ensure that your event bus or stream processing framework
preserves the order of events.</li>
<li><strong>Ensure Fault Tolerance</strong>: Design your system to handle failures gracefully, with retry mechanisms and fallback
strategies.</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Modern event-based architecture provides a robust and flexible approach to building scalable, resilient, and real-time systems. By decoupling components and enabling asynchronous communication through events, this architecture pattern addresses many challenges of traditional systems. Whether you&rsquo;re building an e-commerce platform, a real-time analytics system, or an IoT solution, event-based architecture can help you achieve better performance, scalability, and agility.</p>

<p>Embracing this architectural style requires careful planning, but the benefits it offers make it a worthwhile investment for any modern application.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding the Bloom filter]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/understanding-the-bloom-filter/"/>
    <updated>2024-06-11T10:09:01+05:30</updated>
    <id>https://rishijeet.github.io/blog/understanding-the-bloom-filter</id>
    <content type="html"><![CDATA[<p>A Bloom filter is a probabilistic data structure used to test whether an element is a member of a set. It is highly space-efficient and allows for fast query operations, but it has a small risk of false positives (reporting that an element is in the set when it is not) while guaranteeing no false negatives (an element that is in the set will always be reported as such).</p>

<a name="How-Bloom-Filters-Work"></a>
<h2>How Bloom Filters Work</h2>

<p>A Bloom filter uses a bit array of fixed size and a set of hash functions. Here is a simplified example of how it works:</p>

<p><strong>Initialization</strong>:</p>

<ul>
<li>Create a bit array of size \(m\) and initialize all bits to 0.</li>
</ul>


<p><strong>Adding an Element</strong>:</p>

<ul>
<li>Compute \(k\) hash values of the element using \(k\) different hash functions.</li>
<li>Set the bits at the positions determined by the hash values to 1 in the bit array.</li>
</ul>


<p><strong>Checking Membership</strong>:</p>

<ul>
<li>Compute the \(k\) hash values of the element.</li>
<li>Check the bits at the positions determined by the hash values.</li>
<li>If all bits are set to 1, the element is considered to be possibly in the set (with a risk of false positive).</li>
<li>If any bit is 0, the element is definitely not in the set.</li>
</ul>


<p>The underlying architecture of a Bloom filter consists of three main components: a bit array, a set of hash functions, and the operations for adding elements and checking membership. Below is a detailed breakdown of each component and the overall architecture:</p>

<a name="Components-of-a-Bloom-Filter"></a>
<h2>Components of a Bloom Filter</h2>

<p><strong>Bit Array</strong>:</p>

<ul>
<li>A Bloom filter uses a bit array of fixed size \( m \). This array is initialized with all bits set to 0.</li>
<li>The size of the bit array \( m \) is chosen based on the expected number of elements \( n \) and the desired
false positive rate \( p \).</li>
</ul>


<p><strong>Hash Functions</strong>:</p>

<ul>
<li>A Bloom filter uses \( k \) different hash functions. Each hash function maps an input element to one of the
positions in the bit array uniformly at random.</li>
<li>The number of hash functions \( k \) is optimized to minimize the false positive rate.</li>
</ul>


<!-- more -->


<a name="Operations"></a>
<h2>Operations</h2>

<p><strong>Adding an Element</strong>:</p>

<ul>
<li>To add an element to the Bloom filter, the element is passed through each of the \( k \) hash functions to
produce \( k \) hash values.</li>
<li>Each hash value corresponds to a position in the bit array. The bits at these positions are set to 1.</li>
<li>If a bit is already set to 1, it remains 1.</li>
</ul>


<p><strong>Checking Membership</strong>:</p>

<ul>
<li>To check if an element is in the Bloom filter, the element is passed through the \( k \) hash functions to
produce \( k \) hash values.</li>
<li>Each hash value corresponds to a position in the bit array. If all the bits at these positions are 1, the element is considered to be possibly in the set.</li>
<li>If any bit at these positions is 0, the element is definitely not in the set.</li>
</ul>


<a name="Architecture-Details"></a>
<h2>Architecture Details</h2>

<p>The architecture of a Bloom filter can be visualized as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>                +---------------------+
</span><span class='line'>                |     Bit Array       |
</span><span class='line'>                | [0, 0, 0, ..., 0]   |
</span><span class='line'>                +---------|-----------+
</span><span class='line'>                          |
</span><span class='line'>                          v
</span><span class='line'>+-------------------+     v     +-------------------+
</span><span class='line'>| Hash Function 1   | ----------&gt; | Hash Function 2   | ... | Hash Function k |
</span><span class='line'>+-------------------+     |     +-------------------+
</span><span class='line'>       |                  |
</span><span class='line'>       v                  v
</span><span class='line'>+------+-------+   +------+-------+
</span><span class='line'>| Element to be |   | Element to be |
</span><span class='line'>|    added      |   |  checked     |
</span><span class='line'>+---------------+   +---------------+
</span><span class='line'>       |                  |
</span><span class='line'>       v                  v
</span><span class='line'>+-------------------+     +-------------------+
</span><span class='line'>| Calculate Hash    |     | Calculate Hash    |
</span><span class='line'>|  Positions        |     |  Positions        |
</span><span class='line'>+-------------------+     +-------------------+
</span><span class='line'>       |                  |
</span><span class='line'>       v                  v
</span><span class='line'>+-------------------+     +-------------------+
</span><span class='line'>| Set Bits in Bit   |     | Check Bits in Bit |
</span><span class='line'>| Array to 1        |     | Array             |
</span><span class='line'>+-------------------+     +-------------------+
</span><span class='line'>                          |
</span><span class='line'>                          v
</span><span class='line'>                      +-------------------+
</span><span class='line'>                      |   Check Result    |
</span><span class='line'>                      +-------------------+</span></code></pre></td></tr></table></div></figure>


<a name="Detailed-Process"></a>
<h2>Detailed Process</h2>

<p><strong>Initialization</strong>:</p>

<ul>
<li>The bit array of size \( m \) is initialized to all 0s.</li>
<li>The hash functions are chosen, ensuring they distribute hash values uniformly across the bit array.</li>
</ul>


<p><strong>Adding an Element</strong>:</p>

<ul>
<li>The element is processed through each hash function to get \( k \) positions.</li>
<li><div> Example: For an element &#92;( x &#92;) and hash functions &#92;( h_1, h_2, &#8230;, h_k &#92;) </div>


<ul>
<li><div>\( h_1(x) = p_1 \)</div>
</li>
<li><div>\( h_2(x) = p_2 \)</div>
</li>
<li><div>&#8230;</div>
</li>
<li><div>\( h_k(x) = p_k \)</div>
</li>
</ul>
</li>
<li><div> Set the bit positions \( p_1, p_2, &#8230;, p_k \) to 1 in the bit array. </div>
</li>
</ul>


<p><strong>Checking Membership</strong>:</p>

<ul>
<li>The element is processed through each hash function to get \( k \) positions.</li>
<li><div>Example: For an element &#92;( y &#92;) and hash functions \( h_1, h_2, &#8230;, h_k \):</div>


<ul>
<li><div> &#92;( h_1(y) = q_1 &#92;)</div>
</li>
<li><div>&#92;( h_2(y) = q_2 &#92;)</div>
</li>
<li><div>&#8230;</div>
</li>
<li><div>&#92;( h_k(y) = q_k &#92;)</div>
</li>
</ul>
</li>
<li><div>Check if all bit positions &#92;( q_1, q_2, &#8230;, q_k &#92;) are 1 in the bit array. </div>
</li>
<li>If all are 1, the element is possibly in the set; if any is 0, the element is definitely not in the set.</li>
</ul>


<a name="Mathematical-Foundation"></a>
<h2>Mathematical Foundation</h2>

<ul>
<li><p>The probability of a false positive can be estimated using the formula:
\[
p \approx \left(1 - e^{-\frac{kn}{m}}\right)^k
\]
where \( k \) is the number of hash functions, \( n \) is the number of elements added, and \( m \) is the size of the bit array.</p></li>
<li><p>Optimal number of hash functions:
\[
k = \frac{m}{n} \ln 2
\]
This minimizes the false positive rate for given \( m \) and \( n \).</p></li>
</ul>


<a name="Example-in-Python"></a>
<h3>Example in Python</h3>

<p>Here’s a complete example of a Bloom filter in Python:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">mmh3</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">bitarray</span> <span class="kn">import</span> <span class="n">bitarray</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">BloomFilter</span><span class="p">:</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span> <span class="o">=</span> <span class="n">hash_count</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span> <span class="o">=</span> <span class="n">bitarray</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="o">.</span><span class="n">setall</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>                <span class="k">return</span> <span class="bp">False</span>
</span><span class='line'>        <span class="k">return</span> <span class="bp">True</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Example usage</span>
</span><span class='line'><span class="n">bf</span> <span class="o">=</span> <span class="n">BloomFilter</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Add items</span>
</span><span class='line'><span class="n">bf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;apple&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">bf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;banana&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Check for items</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">bf</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="s">&quot;apple&quot;</span><span class="p">))</span>  <span class="c"># Output: True</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">bf</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="s">&quot;banana&quot;</span><span class="p">))</span>  <span class="c"># Output: True</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">bf</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="s">&quot;grape&quot;</span><span class="p">))</span>  <span class="c"># Output: False</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Types-of-Bloom-Filters"></a>
<h2>Types of Bloom Filters</h2>

<p>Bloom filters have several variations and types that cater to different use cases and requirements. Here are some of the main types of Bloom filters:</p>

<p><strong>Standard Bloom Filter</strong>:</p>

<ul>
<li>The basic version as described previously, which uses a bit array and multiple hash functions to determine membership with a probabilistic guarantee.</li>
</ul>


<p><strong>Counting Bloom Filter</strong>:</p>

<ul>
<li>Extends the standard Bloom filter by using a counter array instead of a bit array.</li>
<li>Allows for deletion of elements by decrementing the counters.</li>
<li>Useful in scenarios where elements may be frequently added and removed.</li>
</ul>


<p><strong>Scalable Bloom Filter</strong>:</p>

<ul>
<li>Adjusts the size dynamically to accommodate an increasing number of elements while maintaining a low false positive rate.</li>
<li>Uses a series of Bloom filters with exponentially increasing sizes and decreasing false positive rates.</li>
</ul>


<p><strong>Partitioned Bloom Filter</strong>:</p>

<ul>
<li>The bit array is divided into partitions, with each partition associated with one hash function.</li>
<li>Reduces the chance of hash collisions and improves performance.</li>
</ul>


<p><strong>Compressed Bloom Filter</strong>:</p>

<ul>
<li>A Bloom filter that is compressed to save space, at the cost of slightly higher false positive rates and processing time.</li>
<li>Useful in scenarios with very tight space constraints.</li>
</ul>


<p><strong>Cuckoo Filter</strong>:</p>

<ul>
<li>Similar to a Bloom filter but uses cuckoo hashing, which allows for dynamic insertion and deletion with a guaranteed maximum number of hash collisions.</li>
<li>Provides better performance for insertion and deletion operations compared to counting Bloom filters.</li>
</ul>


<p><strong>d-left Counting Bloom Filter</strong>:</p>

<ul>
<li>A combination of d-left hashing and counting Bloom filters, providing efficient updates and low false positive rates.</li>
<li>Suitable for scenarios with high update rates.</li>
</ul>


<p><strong>Stable Bloom Filter</strong>:</p>

<ul>
<li>Designed to handle continuous data streams where only the most recent elements matter.</li>
<li>Uses a sliding window approach to keep the Bloom filter updated with the most recent elements.</li>
</ul>


<a name="Example-Implementations-in-Python"></a>
<h3>Example Implementations in Python</h3>

<p>Here are some Python implementations for a few types of Bloom filters:</p>

<a name="Standard-Bloom-Filter"></a>
<h4>Standard Bloom Filter</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">mmh3</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">bitarray</span> <span class="kn">import</span> <span class="n">bitarray</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">BloomFilter</span><span class="p">:</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span> <span class="o">=</span> <span class="n">hash_count</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span> <span class="o">=</span> <span class="n">bitarray</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="o">.</span><span class="n">setall</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>                <span class="k">return</span> <span class="bp">False</span>
</span><span class='line'>        <span class="k">return</span> <span class="bp">True</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Counting-Bloom-Filter"></a>
<h4>Counting Bloom Filter</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">mmh3</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">CountingBloomFilter</span><span class="p">:</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span> <span class="o">=</span> <span class="n">hash_count</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">count_array</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">size</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">count_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">remove</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>                <span class="bp">self</span><span class="o">.</span><span class="n">count_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>                <span class="k">return</span> <span class="bp">False</span>
</span><span class='line'>        <span class="k">return</span> <span class="bp">True</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Scalable-Bloom-Filter"></a>
<h4>Scalable Bloom Filter</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">math</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">mmh3</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">bitarray</span> <span class="kn">import</span> <span class="n">bitarray</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">ScalableBloomFilter</span><span class="p">:</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_size</span><span class="p">,</span> <span class="n">error_rate</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">filters</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">initial_size</span> <span class="o">=</span> <span class="n">initial_size</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span> <span class="o">=</span> <span class="n">error_rate</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_add_filter</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">_add_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">:</span>
</span><span class='line'>            <span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_size</span>
</span><span class='line'>            <span class="n">error_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span>
</span><span class='line'>        <span class="k">else</span><span class="p">:</span>
</span><span class='line'>            <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bit_array</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
</span><span class='line'>            <span class="n">error_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">error_rate</span> <span class="o">/</span> <span class="mi">2</span>
</span><span class='line'>        <span class="n">new_filter</span> <span class="o">=</span> <span class="n">BloomFilter</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">error_rate</span><span class="p">)</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</span><span class='line'>        <span class="n">new_filter</span><span class="o">.</span><span class="n">error_rate</span> <span class="o">=</span> <span class="n">error_rate</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_filter</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
</span><span class='line'>            <span class="k">return</span>
</span><span class='line'>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">count</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bit_array</span><span class="p">):</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">_add_filter</span><span class="p">()</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">filters</span><span class="p">:</span>
</span><span class='line'>            <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
</span><span class='line'>                <span class="k">return</span> <span class="bp">True</span>
</span><span class='line'>        <span class="k">return</span> <span class="bp">False</span>
</span><span class='line'>
</span><span class='line'><span class="k">class</span> <span class="nc">BloomFilter</span><span class="p">:</span>
</span><span class='line'>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">hash_count</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span> <span class="o">=</span> <span class="n">bitarray</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="o">.</span><span class="n">setall</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_count</span><span class="p">):</span>
</span><span class='line'>            <span class="n">digest</span> <span class="o">=</span> <span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>
</span><span class='line'>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bit_array</span><span class="p">[</span><span class="n">digest</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>                <span class="k">return</span> <span class="bp">False</span>
</span><span class='line'>        <span class="k">return</span> <span class="bp">True</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Key-uses-of-Bloom-Filters"></a>
<h2>Key uses of Bloom Filters</h2>

<p><strong>Membership Testing</strong></p>

<ul>
<li><strong>Applications</strong>: Used in network and database systems to test if an element (e.g., an IP address, URL, or
database entry) is present in a large dataset.</li>
<li><strong>Example</strong>: In a web caching system, a Bloom filter can quickly determine if a requested URL is already cached,
thus avoiding the need to query the actual cache storage.</li>
</ul>


<p><strong>Preventing Redundant Data</strong></p>

<ul>
<li><strong>Applications</strong>: Helps in avoiding the storage or processing of duplicate elements.</li>
<li><strong>Example</strong>: In distributed databases or big data processing frameworks like Hadoop and Spark, Bloom filters can ensure that only unique records are processed or stored.</li>
</ul>


<p><strong>Distributed Systems</strong></p>

<ul>
<li><strong>Applications</strong>: Used to efficiently share set membership information across distributed nodes.</li>
<li><strong>Example</strong>: In a distributed hash table (DHT) like Cassandra, Bloom filters help quickly determine if a row exists in a particular node before attempting a read operation, thereby reducing unnecessary I/O operations.</li>
</ul>


<p><strong>Database Indexing</strong></p>

<ul>
<li><strong>Applications</strong>: Enhances the performance of database indexing mechanisms by quickly checking if a key is present.</li>
<li><strong>Example</strong>: In a database like Apache HBase, Bloom filters are used to reduce the number of disk lookups for non-existent rows.</li>
</ul>


<p><strong>Network Security</strong></p>

<ul>
<li><strong>Applications</strong>: Helps in quickly checking if a network packet matches a known malicious pattern.</li>
<li><strong>Example</strong>: In intrusion detection systems (IDS) and firewalls, Bloom filters can be used to check if incoming network traffic matches a list of known attack signatures.</li>
</ul>


<p><strong>Spell Checking</strong></p>

<ul>
<li><strong>Applications</strong>: Quickly verify if a word exists in a dictionary.</li>
<li><strong>Example</strong>: Spell checkers can use Bloom filters to rapidly determine if a word is valid, thus speeding up the spell-checking process.</li>
</ul>


<a name="Summary"></a>
<h2>Summary</h2>

<p>Bloom filters are versatile data structures with various types designed to optimize performance, space efficiency, and functionality for different use cases. Whether you need basic membership checking, dynamic size adjustment, element deletion, or handling continuous data streams, there&rsquo;s a Bloom filter variant that can meet your requirements.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cassandra - Under the hood]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/cassandra-under-the-hood/"/>
    <updated>2024-05-22T23:48:44+05:30</updated>
    <id>https://rishijeet.github.io/blog/cassandra-under-the-hood</id>
    <content type="html"><![CDATA[<p>Apache Cassandra is designed to handle large amounts of data across many commodity servers without any single point of failure. This architecture allows it to provide high availability and fault tolerance, making it an excellent choice for large-scale, mission-critical applications. Below, we&rsquo;ll delve into the key components and architecture of Cassandra.</p>

<a name="Key-Components"></a>
<h3>Key Components</h3>

<ul>
<li><strong>Nodes</strong>: Individual machines running Cassandra.</li>
<li><strong>Clusters</strong>: A collection of nodes that work together.</li>
<li><strong>Data Centers</strong>: Groupings of nodes within a cluster, typically corresponding to physical or logical locations.</li>
<li><strong>Keyspace</strong>: A namespace for tables, analogous to a database in SQL.</li>
<li><strong>Tables</strong>: Collections of rows, each row containing columns, similar to tables in an RDBMS.</li>
<li><strong>Commit Log</strong>: A log of all write operations, used for crash recovery.</li>
<li><strong>Memtable</strong>: An in-memory structure where data is first written.</li>
<li><strong>SSTable</strong>: Immutable on-disk storage files created from flushed Memtables.</li>
<li><strong>Bloom Filters</strong>: Probabilistic data structures that help determine whether an SSTable might contain a requested row.</li>
</ul>


<a name="Architecture-Overview"></a>
<h3>Architecture Overview</h3>

<a name="Cluster-Management"></a>
<h4>Cluster Management</h4>

<p>Cassandra&rsquo;s cluster architecture ensures high availability and fault tolerance. The cluster is a set of nodes, and data is distributed among these nodes using consistent hashing. Key features include:</p>

<ul>
<li><strong>Gossip Protocol</strong>: Nodes communicate with each other using a peer-to-peer gossip protocol to share state information.</li>
<li><strong>Snitches</strong>: Determine the relative distance between nodes to route requests efficiently.</li>
<li><strong>Replication</strong>: Data is replicated across multiple nodes. The replication strategy and factor determine how and where data is replicated.</li>
</ul>


<!--more-->


<a name="Data-Distribution"></a>
<h4>Data Distribution</h4>

<p>Cassandra uses a consistent hashing algorithm to distribute data across nodes. Key features include:</p>

<ul>
<li><strong>Partitioners</strong>: Determine the node placement of data based on the primary key.</li>
<li><strong>Token Ring</strong>: Each node in the cluster is assigned a range of tokens. Data is distributed based on these tokens.</li>
<li><strong>Replication Factor</strong>: The number of copies of data stored in the cluster.</li>
</ul>


<a name="Write-Path"></a>
<h4>Write Path</h4>

<p>The write path in Cassandra ensures durability and high availability:</p>

<ul>
<li><strong>Commit Log</strong>: Each write operation is recorded in the commit log for durability.</li>
<li><strong>Memtable</strong>: The data is written to an in-memory structure called the Memtable.</li>
<li><strong>SSTable</strong>: Once the Memtable is full, data is flushed to disk into an SSTable.</li>
<li><strong>Compaction</strong>: Over time, SSTables are compacted to merge and purge deleted data.</li>
</ul>


<a name="Read-Path"></a>
<h4>Read Path</h4>

<p>The read path in Cassandra is optimized for speed:</p>

<ul>
<li><strong>Read Request</strong>: A read request is routed to the appropriate nodes.</li>
<li><strong>Bloom Filter</strong>: Checks if the SSTable might contain the requested row.</li>
<li><strong>Key Cache</strong>: Quickly locates the row key in the SSTable.</li>
<li><strong>Row Cache</strong>: Caches the entire row to speed up frequent queries.</li>
<li><strong>Memtable and SSTable</strong>: Data is read from Memtables and SSTables, and results are merged.</li>
</ul>


<a name="Fault-Tolerance"></a>
<h4>Fault Tolerance</h4>

<p>Cassandra is designed to be highly fault-tolerant:</p>

<ul>
<li><strong>Data Replication</strong>: Multiple copies of data are stored across different nodes.</li>
<li><strong>Hinted Handoff</strong>: If a node is down, writes are stored temporarily on another node and delivered when the target node is available.</li>
<li><strong>Read Repair</strong>: During reads, inconsistencies are repaired by comparing data across replicas.</li>
<li><strong>Anti-Entropy Repair</strong>: Regularly scheduled repairs ensure all replicas are consistent.</li>
</ul>


<a name="Diagram"></a>
<h3>Diagram</h3>

<p>Here’s a simplified diagram of Cassandra’s architecture:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>                    +-----------------------------+
</span><span class='line'>                    |         Cassandra Cluster   |
</span><span class='line'>                    +-----------------------------+
</span><span class='line'>                                  |
</span><span class='line'>  +-------------------------------+-------------------------------+
</span><span class='line'>  |                               |                               |
</span><span class='line'>+------------+                 +------------+                 +------------+
</span><span class='line'>| Data Center 1 |               | Data Center 2 |               | Data Center 3 |
</span><span class='line'>+------------+                 +------------+                 +------------+
</span><span class='line'>  |                               |                               |
</span><span class='line'>+------+--------+          +------+--------+          +------+--------+
</span><span class='line'>| Node 1       |          | Node 1       |          | Node 1       |
</span><span class='line'>+--------------+          +--------------+          +--------------+
</span><span class='line'>| Commit Log   |          | Commit Log   |          | Commit Log   |
</span><span class='line'>| Memtable     |          | Memtable     |          | Memtable     |
</span><span class='line'>| SSTable      |          | SSTable      |          | SSTable      |
</span><span class='line'>+--------------+          +--------------+          +--------------+</span></code></pre></td></tr></table></div></figure>


<p>To illustrate, let&rsquo;s consider setting up a Cassandra cluster and creating a keyspace</p>

<a name="Configuration"></a>
<h4>Configuration</h4>

<p><strong>cassandra.yaml</strong>: The primary configuration file for Cassandra.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">cluster_name</span><span class="p-Indicator">:</span> <span class="s">&#39;MyCluster&#39;</span>
</span><span class='line'><span class="l-Scalar-Plain">num_tokens</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">256</span>
</span><span class='line'><span class="l-Scalar-Plain">seed_provider</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">class_name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">org.apache.cassandra.locator.SimpleSeedProvider</span>
</span><span class='line'>    <span class="l-Scalar-Plain">parameters</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">seeds</span><span class="p-Indicator">:</span> <span class="s">&quot;127.0.0.1&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">storage_port</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">7000</span>
</span><span class='line'><span class="l-Scalar-Plain">listen_address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">localhost</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">rpc_port</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">9042</span>
</span><span class='line'><span class="l-Scalar-Plain">rpc_address</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">localhost</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">endpoint_snitch</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">SimpleSnitch</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Keyspace-and-Table-Creation"></a>
<h4>Keyspace and Table Creation</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="c1">-- Create a keyspace</span>
</span><span class='line'><span class="k">CREATE</span> <span class="n">KEYSPACE</span> <span class="n">mykeyspace</span> <span class="k">WITH</span> <span class="n">replication</span> <span class="o">=</span> <span class="err">{</span>
</span><span class='line'>  <span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="s1">&#39;SimpleStrategy&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="s1">&#39;replication_factor&#39;</span><span class="p">:</span> <span class="mi">3</span>
</span><span class='line'><span class="err">}</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="c1">-- Use the keyspace</span>
</span><span class='line'><span class="n">USE</span> <span class="n">mykeyspace</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="c1">-- Create a table</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">users</span> <span class="p">(</span>
</span><span class='line'>  <span class="n">user_id</span> <span class="n">UUID</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
</span><span class='line'>  <span class="n">name</span> <span class="nb">TEXT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">email</span> <span class="nb">TEXT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">age</span> <span class="nb">INT</span>
</span><span class='line'><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Why-is-Cassandra-fast-in-writes-3f-"></a>
<h2>Why is Cassandra fast in writes?</h2>

<a name="Log-2d-Structured-Storage"></a>
<h3>Log-Structured Storage</h3>

<ul>
<li>Cassandra appends write operations to a commit log on disk for durability.</li>
<li>This sequential write pattern minimizes disk seeks and maximizes disk throughput, leading to fast write operations.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// Insert data into Cassandra using CQL (Cassandra Query Language)</span>
</span><span class='line'><span class="n">session</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;INSERT INTO users (user_id, name, email, age) VALUES (uuid(), &#39;Alice&#39;, &#39;alice@example.com&#39;, 30)&quot;</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<a name="In-2d-Memory-Write-Path"></a>
<h3>In-Memory Write Path</h3>

<ul>
<li>Write operations are stored in an in-memory structure called the Memtable.</li>
<li>Memtables are flushed to disk periodically or when they reach a certain size threshold.</li>
<li>Buffering writes in memory before flushing them to disk speeds up write operations.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// Insert data into Cassandra using CQL</span>
</span><span class='line'><span class="n">session</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;INSERT INTO users (user_id, name, email, age) VALUES (uuid(), &#39;Alice&#39;, &#39;alice@example.com&#39;, 30)&quot;</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Multi-2d-Threaded-Architecture"></a>
<h3>Multi-Threaded Architecture</h3>

<ul>
<li>Cassandra&rsquo;s architecture allows for parallel processing of writes across multiple threads and cores.</li>
<li>Each node in the Cassandra cluster can handle multiple concurrent writes, maximizing hardware resources utilization.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// Insert data into Cassandra using multiple threads</span>
</span><span class='line'><span class="n">ExecutorService</span> <span class="n">executor</span> <span class="o">=</span> <span class="n">Executors</span><span class="o">.</span><span class="na">newFixedThreadPool</span><span class="o">(</span><span class="mi">10</span><span class="o">);</span>
</span><span class='line'><span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">executor</span><span class="o">.</span><span class="na">submit</span><span class="o">(()</span> <span class="o">-&gt;</span> <span class="n">session</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;INSERT INTO users (user_id, name, email, age) VALUES (uuid(), &#39;Alice&#39;, &#39;alice@example.com&#39;, 30)&quot;</span><span class="o">));</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'><span class="n">executor</span><span class="o">.</span><span class="na">shutdown</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Distributed-Writes"></a>
<h3>Distributed Writes</h3>

<ul>
<li>Cassandra distributes data across multiple nodes using consistent hashing.</li>
<li>Write operations are replicated to multiple nodes based on the configured replication factor.</li>
<li>This distributed nature allows Cassandra to scale horizontally, handling write-heavy workloads with ease.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// Insert data into Cassandra with replication factor</span>
</span><span class='line'><span class="n">session</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;INSERT INTO users (user_id, name, email, age) VALUES (uuid(), &#39;Alice&#39;, &#39;alice@example.com&#39;, 30)&quot;</span><span class="o">)</span>
</span><span class='line'>        <span class="o">.</span><span class="na">setConsistencyLevel</span><span class="o">(</span><span class="n">DefaultConsistencyLevel</span><span class="o">.</span><span class="na">ALL</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Tunable-Consistency"></a>
<h3>Tunable Consistency</h3>

<ul>
<li>Cassandra allows for tunable consistency levels for write operations.</li>
<li>Clients can choose the level of consistency required for each write operation, balancing consistency and latency.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// Insert data into Cassandra with tunable consistency level</span>
</span><span class='line'><span class="n">session</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;INSERT INTO users (user_id, name, email, age) VALUES (uuid(), &#39;Alice&#39;, &#39;alice@example.com&#39;, 30)&quot;</span><span class="o">)</span>
</span><span class='line'>        <span class="o">.</span><span class="na">setConsistencyLevel</span><span class="o">(</span><span class="n">DefaultConsistencyLevel</span><span class="o">.</span><span class="na">QUORUM</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<a name="No-Single-Point-of-Bottleneck"></a>
<h3>No Single Point of Bottleneck</h3>

<ul>
<li>Cassandra&rsquo;s decentralized architecture ensures no single point of bottleneck for writes.</li>
<li>Each node in the cluster can independently process write operations, leading to linear scalability.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// Insert data into Cassandra on multiple nodes in the cluster</span>
</span><span class='line'><span class="n">session</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;INSERT INTO users (user_id, name, email, age) VALUES (uuid(), &#39;Alice&#39;, &#39;alice@example.com&#39;, 30)&quot;</span><span class="o">)</span>
</span><span class='line'>        <span class="o">.</span><span class="na">setConsistencyLevel</span><span class="o">(</span><span class="n">DefaultConsistencyLevel</span><span class="o">.</span><span class="na">LOCAL_QUORUM</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>Cassandra&rsquo;s fast write performance is achieved through a combination of log-structured storage, in-memory write buffering, multi-threaded architecture, distributed writes, tunable consistency, and decentralized design. By leveraging these design principles and using appropriate configuration options, Cassandra can handle high-throughput write workloads efficiently, making it an ideal choice for applications that require fast ingestion of large volumes of data.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Advantages of Enable Checkpointing in Apache Flink]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/advantages-of-enable-checkpointing-in-apache-flink/"/>
    <updated>2024-05-19T21:32:50+05:30</updated>
    <id>https://rishijeet.github.io/blog/advantages-of-enable-checkpointing-in-apache-flink</id>
    <content type="html"><![CDATA[<p>Enabling checkpointing in Apache Flink provides significant advantages for ensuring the reliability, consistency, and fault-tolerance of stream processing applications. Below, I detail the benefits and provide a code example.</p>

<a name="Advantages-of-Checkpointing"></a>
<h2>Advantages of Checkpointing</h2>

<ul>
<li><p><strong>Fault Tolerance</strong> Checkpointing ensures that the state of your Flink application can be recovered in case of a failure. Flink periodically saves snapshots of the entire distributed data stream and state to a persistent storage. If a failure occurs, Flink can restart the application and restore the state from the latest checkpoint, minimizing data loss and downtime.</p></li>
<li><p><strong>Exactly-Once Processing Semantics</strong> With checkpointing, Flink guarantees exactly-once processing semantics. This means that each event in the stream is processed exactly once, even in the face of failures. This is crucial for applications where accuracy is paramount, such as financial transaction processing or data analytics.</p></li>
<li><p><strong>Consistent State Management</strong> Checkpointing provides consistent snapshots of the application state. This consistency ensures that all parts of the state are in sync and correspond to the same point in the input stream, avoiding issues like partial updates or inconsistent results.</p></li>
<li><p><strong>Efficient State Recovery</strong> Checkpointing allows efficient recovery of the application state. Instead of reprocessing the entire data stream from the beginning, Flink can resume processing from the last checkpoint, saving computational resources and reducing recovery time.</p></li>
<li><p><strong>Backpressure Handling</strong> Flink’s checkpointing mechanism can help manage backpressure in the system by ensuring that the system processes data at a rate that matches the checkpointing intervals, preventing data overloads.</p></li>
<li><p><strong>State Evolution</strong> Checkpointing supports state evolution, allowing updates to the state schema without losing data. This is useful for applications that need to update their state representation over time while maintaining historical consistency.</p></li>
</ul>


<!--more-->


<a name="Code-Example"></a>
<h2>Code Example</h2>

<p>Here’s a basic example of enabling checkpointing in a Flink job:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.restartstrategy.RestartStrategies</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.environment.CheckpointConfig</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.CheckpointingMode</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">CheckpointingExample</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>        <span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Enable checkpointing every 10 seconds</span>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">enableCheckpointing</span><span class="o">(</span><span class="mi">10000</span><span class="o">);</span> <span class="c1">// 10 seconds</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Set checkpointing mode to exactly-once (default)</span>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">getCheckpointConfig</span><span class="o">().</span><span class="na">setCheckpointingMode</span><span class="o">(</span><span class="n">CheckpointingMode</span><span class="o">.</span><span class="na">EXACTLY_ONCE</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Ensure 500 ms of progress happen between checkpoints</span>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">getCheckpointConfig</span><span class="o">().</span><span class="na">setMinPauseBetweenCheckpoints</span><span class="o">(</span><span class="mi">500</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Checkpoints have to complete within one minute, or are discarded</span>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">getCheckpointConfig</span><span class="o">().</span><span class="na">setCheckpointTimeout</span><span class="o">(</span><span class="mi">60000</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Allow only one checkpoint to be in progress at the same time</span>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">getCheckpointConfig</span><span class="o">().</span><span class="na">setMaxConcurrentCheckpoints</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Retain the checkpoints on cancellation</span>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">getCheckpointConfig</span><span class="o">().</span><span class="na">enableExternalizedCheckpoints</span><span class="o">(</span><span class="n">CheckpointConfig</span><span class="o">.</span><span class="na">ExternalizedCheckpointCleanup</span><span class="o">.</span><span class="na">RETAIN_ON_CANCELLATION</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Set a restart strategy</span>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">setRestartStrategy</span><span class="o">(</span><span class="n">RestartStrategies</span><span class="o">.</span><span class="na">fixedDelayRestart</span><span class="o">(</span>
</span><span class='line'>            <span class="mi">3</span><span class="o">,</span> <span class="c1">// number of restart attempts</span>
</span><span class='line'>            <span class="mi">10000</span> <span class="c1">// delay between attempts</span>
</span><span class='line'>        <span class="o">));</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Define your data source, transformations, and sinks</span>
</span><span class='line'>        <span class="c1">// ...</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Flink Checkpointing Example&quot;</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>By setting up checkpointing, you ensure your Flink application is resilient and can recover from failures efficiently, maintaining data integrity and consistency.</p>

<p>For more detailed information, you can refer to the <a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/datastream/fault-tolerance/checkpointing/">Apache Flink Documentation on Checkpointing</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Windowing in Apache Flink]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/understanding-windowing-in-apache-flink/"/>
    <updated>2024-05-19T20:57:38+05:30</updated>
    <id>https://rishijeet.github.io/blog/understanding-windowing-in-apache-flink</id>
    <content type="html"><![CDATA[<p>Windowing is a fundamental concept in stream processing that allows you to group a continuous stream of events into finite chunks for processing. Apache Flink provides powerful windowing capabilities that support various window types and triggers for flexible, real-time data analysis.</p>

<p><img src="https://rishijeet.github.io/images/windows.svg" height="300" width="900" alt="Alt text" /><em>Source: Apache Flink</em></p>

<a name="Types-of-Windows-in-Flink"></a>
<h2>Types of Windows in Flink</h2>

<a name="Tumbling-Windows"></a>
<h3>Tumbling Windows</h3>

<p>Tumbling windows are fixed-size, non-overlapping windows. Each event belongs to exactly one window.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// your event stream</span>
</span><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">windowedStream</span> <span class="o">=</span> <span class="n">stream</span>
</span><span class='line'>    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
</span><span class='line'>    <span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="k">new</span> <span class="n">WindowFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">,</span> <span class="n">WindowedEvent</span><span class="o">,</span> <span class="n">Key</span><span class="o">,</span> <span class="n">TimeWindow</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">apply</span><span class="o">(</span><span class="n">Key</span> <span class="n">key</span><span class="o">,</span> <span class="n">TimeWindow</span> <span class="n">window</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">input</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="c1">// Window processing logic</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Sliding-Windows"></a>
<h3>Sliding Windows</h3>

<p>Sliding windows are also fixed-size but can overlap. Each event can belong to multiple windows depending on the slide interval.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span>
</span><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">windowedStream</span> <span class="o">=</span> <span class="n">stream</span>
</span><span class='line'>    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">SlidingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">),</span> <span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
</span><span class='line'>    <span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="k">new</span> <span class="n">WindowFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">,</span> <span class="n">WindowedEvent</span><span class="o">,</span> <span class="n">Key</span><span class="o">,</span> <span class="n">TimeWindow</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">apply</span><span class="o">(</span><span class="n">Key</span> <span class="n">key</span><span class="o">,</span> <span class="n">TimeWindow</span> <span class="n">window</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">input</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="c1">// Window processing logic</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>




<!--more-->


<a name="Session-Windows"></a>
<h3>Session Windows</h3>

<p>Session windows group events that arrive close to each other, with a session gap defining the threshold for grouping.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span>
</span><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">windowedStream</span> <span class="o">=</span> <span class="n">stream</span>
</span><span class='line'>    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">ProcessingTimeSessionWindows</span><span class="o">.</span><span class="na">withGap</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">minutes</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
</span><span class='line'>    <span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="k">new</span> <span class="n">WindowFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">,</span> <span class="n">WindowedEvent</span><span class="o">,</span> <span class="n">Key</span><span class="o">,</span> <span class="n">TimeWindow</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">apply</span><span class="o">(</span><span class="n">Key</span> <span class="n">key</span><span class="o">,</span> <span class="n">TimeWindow</span> <span class="n">window</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">input</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="c1">// Window processing logic</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Global-Windows"></a>
<h3>Global Windows</h3>

<p>Global windows group all elements with the same key into a single window. These windows require custom triggers to define when to produce results.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span>
</span><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">windowedStream</span> <span class="o">=</span> <span class="n">stream</span>
</span><span class='line'>    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">GlobalWindows</span><span class="o">.</span><span class="na">create</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">trigger</span><span class="o">(</span><span class="n">CountTrigger</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="mi">100</span><span class="o">))</span> <span class="c1">// Triggering every 100 events</span>
</span><span class='line'>    <span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="k">new</span> <span class="n">WindowFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">,</span> <span class="n">WindowedEvent</span><span class="o">,</span> <span class="n">Key</span><span class="o">,</span> <span class="n">TimeWindow</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">apply</span><span class="o">(</span><span class="n">Key</span> <span class="n">key</span><span class="o">,</span> <span class="n">TimeWindow</span> <span class="n">window</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">input</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="c1">// Window processing logic</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Assigning-Timestamps-and-Generating-Watermarks"></a>
<h2>Assigning Timestamps and Generating Watermarks</h2>

<p>For event-time windowing, it&rsquo;s crucial to assign timestamps to events and generate watermarks.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span>
</span><span class='line'><span class="n">WatermarkStrategy</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">watermarkStrategy</span> <span class="o">=</span> <span class="n">WatermarkStrategy</span>
</span><span class='line'>    <span class="o">.&lt;</span><span class="n">Event</span><span class="o">&gt;</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="n">Duration</span><span class="o">.</span><span class="na">ofSeconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
</span><span class='line'>    <span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">(</span><span class="k">new</span> <span class="n">SerializableTimestampAssigner</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">long</span> <span class="nf">extractTimestamp</span><span class="o">(</span><span class="n">Event</span> <span class="n">event</span><span class="o">,</span> <span class="kt">long</span> <span class="n">recordTimestamp</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">return</span> <span class="n">event</span><span class="o">.</span><span class="na">getTimestamp</span><span class="o">();</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">});</span>
</span><span class='line'>
</span><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">timestampedStream</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="n">watermarkStrategy</span><span class="o">);</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Example:-Tumbling-Window-with-Event-Time"></a>
<h2>Example: Tumbling Window with Event Time</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.eventtime.SerializableTimestampAssigner</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.eventtime.WatermarkStrategy</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.datastream.DataStream</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.time.Time</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.windowing.windows.TimeWindow</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.util.Collector</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">TumblingWindowExample</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>        <span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nf">EventSource</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">WatermarkStrategy</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">watermarkStrategy</span> <span class="o">=</span> <span class="n">WatermarkStrategy</span>
</span><span class='line'>            <span class="o">.&lt;</span><span class="n">Event</span><span class="o">&gt;</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="n">Duration</span><span class="o">.</span><span class="na">ofSeconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
</span><span class='line'>            <span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">(</span><span class="k">new</span> <span class="n">SerializableTimestampAssigner</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>                <span class="nd">@Override</span>
</span><span class='line'>                <span class="kd">public</span> <span class="kt">long</span> <span class="nf">extractTimestamp</span><span class="o">(</span><span class="n">Event</span> <span class="n">event</span><span class="o">,</span> <span class="kt">long</span> <span class="n">recordTimestamp</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>                    <span class="k">return</span> <span class="n">event</span><span class="o">.</span><span class="na">getTimestamp</span><span class="o">();</span>
</span><span class='line'>                <span class="o">}</span>
</span><span class='line'>            <span class="o">});</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">timestampedStream</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="n">watermarkStrategy</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">timestampedStream</span>
</span><span class='line'>            <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>            <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
</span><span class='line'>            <span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="k">new</span> <span class="n">WindowFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">,</span> <span class="n">WindowedEvent</span><span class="o">,</span> <span class="n">String</span><span class="o">,</span> <span class="n">TimeWindow</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>                <span class="nd">@Override</span>
</span><span class='line'>                <span class="kd">public</span> <span class="kt">void</span> <span class="nf">apply</span><span class="o">(</span><span class="n">String</span> <span class="n">key</span><span class="o">,</span> <span class="n">TimeWindow</span> <span class="n">window</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">input</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">WindowedEvent</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>                    <span class="c1">// Window processing logic</span>
</span><span class='line'>                    <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="k">new</span> <span class="nf">WindowedEvent</span><span class="o">(</span><span class="n">key</span><span class="o">,</span> <span class="n">window</span><span class="o">,</span> <span class="n">input</span><span class="o">));</span>
</span><span class='line'>                <span class="o">}</span>
</span><span class='line'>            <span class="o">})</span>
</span><span class='line'>            <span class="o">.</span><span class="na">print</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Tumbling Window Example&quot;</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Benefits-of-Windowing"></a>
<h2>Benefits of Windowing</h2>

<p><strong>Temporal Aggregation</strong>: Windows allow you to perform aggregations and computations over specific time intervals, essential for real-time analytics and monitoring.</p>

<p><strong>Handling Out-of-Order Events</strong>: With proper windowing and watermarking, Flink can handle out-of-order events and ensure accurate results.</p>

<p><strong>Scalability</strong>: Windowed operations can be distributed and parallelized, making it feasible to process large-scale data streams efficiently.</p>

<p><strong>Flexibility</strong>: Flink&rsquo;s windowing system is highly flexible, supporting various window types and custom triggers, catering to a wide range of use cases.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Windowing in Apache Flink is a versatile and powerful feature that enables the processing of continuous data streams in meaningful chunks. By utilizing different types of windows and configuring them appropriately, you can implement robust real-time data processing pipelines that handle time-based computations effectively.</p>

<p>For more detailed information, you can refer to the <a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/datastream/operators/windows/">Apache Flink Documentation on Windowing</a> and <a href="https://rishijeet.github.io/blog/understanding-event-time-in-apache-flink">Understanding Event Time in Apache Flink</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Watermarks in Apache Flink]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/understanding-watermarks-in-apache-flink/"/>
    <updated>2024-05-19T20:35:48+05:30</updated>
    <id>https://rishijeet.github.io/blog/understanding-watermarks-in-apache-flink</id>
    <content type="html"><![CDATA[<a name="What-are-Watermarks-3f-"></a>
<h2>What are Watermarks?</h2>

<p>Watermarks in Apache Flink are a mechanism to handle event time and out-of-order events in stream processing. They represent a point in time in the data stream and indicate that no events with timestamps earlier than the watermark should be expected. Essentially, watermarks help Flink understand the progress of event time in the stream and trigger computations like window operations based on this understanding.</p>

<ul>
<li><strong>Event Time</strong> Event Time is the time at which events actually occurred, as recorded in the event data itself. For more detailed information, you can refer to the <a href="https://rishijeet.github.io/blog/understanding-event-time-in-apache-flink">Understanding Event Time in Apache Flink</a></li>
<li><strong>Ingestion Time</strong> Ingestion Time is the time when events enter the Flink pipeline.</li>
<li><strong>Processing Time</strong> Processing Time is the time when events are processed by Flink.</li>
</ul>


<a name="Watermarks"></a>
<h3>Watermarks</h3>

<ul>
<li><strong>Definition</strong>: A watermark is a timestamp that flows as part of the data stream and denotes the progress of event time.</li>
<li><strong>Purpose</strong>: Watermarks help in handling late events and triggering event-time-based operations like windowing.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/stream_watermark_in_order.svg" height="300" width="900" alt="Alt text" /><em>Source: Apache Flink</em></p>

<p><img src="https://rishijeet.github.io/images/stream_watermark_out_of_order.svg" height="300" width="900" alt="Alt text" /><em>Source: Apache Flink</em></p>

<!--more-->


<a name="Generating-Watermarks"></a>
<h2>Generating Watermarks</h2>

<p>Watermarks can be generated in two main ways:</p>

<p><strong>Punctuated Watermarks</strong>: These are emitted at specific points in the stream, often when certain events are encountered.</p>

<p><strong>Periodic Watermarks</strong>: These are emitted at regular intervals.</p>

<a name="Example-of-Watermark-Generation"></a>
<h3>Example of Watermark Generation</h3>

<p>Here’s a code example demonstrating how to assign timestamps and generate watermarks using periodic watermarks:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.eventtime.SerializableTimestampAssigner</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.eventtime.WatermarkGenerator</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.eventtime.WatermarkGeneratorSupplier</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.api.common.eventtime.WatermarkStrategy</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.datastream.DataStream</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.functions.source.SourceFunction</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.flink.streaming.api.watermark.Watermark</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WatermarkExample</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>        <span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nf">EventSource</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">WatermarkStrategy</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">watermarkStrategy</span> <span class="o">=</span> <span class="n">WatermarkStrategy</span>
</span><span class='line'>            <span class="o">.&lt;</span><span class="n">Event</span><span class="o">&gt;</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="n">Duration</span><span class="o">.</span><span class="na">ofSeconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
</span><span class='line'>            <span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">(</span><span class="k">new</span> <span class="n">SerializableTimestampAssigner</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>                <span class="nd">@Override</span>
</span><span class='line'>                <span class="kd">public</span> <span class="kt">long</span> <span class="nf">extractTimestamp</span><span class="o">(</span><span class="n">Event</span> <span class="n">event</span><span class="o">,</span> <span class="kt">long</span> <span class="n">recordTimestamp</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>                    <span class="k">return</span> <span class="n">event</span><span class="o">.</span><span class="na">getTimestamp</span><span class="o">();</span>
</span><span class='line'>                <span class="o">}</span>
</span><span class='line'>            <span class="o">});</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">watermarkedStream</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="n">watermarkStrategy</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">watermarkedStream</span>
</span><span class='line'>            <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>            <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
</span><span class='line'>            <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="nf">EventTimeWindowFunction</span><span class="o">())</span>
</span><span class='line'>            <span class="o">.</span><span class="na">print</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Watermark Example&quot;</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Example-Source-Function"></a>
<h3>Example Source Function</h3>

<p>Here’s a simple source function generating events with timestamps:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">EventSource</span> <span class="kd">implements</span> <span class="n">SourceFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">private</span> <span class="kd">volatile</span> <span class="kt">boolean</span> <span class="n">running</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">(</span><span class="n">SourceContext</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">ctx</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">while</span> <span class="o">(</span><span class="n">running</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="kt">long</span> <span class="n">timestamp</span> <span class="o">=</span> <span class="n">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
</span><span class='line'>            <span class="n">ctx</span><span class="o">.</span><span class="na">collectWithTimestamp</span><span class="o">(</span><span class="k">new</span> <span class="nf">Event</span><span class="o">(</span><span class="s">&quot;key&quot;</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">),</span> <span class="n">timestamp</span><span class="o">);</span>
</span><span class='line'>            <span class="n">ctx</span><span class="o">.</span><span class="na">emitWatermark</span><span class="o">(</span><span class="k">new</span> <span class="nf">Watermark</span><span class="o">(</span><span class="n">timestamp</span> <span class="o">-</span> <span class="mi">5000</span><span class="o">));</span>
</span><span class='line'>            <span class="n">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">100</span><span class="o">);</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">cancel</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">running</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Handling-Parallel-Streams"></a>
<h2>Handling Parallel Streams</h2>

<p>In a distributed environment, Flink processes streams in parallel. Each parallel sub-task can emit its own watermarks. Flink uses the minimum watermark of all parallel sub-tasks to ensure that no events are missed.</p>

<p><img src="https://rishijeet.github.io/images/parallel_streams_watermarks.svg" height="300" width="900" alt="Alt text" /><em>Source: Apache Flink</em></p>

<a name="Example-of-Parallel-Watermark-Handling"></a>
<h3>Example of Parallel Watermark Handling</h3>

<p>When using parallel streams, each sub-task generates its watermarks, and Flink computes the minimum watermark across all sub-tasks. This is crucial to correctly handle late events and ensure accurate window computations.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nf">ParallelEventSource</span><span class="o">()).</span><span class="na">setParallelism</span><span class="o">(</span><span class="mi">4</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="n">WatermarkStrategy</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">watermarkStrategy</span> <span class="o">=</span> <span class="n">WatermarkStrategy</span>
</span><span class='line'>    <span class="o">.&lt;</span><span class="n">Event</span><span class="o">&gt;</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="n">Duration</span><span class="o">.</span><span class="na">ofSeconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
</span><span class='line'>    <span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">(</span><span class="k">new</span> <span class="n">SerializableTimestampAssigner</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">long</span> <span class="nf">extractTimestamp</span><span class="o">(</span><span class="n">Event</span> <span class="n">event</span><span class="o">,</span> <span class="kt">long</span> <span class="n">recordTimestamp</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">return</span> <span class="n">event</span><span class="o">.</span><span class="na">getTimestamp</span><span class="o">();</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">});</span>
</span><span class='line'>
</span><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">watermarkedStream</span> <span class="o">=</span> <span class="n">stream</span><span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="n">watermarkStrategy</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="n">watermarkedStream</span>
</span><span class='line'>    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
</span><span class='line'>    <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="nf">EventTimeWindowFunction</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">print</span><span class="o">();</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Watermark-Strategy-for-Parallel-Sources"></a>
<h3>Watermark Strategy for Parallel Sources</h3>

<p>Here&rsquo;s an example of a parallel source function generating events and watermarks:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">ParallelEventSource</span> <span class="kd">extends</span> <span class="n">RichParallelSourceFunction</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">private</span> <span class="kd">volatile</span> <span class="kt">boolean</span> <span class="n">running</span> <span class="o">=</span> <span class="kc">true</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">(</span><span class="n">SourceContext</span><span class="o">&lt;</span><span class="n">Event</span><span class="o">&gt;</span> <span class="n">ctx</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">while</span> <span class="o">(</span><span class="n">running</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="kt">long</span> <span class="n">timestamp</span> <span class="o">=</span> <span class="n">System</span><span class="o">.</span><span class="na">currentTimeMillis</span><span class="o">();</span>
</span><span class='line'>            <span class="n">ctx</span><span class="o">.</span><span class="na">collectWithTimestamp</span><span class="o">(</span><span class="k">new</span> <span class="nf">Event</span><span class="o">(</span><span class="s">&quot;key&quot;</span><span class="o">,</span> <span class="n">timestamp</span><span class="o">),</span> <span class="n">timestamp</span><span class="o">);</span>
</span><span class='line'>            <span class="n">ctx</span><span class="o">.</span><span class="na">emitWatermark</span><span class="o">(</span><span class="k">new</span> <span class="nf">Watermark</span><span class="o">(</span><span class="n">timestamp</span> <span class="o">-</span> <span class="mi">5000</span><span class="o">));</span>
</span><span class='line'>            <span class="n">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">100</span><span class="o">);</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">cancel</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">running</span> <span class="o">=</span> <span class="kc">false</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Benefits-of-Watermarks"></a>
<h2>Benefits of Watermarks</h2>

<p> <strong>Handling Late Data</strong>: Watermarks allow the system to process late events and include them in the correct windows, ensuring completeness and accuracy.</p>

<p><strong>Event Time Processing</strong>: With watermarks, Flink can process events based on their actual occurrence time, making it suitable for applications where timing is critical.</p>

<p><strong>Out-of-Order Event Handling</strong>: Watermarks enable Flink to handle out-of-order events gracefully by providing a tolerance for lateness.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Watermarks are a critical component in Apache Flink for dealing with event time and out-of-order data. By generating and using watermarks, Flink can accurately perform time-based computations like windowing and aggregations, even in the presence of late-arriving events. This makes Flink a powerful tool for real-time stream processing applications.</p>

<p>For more detailed information, you can refer to the <a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/datastream/event_time/">Apache Flink Documentation on Watermarks</a> and <a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/concepts/time/">Event Time</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Event Time in Apache Flink]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/understanding-event-time-in-apache-flink/"/>
    <updated>2024-05-19T20:22:47+05:30</updated>
    <id>https://rishijeet.github.io/blog/understanding-event-time-in-apache-flink</id>
    <content type="html"><![CDATA[<a name="What-is-Event-Time-3f-"></a>
<h3>What is Event Time?</h3>

<p>Event Time is one of the three time semantics in Apache Flink, along with Ingestion Time and Processing Time. Event Time refers to the time at which each individual event actually occurred, typically extracted from the event itself. This contrasts with Processing Time, which refers to the time at which events are processed by the Flink system, and Ingestion Time, which is the time at which events enter the Flink pipeline.</p>

<p><img src="https://rishijeet.github.io/images/event_processing_time.svg" height="300" width="900" alt="Alt text" /><em>Source: Apache Flink</em></p>

<a name="Key-Features-of-Event-Time:"></a>
<h3>Key Features of Event Time:</h3>

<p><strong>Timestamp Extraction</strong>: In Event Time, each event must have a timestamp that indicates when the event occurred. This timestamp is extracted from the event data itself.</p>

<p><strong>Watermarks</strong>: Watermarks are a mechanism used to track progress in Event Time. They are special timestamps that indicate that no events with a timestamp older than the watermark should be expected. Watermarks allow Flink to handle late-arriving data and trigger computations when it is safe to assume all relevant data has been processed. For more detailed information, you can refer to the <a href="https://rishijeet.github.io/blog/understanding-watermarks-in-apache-flink">Understanding Watermarks in Apache Flink</a></p>

<p><strong>Windowing</strong>: Event Time is crucial for windowed operations. Windows (e.g., tumbling, sliding, session windows) in Flink can be defined based on Event Time, ensuring that events are grouped according to when they actually occurred.</p>

<!-- more -->


<a name="Benefits-of-Using-Event-Time"></a>
<h2>Benefits of Using Event Time</h2>

<p><strong>Accuracy in Time-Based Operations</strong>:</p>

<ul>
<li> Using Event Time allows for more accurate and reliable time-based operations, such as windowed aggregations, joins, and pattern detections. This is because the operations are based on the actual occurrence time of events, rather than the time they are processed.</li>
</ul>


<p><strong>Handling Out-of-Order Events</strong>:</p>

<ul>
<li> Real-world data streams often have events that arrive out of order. With Event Time and watermarks, Flink can manage out-of-order events effectively. Watermarks help to delay processing just enough to account for late events without significant delays, ensuring completeness and correctness in the results.</li>
</ul>


<p><strong>Consistency Across Distributed Systems</strong>:</p>

<ul>
<li> In distributed systems, processing time can vary significantly across different nodes due to network latency, load balancing, and other factors. Event Time provides a consistent temporal reference across all nodes, ensuring that operations like windowing produce consistent results regardless of where or when events are processed.</li>
</ul>


<p><strong>Improved Late Data Handling</strong>:</p>

<ul>
<li> By leveraging watermarks, Flink can handle late-arriving data more gracefully. You can define how much lateness to tolerate and what actions to take for late data, allowing for flexible and robust processing pipelines that can deal with real-world stream data issues.</li>
</ul>


<a name="Extracting-Timestamps-and-Generating-Watermarks"></a>
<h3>Extracting Timestamps and Generating Watermarks</h3>

<p>To use Event Time in Flink, you typically need to:</p>

<p><strong>Assign Timestamps</strong>: Extract the event timestamps from the incoming data.</p>

<p><strong>Generate Watermarks</strong>: Define a strategy for generating watermarks that dictate the event-time progress.</p>

<p>Here’s an example in Java:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">MyEvent</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nf">MyEventSource</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'><span class="n">stream</span>
</span><span class='line'>    <span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="k">new</span> <span class="n">AssignerWithPunctuatedWatermarks</span><span class="o">&lt;</span><span class="n">MyEvent</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">long</span> <span class="nf">extractTimestamp</span><span class="o">(</span><span class="n">MyEvent</span> <span class="n">element</span><span class="o">,</span> <span class="kt">long</span> <span class="n">previousElementTimestamp</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">return</span> <span class="n">element</span><span class="o">.</span><span class="na">getTimestamp</span><span class="o">();</span> <span class="c1">// Extract timestamp from event</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="n">Watermark</span> <span class="nf">checkAndGetNextWatermark</span><span class="o">(</span><span class="n">MyEvent</span> <span class="n">lastElement</span><span class="o">,</span> <span class="kt">long</span> <span class="n">extractedTimestamp</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">return</span> <span class="k">new</span> <span class="nf">Watermark</span><span class="o">(</span><span class="n">extractedTimestamp</span> <span class="o">-</span> <span class="mi">1</span><span class="o">);</span> <span class="c1">// Generate watermark</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">})</span>
</span><span class='line'>    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
</span><span class='line'>    <span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="k">new</span> <span class="n">WindowFunction</span><span class="o">&lt;</span><span class="n">MyEvent</span><span class="o">,</span> <span class="n">ResultType</span><span class="o">,</span> <span class="n">KeyType</span><span class="o">,</span> <span class="n">TimeWindow</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">apply</span><span class="o">(</span><span class="n">KeyType</span> <span class="n">key</span><span class="o">,</span> <span class="n">TimeWindow</span> <span class="n">window</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">MyEvent</span><span class="o">&gt;</span> <span class="n">input</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">ResultType</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="c1">// Process windowed events</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">});</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Using-Event-Time-Windows"></a>
<h3>Using Event Time Windows</h3>

<p>Flink supports various types of windows based on Event Time:</p>

<ul>
<li><strong>Tumbling Windows</strong>: Fixed-size, non-overlapping windows.</li>
<li><strong>Sliding Windows</strong>: Fixed-size windows that can overlap.</li>
<li><strong>Session Windows</strong>: Variable-sized windows that group events based on session gaps.</li>
</ul>


<p>Example of a tumbling window in Event Time:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">MyEvent</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...;</span> <span class="c1">// Your event stream</span>
</span><span class='line'>
</span><span class='line'><span class="n">stream</span>
</span><span class='line'>    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">event</span> <span class="o">-&gt;</span> <span class="n">event</span><span class="o">.</span><span class="na">getKey</span><span class="o">())</span>
</span><span class='line'>    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
</span><span class='line'>    <span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="s">&quot;value&quot;</span><span class="o">);</span> <span class="c1">// Aggregation function</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Event Time in Apache Flink is essential for accurately processing and analyzing time-based event streams. By utilizing timestamps extracted from the events and managing time progress through watermarks, Flink ensures precise and consistent stream processing even in the presence of out-of-order and late-arriving events. This makes Event Time invaluable for real-world applications where timing accuracy is critical.</p>

<p>For more detailed information, you can refer to the <a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/concepts/time/">Apache Flink Documentation on Event Time</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Broadcast State Pattern in Flink for Fraud Detection]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/using-broadcast-state-pattern-in-flink-for-fraud-detection/"/>
    <updated>2024-05-19T19:47:48+05:30</updated>
    <id>https://rishijeet.github.io/blog/using-broadcast-state-pattern-in-flink-for-fraud-detection</id>
    <content type="html"><![CDATA[<p>The Broadcast State Pattern in Apache Flink is a powerful feature for real-time stream processing, particularly useful for scenarios like fraud detection. This pattern allows you to maintain a shared state that can be updated and accessed by multiple parallel instances of a stream processing operator. Here&rsquo;s how it can be applied to fraud detection:</p>

<a name="Key-Concepts-of-the-Broadcast-State-Pattern"></a>
<h2>Key Concepts of the Broadcast State Pattern</h2>

<p><strong>Broadcast State</strong>: This is a state that is shared across all parallel instances of an operator. It is used to store information that needs to be accessible to all instances, such as configuration data or rules for fraud detection.</p>

<p><strong>Regular (Non-Broadcast) Streams</strong>: These streams carry the main data that needs to be processed, such as transaction events.</p>

<p><strong>Broadcast Streams</strong>: These streams carry the state updates, such as new fraud detection rules or updates to existing rules.</p>

<a name="Steps-to-Implement-Fraud-Detection-Using-Broadcast-State-Pattern"></a>
<h2>Steps to Implement Fraud Detection Using Broadcast State Pattern</h2>

<p><strong>Define the Broadcast State</strong>:</p>

<ul>
<li> Define the data structure that will hold the fraud detection rules.</li>
<li> For example, a map where the key is a rule identifier and the value is the rule details.</li>
</ul>


<p><strong>Create the Broadcast Stream</strong>:</p>

<ul>
<li> This stream will carry the updates to the fraud detection rules.</li>
<li> Use <code>BroadcastStream</code> to broadcast this stream to all parallel instances of the operator that processes the transactions.</li>
</ul>


<!-- more -->


<p><strong>Process the Broadcast State</strong>:</p>

<ul>
<li> Implement a <code>BroadcastProcessFunction</code> that handles both the main transaction stream and the broadcast rule updates.</li>
<li> In the <code>processBroadcastElement</code> method, update the broadcast state with new or modified rules.</li>
<li> In the <code>processElement</code> method, access the broadcast state to apply the current fraud detection rules to each transaction.</li>
</ul>


<p><strong>Apply Fraud Detection Logic</strong>:</p>

<ul>
<li> As each transaction event arrives, use the current set of fraud detection rules stored in the broadcast state to determine if the transaction is potentially fraudulent.</li>
</ul>


<a name="Example-Implementation"></a>
<h2>Example Implementation</h2>

<p>Here&rsquo;s a simplified example (I have used Java as an example but works with other programming languages too ) of how you might implement this in Flink:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="c1">// Define a data structure for fraud detection rules</span>
</span><span class='line'><span class="kd">class</span> <span class="nc">FraudDetectionRule</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">String</span> <span class="n">ruleId</span><span class="o">;</span>
</span><span class='line'>    <span class="n">String</span> <span class="n">ruleDetails</span><span class="o">;</span>
</span><span class='line'>    <span class="c1">// Other relevant fields and methods</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Create the main transaction stream</span>
</span><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Transaction</span><span class="o">&gt;</span> <span class="n">transactionStream</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nf">TransactionSource</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Create the broadcast stream for fraud detection rules</span>
</span><span class='line'><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">FraudDetectionRule</span><span class="o">&gt;</span> <span class="n">ruleStream</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nf">RuleSource</span><span class="o">());</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Define the broadcast state descriptor</span>
</span><span class='line'><span class="n">MapStateDescriptor</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">FraudDetectionRule</span><span class="o">&gt;</span> <span class="n">ruleStateDescriptor</span> <span class="o">=</span>
</span><span class='line'>    <span class="k">new</span> <span class="n">MapStateDescriptor</span><span class="o">&lt;&gt;(</span><span class="s">&quot;FraudRules&quot;</span><span class="o">,</span> <span class="n">String</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">FraudDetectionRule</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Broadcast the rule stream</span>
</span><span class='line'><span class="n">BroadcastStream</span><span class="o">&lt;</span><span class="n">FraudDetectionRule</span><span class="o">&gt;</span> <span class="n">broadcastRuleStream</span> <span class="o">=</span> <span class="n">ruleStream</span><span class="o">.</span><span class="na">broadcast</span><span class="o">(</span><span class="n">ruleStateDescriptor</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Process the streams with a BroadcastProcessFunction</span>
</span><span class='line'><span class="n">transactionStream</span>
</span><span class='line'>    <span class="o">.</span><span class="na">connect</span><span class="o">(</span><span class="n">broadcastRuleStream</span><span class="o">)</span>
</span><span class='line'>    <span class="o">.</span><span class="na">process</span><span class="o">(</span><span class="k">new</span> <span class="n">BroadcastProcessFunction</span><span class="o">&lt;</span><span class="n">Transaction</span><span class="o">,</span> <span class="n">FraudDetectionRule</span><span class="o">,</span> <span class="n">Alert</span><span class="o">&gt;()</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>        <span class="kd">private</span> <span class="n">MapState</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">FraudDetectionRule</span><span class="o">&gt;</span> <span class="n">rulesState</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">open</span><span class="o">(</span><span class="n">Configuration</span> <span class="n">parameters</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">rulesState</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">getMapState</span><span class="o">(</span><span class="n">ruleStateDescriptor</span><span class="o">);</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">processElement</span><span class="o">(</span><span class="n">Transaction</span> <span class="n">transaction</span><span class="o">,</span> <span class="n">ReadOnlyContext</span> <span class="n">ctx</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Alert</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>            <span class="c1">// Apply the current fraud detection rules</span>
</span><span class='line'>            <span class="k">for</span> <span class="o">(</span><span class="n">FraudDetectionRule</span> <span class="n">rule</span> <span class="o">:</span> <span class="n">rulesState</span><span class="o">.</span><span class="na">values</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>                <span class="k">if</span> <span class="o">(</span><span class="n">applyRule</span><span class="o">(</span><span class="n">transaction</span><span class="o">,</span> <span class="n">rule</span><span class="o">))</span> <span class="o">{</span>
</span><span class='line'>                    <span class="n">out</span><span class="o">.</span><span class="na">collect</span><span class="o">(</span><span class="k">new</span> <span class="nf">Alert</span><span class="o">(</span><span class="n">transaction</span><span class="o">,</span> <span class="n">rule</span><span class="o">));</span>
</span><span class='line'>                <span class="o">}</span>
</span><span class='line'>            <span class="o">}</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="nd">@Override</span>
</span><span class='line'>        <span class="kd">public</span> <span class="kt">void</span> <span class="nf">processBroadcastElement</span><span class="o">(</span><span class="n">FraudDetectionRule</span> <span class="n">rule</span><span class="o">,</span> <span class="n">Context</span> <span class="n">ctx</span><span class="o">,</span> <span class="n">Collector</span><span class="o">&lt;</span><span class="n">Alert</span><span class="o">&gt;</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
</span><span class='line'>            <span class="c1">// Update the broadcast state with new or modified rules</span>
</span><span class='line'>            <span class="n">rulesState</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">rule</span><span class="o">.</span><span class="na">ruleId</span><span class="o">,</span> <span class="n">rule</span><span class="o">);</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="kd">private</span> <span class="kt">boolean</span> <span class="nf">applyRule</span><span class="o">(</span><span class="n">Transaction</span> <span class="n">transaction</span><span class="o">,</span> <span class="n">FraudDetectionRule</span> <span class="n">rule</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="c1">// Implement rule logic here</span>
</span><span class='line'>            <span class="k">return</span> <span class="kc">false</span><span class="o">;</span> <span class="c1">// Example placeholder</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>    <span class="o">});</span>
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<a name="Benefits-of-Using-Broadcast-State-Pattern"></a>
<h2>Benefits of Using Broadcast State Pattern</h2>

<p> <strong>Consistency:</strong>Ensures all instances have a consistent view of the rules.</p>

<p> <strong>Scalability:</strong> Can handle high-throughput streams by distributing the workload across multiple parallel instances.</p>

<p><strong>Flexibility:</strong> Rules can be dynamically updated without stopping the stream processing.</p>

<p>By leveraging the Broadcast State Pattern, you can efficiently manage and apply real-time fraud detection rules across your entire data stream, ensuring timely and accurate detection of fraudulent activities.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Efficient Thread Handling in Rust: A Deep Dive]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/efficient-thread-handling-in-rust-a-deep-dive/"/>
    <updated>2024-04-16T19:43:17+05:30</updated>
    <id>https://rishijeet.github.io/blog/efficient-thread-handling-in-rust-a-deep-dive</id>
    <content type="html"><![CDATA[<p>Concurrency is a fundamental aspect of modern software development, and Rust provides robust abstractions for managing concurrent tasks through its ownership and borrowing system. Threads, a primary mechanism for concurrent programming in Rust, can be efficiently handled using various features and best practices. In this article, we will explore the basics of thread handling in Rust, ownership, and thread safety, as well as practical examples to illustrate efficient concurrent programming.</p>

<a name="Basics-of-Threads-in-Rust"></a>
<h2>Basics of Threads in Rust</h2>

<p>Rust&rsquo;s standard library provides the <code>std::thread</code> module for working with threads. To create a new thread, the <code>std::thread::spawn</code> function is used, taking a closure that represents the code to be executed in the new thread.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='rust'><span class='line'><span class="kn">use</span> <span class="n">std</span><span class="o">::</span><span class="n">thread</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">fn</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="kd">let</span> <span class="n">handle</span> <span class="o">=</span> <span class="n">thread</span><span class="o">::</span><span class="nb">spawn</span><span class="p">(</span><span class="o">||</span> <span class="p">{</span>
</span><span class='line'>        <span class="c1">// Code to be executed in the new thread</span>
</span><span class='line'>    <span class="p">});</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Do other work in the main thread</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Wait for the spawned thread to finish</span>
</span><span class='line'>    <span class="n">handle</span><span class="p">.</span><span class="n">join</span><span class="p">().</span><span class="n">unwrap</span><span class="p">();</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>




<!-- more -->


<a name="Ownership-and-Thread-Safety"></a>
<h2>Ownership and Thread Safety</h2>

<p>Rust&rsquo;s ownership system plays a pivotal role in ensuring thread safety. Data races are prevented, and shared mutable state is carefully managed through ownership and borrowing. Each thread has its stack, and data is not shared unless explicitly specified. The ownership and borrowing rules prevent data races and ensure that mutable data is accessed safely.</p>

<p>However, when shared state is necessary, Rust provides synchronization primitives such as <code>Mutex</code>, <code>Arc</code> (atomic reference counting), and <code>RwLock</code> to manage shared mutable state safely. The following example uses a <code>Mutex</code> to protect a shared counter:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='rust'><span class='line'><span class="kn">use</span> <span class="n">std</span><span class="o">::</span><span class="n">sync</span><span class="o">::</span><span class="p">{</span><span class="n">Mutex</span><span class="p">,</span> <span class="n">Arc</span><span class="p">};</span>
</span><span class='line'><span class="kn">use</span> <span class="n">std</span><span class="o">::</span><span class="n">thread</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">fn</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="kd">let</span> <span class="n">counter</span> <span class="o">=</span> <span class="n">Arc</span><span class="o">::</span><span class="n">new</span><span class="p">(</span><span class="n">Mutex</span><span class="o">::</span><span class="n">new</span><span class="p">(</span><span class="mi">0</span><span class="p">));</span>
</span><span class='line'>    <span class="kd">let</span> <span class="k">mut</span> <span class="n">handles</span> <span class="o">=</span> <span class="n">vec</span><span class="o">!</span><span class="p">[];</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="mf">0.</span><span class="p">.</span><span class="mi">10</span> <span class="p">{</span>
</span><span class='line'>        <span class="kd">let</span> <span class="n">counter</span> <span class="o">=</span> <span class="n">Arc</span><span class="o">::</span><span class="n">clone</span><span class="p">(</span><span class="o">&amp;</span><span class="n">counter</span><span class="p">);</span>
</span><span class='line'>        <span class="kd">let</span> <span class="n">handle</span> <span class="o">=</span> <span class="n">thread</span><span class="o">::</span><span class="nb">spawn</span><span class="p">(</span><span class="n">move</span> <span class="o">||</span> <span class="p">{</span>
</span><span class='line'>            <span class="kd">let</span> <span class="k">mut</span> <span class="n">num</span> <span class="o">=</span> <span class="n">counter</span><span class="p">.</span><span class="n">lock</span><span class="p">().</span><span class="n">unwrap</span><span class="p">();</span>
</span><span class='line'>            <span class="o">*</span><span class="n">num</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
</span><span class='line'>        <span class="p">});</span>
</span><span class='line'>        <span class="n">handles</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">for</span> <span class="n">handle</span> <span class="k">in</span> <span class="n">handles</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">handle</span><span class="p">.</span><span class="n">join</span><span class="p">().</span><span class="n">unwrap</span><span class="p">();</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nb">println</span><span class="o">!</span><span class="p">(</span><span class="s">&quot;Result: {}&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">counter</span><span class="p">.</span><span class="n">lock</span><span class="p">().</span><span class="n">unwrap</span><span class="p">());</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here, the <code>Mutex</code> ensures exclusive access to the shared counter, preventing multiple threads from updating it simultaneously.</p>

<a name="Message-Passing"></a>
<h2>Message Passing</h2>

<p>Rust&rsquo;s channels provide a powerful mechanism for communication between threads. The <code>std::sync::mpsc</code> module offers multiple-producer, single-consumer channels. The following example demonstrates message passing using channels:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='rust'><span class='line'><span class="kn">use</span> <span class="n">std</span><span class="o">::</span><span class="n">sync</span><span class="o">::</span><span class="n">mpsc</span><span class="p">;</span>
</span><span class='line'><span class="kn">use</span> <span class="n">std</span><span class="o">::</span><span class="n">thread</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">fn</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="kd">let</span> <span class="p">(</span><span class="n">sender</span><span class="p">,</span> <span class="n">receiver</span><span class="p">)</span> <span class="o">=</span> <span class="n">mpsc</span><span class="o">::</span><span class="n">channel</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">let</span> <span class="n">handle</span> <span class="o">=</span> <span class="n">thread</span><span class="o">::</span><span class="nb">spawn</span><span class="p">(</span><span class="n">move</span> <span class="o">||</span> <span class="p">{</span>
</span><span class='line'>        <span class="kd">let</span> <span class="n">val</span> <span class="o">=</span> <span class="n">String</span><span class="o">::</span><span class="n">from</span><span class="p">(</span><span class="s">&quot;Hello from the spawned thread&quot;</span><span class="p">);</span>
</span><span class='line'>        <span class="n">sender</span><span class="p">.</span><span class="n">send</span><span class="p">(</span><span class="n">val</span><span class="p">).</span><span class="n">unwrap</span><span class="p">();</span>
</span><span class='line'>    <span class="p">});</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Do work in the main thread</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">let</span> <span class="n">received</span> <span class="o">=</span> <span class="n">receiver</span><span class="p">.</span><span class="n">recv</span><span class="p">().</span><span class="n">unwrap</span><span class="p">();</span>
</span><span class='line'>    <span class="nb">println</span><span class="o">!</span><span class="p">(</span><span class="s">&quot;Received: {}&quot;</span><span class="p">,</span> <span class="n">received</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">handle</span><span class="p">.</span><span class="n">join</span><span class="p">().</span><span class="n">unwrap</span><span class="p">();</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here, the <code>sender</code> and <code>receiver</code> allow communication between the main thread and the spawned thread, and the <code>recv</code> method blocks until a message is received.</p>

<a name="Thread-Pooling-for-Scalability"></a>
<h2>Thread Pooling for Scalability</h2>

<p>Creating a new thread for every concurrent task can lead to inefficiencies due to the associated overhead. Thread pooling, a technique where a fixed number of threads are reused to execute tasks, can enhance performance. The <code>rayon</code> crate provides an elegant interface for parallel programming in Rust:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='rust'><span class='line'><span class="kn">use</span> <span class="n">rayon</span><span class="o">::</span><span class="n">prelude</span><span class="o">::*</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="k">fn</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="kd">let</span> <span class="n">data</span> <span class="o">=</span> <span class="n">vec</span><span class="o">!</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">];</span>
</span><span class='line'>    <span class="kd">let</span> <span class="n">result</span><span class="o">:</span> <span class="n">Vec</span><span class="o">&lt;</span><span class="n">_</span><span class="o">&gt;</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">par_iter</span><span class="p">().</span><span class="n">map</span><span class="p">(</span><span class="o">|&amp;</span><span class="n">x</span><span class="o">|</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">).</span><span class="n">collect</span><span class="p">();</span>
</span><span class='line'>
</span><span class='line'>    <span class="nb">println</span><span class="o">!</span><span class="p">(</span><span class="s">&quot;{:?}&quot;</span><span class="p">,</span> <span class="n">result</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>par_iter</code> method from <code>rayon</code> allows parallel iteration over the data, and the <code>map</code> function applies the closure to each element concurrently.</p>

<p>Efficient thread handling in Rust involves leveraging the ownership and borrowing system, using synchronization primitives, embracing message passing, and considering thread pooling for scalability. Rust&rsquo;s focus on safety and performance makes it a compelling choice for concurrent programming, providing the tools necessary to write efficient and reliable concurrent code.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Enhancing Natural Language Processing with Retrieval-Augmented Generation]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/enhancing-natural-language-processing-with-retrieval-augmented-generation/"/>
    <updated>2024-01-13T20:34:07+05:30</updated>
    <id>https://rishijeet.github.io/blog/enhancing-natural-language-processing-with-retrieval-augmented-generation</id>
    <content type="html"><![CDATA[<p>Natural Language Processing (NLP) has witnessed remarkable advancements in recent years, with the advent of sophisticated language models like GPT-3 (Generative Pre-trained Transformer 3). However, one of the challenges that still persists in NLP is the generation of coherent and contextually relevant content. Retrieval-Augmented Generation (RAG) emerges as a powerful solution to address this issue, combining the strengths of both retrieval-based and generation-based approaches.</p>

<a name="Understanding-Retrieval-2d-Augmented-Generation"></a>
<h1>Understanding Retrieval-Augmented Generation</h1>

<p>Retrieval-Augmented Generation is a hybrid approach that integrates the benefits of information retrieval systems with generative models. Let&rsquo;s delve into the mathematical formulations of the key components of RAG.</p>

<p><img src="https://rishijeet.github.io/images/rag_new.png" height="300" width="900" alt="Alt text" /> Figure: Overview of our approach. We combine a pre-trained retriever <em>(Query Encoder + Document Index)</em> with a pre-trained seq2seq model <em>(Generator)</em> and fine-tune end-to-end. For query \(x\), we use Maximum Inner Product Search (MIPS) to find the top-\(K\) documents \(z_i\). For the final prediction \(y\), we treat \(z\) as a latent variable and marginalize over seq2seq predictions given different documents. <em><a href="https://arxiv.org/pdf/2005.11401.pdf">Source: arxiv.org</a></em></p>

<!-- more -->


<a name="L1.-Generative-Model"></a>
<h2>1. Generative Model</h2>

<p>The generative model in RAG is often based on a pre-trained transformer architecture, such as GPT-3. The core functionality involves generating text given a context. Mathematically, the generative model can be represented as:</p>

<p><div>
<span>
\[ P_{\text{gen}}(Y|X) \]
</span>
where \( Y \) is the generated text and \( X \) is the input context. This probability distribution captures the likelihood of generating \( Y \) given \( X \).
<div></p>

<a name="L2.-Retrieval-Model"></a>
<h2>2. Retrieval Model</h2>

<p>The retrieval model is responsible for fetching relevant information from a knowledge base. This can be achieved through techniques like dense retrieval using embeddings. The retrieval model computes the similarity between the input query and the documents in the knowledge base. Mathematically, this can be expressed as:
<div>
\[ \text{argmax}_{d \in \text{KnowledgeBase}} \text{similarity}(Q, \text{Embed}(d)) \]</p>

<p>where \( Q \) is the query, \( \text{KnowledgeBase} \) is the set of documents, \( d \) represents a document, \( \text{Embed}(\cdot) \) denotes the embedding function, and \( \text{similarity}(\cdot) \) measures the similarity between the query and document embeddings.
</div></p>

<a name="L3.-Indexing-Mechanism"></a>
<h2>3. Indexing Mechanism</h2>

<p>Indexing mechanisms play a crucial role in efficiently retrieving information. Commonly, techniques like approximate nearest neighbors are employed. Mathematically, indexing involves mapping documents to a space such that retrieval operations are expedited. This can be represented as:</p>

<div>
&#92;[ \text{Index}(d) \rightarrow \text{Embed}(d) &#92;]

where &#92;( \text{Index}(\cdot) &#92;) denotes the indexing function mapping documents to their embeddings.
</div>


<a name="L4.-Context-2d-Aware-Integration"></a>
<h2>4. Context-Aware Integration</h2>

<p>To integrate retrieved information into the generative process while maintaining context, the retrieval model output needs to be combined with the generative model&rsquo;s output. A simple formulation for context-aware integration can be:</p>

<div>
<span>
&#92;[ P_{\text{final}}(Y|X, Q) = \alpha \cdot P_{\text{gen}}(Y|X) + (1-\alpha) \cdot P_{\text{ret}}(Y|Q) &#92;]
</span>
where &#92;( P_{\text{final}}(Y|X, Q) &#92;) is the final probability distribution of generating &#92;( Y &#92;) given &#92;( X &#92;) and &#92;( Q &#92;), \( \alpha \) is a hyperparameter controlling the balance between generative and retrieval components, and \( P_{\text{ret}}(Y|Q) \) is the probability distribution of generating \( Y \) given the retrieved information \( Q \).
</div>


<a name="Advantages-of-Retrieval-2d-Augmented-Generation"></a>
<h1>Advantages of Retrieval-Augmented Generation</h1>

<ol>
<li><p><strong>Improved Relevance:</strong>
By integrating information retrieval, RAG ensures that the generated content is contextually relevant and grounded in factual accuracy. This is particularly beneficial in applications where precision and relevance are critical, such as question-answering systems.</p></li>
<li><p><strong>Addressing Data Sparsity:</strong>
In scenarios where training data is limited, RAG can leverage external knowledge bases to compensate for the lack of specific information. This makes the model more robust and capable of handling a broader range of topics.</p></li>
<li><p><strong>Contextual Enrichment:</strong>
The retrieval-augmented approach allows for the enrichment of generated content by pulling in relevant details from a diverse set of sources. This not only enhances the quality of the generated text but also broadens the scope of information covered.</p></li>
<li><p><strong>Reduced Ambiguity:</strong>
Integrating retrieval mechanisms helps in disambiguating the meaning of ambiguous terms or phrases by pulling in contextually appropriate information from the knowledge base.</p></li>
</ol>


<a name="Applications-of-Retrieval-2d-Augmented-Generation"></a>
<h1>Applications of Retrieval-Augmented Generation</h1>

<ol>
<li><p><strong>Question Answering Systems:</strong>
RAG is particularly effective in question-answering systems where precise and contextually relevant answers are essential. The retrieval model can fetch information from a knowledge base to support or augment the generative model&rsquo;s response.</p></li>
<li><p><strong>Content Creation:</strong>
In content creation tasks, such as article writing or summarization, RAG can enhance the coherence and factual accuracy of the generated content by pulling in information from external sources.</p></li>
<li><p><strong>Dialog Systems:</strong>
Conversational agents can benefit from RAG by providing more informative and contextually relevant responses. The retrieval model aids in quickly accessing relevant information to support the generative model&rsquo;s output during a conversation.</p></li>
</ol>


<a name="Challenges-and-Future-Directions"></a>
<h1>Challenges and Future Directions</h1>

<p>While Retrieval-Augmented Generation shows great promise, it is not without its challenges. Fine-tuning the balance between the generative and retrieval components, handling diverse knowledge bases, and addressing potential biases in retrieved information are areas that require further research. Additionally, exploring ways to dynamically update the knowledge base during the generative process could open new possibilities for real-time applications.</p>

<p>In conclusion, Retrieval-Augmented Generation represents a significant step forward in enhancing the capabilities of natural language processing systems. By seamlessly integrating the strengths of generative and retrieval models, RAG holds the potential to revolutionize various NLP applications, making them more accurate, contextually aware, and capable of handling a wide range of tasks. As research in this field continues to progress, we can expect even more sophisticated and versatile language models that leverage the best of both worlds.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The AI Horizon: Unveiling the Titans - Gemini, Llama2, Olympus, Ajax, and Orca 2]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/the-ai-horizon-unveiling-the-titans-gemini/"/>
    <updated>2023-12-23T22:49:43+05:30</updated>
    <id>https://rishijeet.github.io/blog/the-ai-horizon-unveiling-the-titans-gemini</id>
    <content type="html"><![CDATA[<a name="Introduction"></a>
<h2>Introduction</h2>

<p>Artificial Intelligence (AI) has witnessed remarkable advancements in recent years, with various tech giants investing heavily in developing large language models (LLMs) to enhance natural language understanding and generation. This article delves into the technical details of Google&rsquo;s Gemini, Meta&rsquo;s Llama2, Amazon&rsquo;s Olympus, Microsoft&rsquo;s Orca 2, and Apple&rsquo;s Ajax.</p>

<a name="Google-Gemini"></a>
<h2>Google Gemini</h2>

<p>Google&rsquo;s Gemini, introduced by Demis Hassabis, CEO and Co-Founder of Google DeepMind, represents a significant leap in AI capabilities. Gemini is a multimodal AI model designed to seamlessly understand and operate across different types of information, including text, code, audio, image, and video.</p>

<p>Gemini is optimized for three different sizes:</p>

<ul>
<li><strong>Gemini Ultra:</strong> The largest and most capable model for highly complex tasks.</li>
<li><strong>Gemini Pro:</strong> The best model for scaling across a wide range of tasks.</li>
<li><strong>Gemini Nano:</strong> The most efficient model for on-device tasks.</li>
</ul>


<p>Gemini Ultra outperforms state-of-the-art results on various benchmarks, including massive multitask language understanding (MMLU) and multimodal benchmarks. With its native multimodality, Gemini excels in complex reasoning tasks, image understanding, and advanced coding across multiple programming languages.</p>

<p>The model is trained using Google&rsquo;s AI-optimized infrastructure, including Tensor Processing Units (TPUs) v4 and v5e. The announcement also introduces Cloud TPU v5p, the most powerful TPU system to date, designed to accelerate the development of large-scale generative AI models.</p>

<p>Gemini reflects Google&rsquo;s commitment to responsibility and safety, incorporating comprehensive safety evaluations, including bias and toxicity assessments. The model&rsquo;s availability spans various Google products and platforms, with plans for further integration and expansion.</p>

<a name="Meta-Llama2"></a>
<h2>Meta Llama2</h2>

<p>Meta&rsquo;s Llama2 is an open-source large language model (LLM) designed as a response to models like GPT from OpenAI and Google&rsquo;s AI models. Noteworthy for its open availability for research and commercial purposes, Llama2 is poised to make a significant impact in the AI space.</p>

<p>Functioning similarly to other LLMs like GPT-3 and PaLM 2, Llama2 uses a transformer architecture and employs techniques such as pretraining and fine-tuning. It is available in different sizes, with variations like Llama 2 7B Chat, Llama 2 13B Chat, and Llama 2 70B Chat, each optimized for specific use cases.</p>

<!-- more -->


<p>Llama2 was trained on 2 trillion tokens from publicly available sources, including Common Crawl, Wikipedia, and Project Gutenberg. The model undergoes training strategies, including reinforcement learning with human feedback (RLHF), to optimize safety and appropriateness of responses.</p>

<p>What sets Llama2 apart is its open nature, allowing users to access the research paper detailing its creation, download the model, and run it on various platforms. By providing transparency and openness, Meta aims to empower other companies to develop AI applications with more control.</p>

<a name="Amazon-Olympus"></a>
<h2>Amazon Olympus</h2>

<p>Amazon, in its pursuit of AI excellence, is working on an ambitious large language model (LLM) codenamed &ldquo;Olympus.&rdquo; With a staggering 2 trillion parameters, Olympus aims to rival leading models from OpenAI and Alphabet. Led by Rohit Prasad, former head of Alexa, the team behind Olympus brings together expertise from Alexa AI and Amazon&rsquo;s science team.</p>

<p>Amazon&rsquo;s strategy involves training homegrown models to make its offerings more appealing on Amazon Web Services (AWS), catering to enterprise clients seeking top-performing models. While Amazon has trained smaller models like Titan and collaborated with AI startups such as Anthropic and AI21 Labs, there&rsquo;s no specific timeline for the release of Olympus.</p>

<p>Large language models (LLMs) are crucial for AI tools that learn from extensive datasets to generate human-like responses. Despite the increased costs associated with training larger models, Amazon is committed to investing in LLMs and generative AI.</p>

<a name="Apple-Ajax"></a>
<h2>Apple Ajax</h2>

<p>Apple&rsquo;s investment in artificial intelligence is evident through its Foundational Models unit, focusing on conversational AI. Headed by John Giannandrea, Apple&rsquo;s head of AI, this unit is dedicated to improving Siri and developing AI models across multiple teams.</p>

<p>Apple is working on advanced LLMs, including Ajax GPT, trained on over 200 billion parameters, surpassing the capabilities of OpenAI&rsquo;s GPT-3.5. The models have applications ranging from customer interaction in AppleCare to automating multistep tasks with Siri.</p>

<p>In addition to conversational AI, Apple has Visual Intelligence and Multimodal AI units developing image generation models and models capable of recognizing and producing images, video, and text simultaneously.</p>

<p>Apple&rsquo;s commitment to AI innovation is reflected in its pursuit of powerful models and diverse AI applications, ensuring advancements in Siri and other AI-powered features.</p>

<a name="Microsoft-27-s-Orca-2"></a>
<h2>Microsoft&rsquo;s Orca 2</h2>

<p>Microsoft&rsquo;s Orca 2 employs a teacher-student training scheme, where a larger LLM acts as a teacher for a smaller one, aiming to improve the performance of the student model. The training involves teaching the student various reasoning techniques and selecting the most effective strategy for specific tasks.</p>

<p>Orca 2 outperformed baseline models, including Llama 2 and ChatGPT, on reasoning benchmarks. The model&rsquo;s performance is evaluated on tasks such as language understanding, text completion, and summarization. Microsoft&rsquo;s innovative training methodology involves &ldquo;Cautious Reasoning,&rdquo; where prompts eliciting specific problem-solving strategies are used during teacher training, and the prompts are erased during student training.</p>

<p>The comparison with other LLMs, including GPT-4 and Llama 2, demonstrates Orca 2&rsquo;s competitive performance. Microsoft&rsquo;s approach aims to address the challenges of hosting large LLMs and emphasizes the effectiveness of smaller models when fine-tuned.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>The landscape of large language models continues to evolve, with major tech players pushing the boundaries of AI capabilities. From Google&rsquo;s Gemini to Meta&rsquo;s Llama2, Amazon&rsquo;s Olympus, Apple&rsquo;s Ajax, and Microsoft&rsquo;s Orca 2, each model brings unique features and applications. The open nature of Llama2 and the innovative training schemes of Orca 2 showcase the diverse approaches in AI research. As these models shape the future of AI applications, transparency, responsibility, and safety remain central to their development and deployment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vector Database: Transforming Data Storage and Retrieval in the AI Era]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/vector-database-transforming-data-storage-and-retrieval-in-the-ai-era/"/>
    <updated>2023-11-05T22:09:04+05:30</updated>
    <id>https://rishijeet.github.io/blog/vector-database-transforming-data-storage-and-retrieval-in-the-ai-era</id>
    <content type="html"><![CDATA[<p>The AI revolution has ushered in a new era of innovation, promising breakthroughs across various industries. However, with these advancements come unique challenges, particularly in handling and processing data efficiently. One of the key data types that have gained prominence in AI applications is vector embeddings. Vector databases play a pivotal role in managing and optimizing the retrieval of these embeddings. In this article, we will explore the architecture of vector databases and their crucial role in AI applications.</p>

<a name="What-is-a-Vector-Database-3f-"></a>
<h2>What is a Vector Database?</h2>

<p>A vector database is a specialized database designed to index and store vector embeddings for efficient retrieval and similarity search. These databases offer not only CRUD (Create, Read, Update, Delete) operations but also advanced capabilities like metadata filtering and horizontal scaling. They are essential for AI applications that rely on vector embeddings to understand patterns, relationships, and underlying structures in data.</p>

<p><img src="https://rishijeet.github.io/images/vector_db2.png" height="300" width="900" alt="Alt text" /><em>Source: Elastic</em></p>

<a name="Vector-Embeddings"></a>
<h3>Vector Embeddings</h3>

<p>Vector embeddings are data representations generated by AI models, such as large language models. They encapsulate semantic information critical for AI to understand and perform complex tasks effectively. These embeddings have multiple attributes or features, making their management a unique challenge.</p>

<p>Traditional scalar-based databases struggle to handle the complexity and scale of vector data, hindering real-time analysis and insights extraction. Vector databases are tailored to address these limitations, providing the performance, scalability, and flexibility needed for extracting valuable insights from vector embeddings.</p>

<!-- more -->


<a name="Vector-Database-Architecture"></a>
<h2>Vector Database Architecture</h2>

<p>Traditional databases store scalar data in rows and columns, whereas vector databases operate on vectors. They differ in the way data is optimized and queried.</p>

<p>In traditional databases, queries typically seek exact matches between query values and database records. In vector databases, similarity metrics are applied to find vectors that are most similar to the query. Vector databases employ a combination of algorithms to enable Approximate Nearest Neighbor (ANN) searches, which optimize retrieval speed.</p>

<a name="Vector-Database-Pipeline"></a>
<h3>Vector Database Pipeline</h3>

<p>A typical vector database pipeline consists of the following stages:</p>

<p><img src="https://rishijeet.github.io/images/vector_db_pipeline.png" height="300" width="900" alt="Alt text" /><em>Source: Pinecone</em></p>

<ol>
<li><p><strong>Indexing</strong>: The database indexes vectors using algorithms like PQ (Product Quantization), LSH (Locality-Sensitive Hashing), or HNSW (Hierarchical Navigable Small World). This step maps vectors to data structures for faster searching.</p></li>
<li><p><strong>Querying</strong>: The database compares the indexed query vector to the indexed vectors in the dataset to find the nearest neighbors, applying a similarity metric used by the index.</p></li>
<li><p><strong>Post Processing</strong>: In some cases, the database retrieves the final nearest neighbors from the dataset and may post-process them, such as re-ranking them using a different similarity measure.</p></li>
</ol>


<a name="Algorithms-for-Vector-Indexing"></a>
<h3>Algorithms for Vector Indexing</h3>

<p>Vector databases rely on various algorithms to create efficient indexes for high-dimensional vector embeddings. These algorithms are designed to transform the original vector data into a compressed form, optimizing the query process for faster retrieval.</p>

<a name="Random-Projection"></a>
<h4>Random Projection</h4>

<p>Random projection is a technique that aims to project high-dimensional vectors into a lower-dimensional space using a random projection matrix. Here&rsquo;s how it works:</p>

<ul>
<li><p><strong>Projection Matrix Creation</strong>: A matrix of random numbers is created with the target lower-dimensional value. This matrix is then used to calculate the dot product of input vectors, resulting in a projected matrix that has fewer dimensions but still preserves vector similarity.</p></li>
<li><p><strong>Query Process</strong>: When a query is executed, the same projection matrix is used to project the query vector into the lower-dimensional space. The projected query vector is then compared to the projected vectors in the database to find the nearest neighbors. The reduced dimensionality of the data speeds up the search process.</p></li>
</ul>


<p>It&rsquo;s essential to note that random projection is an approximate method, and the quality of the projection depends on the properties of the projection matrix. Generating a truly random projection matrix can be computationally expensive, especially for large datasets.
<img src="https://rishijeet.github.io/images/vector_rp.png" height="300" width="900" alt="Alt text" /><em>Source: Pinecone</em></p>

<a name="Product-Quantization"></a>
<h4>Product Quantization</h4>

<p>Product quantization (PQ) is a lossy compression technique tailored for high-dimensional vectors, such as vector embeddings. The process involves splitting, training, encoding, and querying:</p>

<ul>
<li><p><strong>Splitting</strong>: Vectors are divided into segments.</p></li>
<li><p><strong>Training</strong>: A &ldquo;codebook&rdquo; is created for each segment, representing potential codes for vectors. The codebook is established by performing k-means clustering on each segment, resulting in center points that serve as codes.</p></li>
<li><p><strong>Encoding</strong>: Each vector segment is assigned a specific code from the codebook, typically the nearest value. Multiple PQ codes can represent a segment.</p></li>
<li><p><strong>Query Process</strong>: During querying, vectors are broken down into sub-vectors and quantized using the codebook. The indexed codes are then used to find the nearest vectors to the query vector.</p></li>
</ul>


<p>The number of representative vectors in the codebook involves a trade-off between representation accuracy and computational cost. A larger codebook improves accuracy but increases computational expenses.
<img src="https://rishijeet.github.io/images/vector_pq.png" height="300" width="900" alt="Alt text" /><em>Source: Towards Data Science</em></p>

<a name="Locality-2d-Sensitive-Hashing--28-LSH-29-"></a>
<h4>Locality-Sensitive Hashing (LSH)</h4>

<p>Locality-sensitive hashing (LSH) is optimized for approximate nearest-neighbor search. LSH maps similar vectors into &ldquo;buckets&rdquo; using a set of hashing functions:</p>

<ul>
<li><p><strong>Indexing</strong>: Similar vectors are grouped into hash tables using the hashing functions.</p></li>
<li><p><strong>Query Process</strong>: To find the nearest neighbors for a query vector, the same hashing functions are used to map the query vector to a specific table. The query vector is then compared with the vectors in that table to find the closest matches. This method accelerates searching by reducing the number of vectors to consider.</p></li>
</ul>


<p>LSH is an approximate method, and the quality of the approximation depends on the properties of the hash functions. Using more hash functions improves approximation quality but can be computationally expensive, especially for large datasets.
<img src="https://rishijeet.github.io/images/vector_lsh.png" height="300" width="900" alt="Alt text" /><em>Source: Pinecone</em></p>

<a name="Hierarchical-Navigable-Small-World--28-HNSW-29-"></a>
<h4>Hierarchical Navigable Small World (HNSW)</h4>

<p>HNSW creates a hierarchical, tree-like structure where each node represents a set of vectors, and edges indicate similarity between vectors. The algorithm follows these steps:</p>

<ul>
<li><p><strong>Node Creation</strong>: A set of nodes is established, each containing a small number of vectors. Nodes can be created randomly or by clustering vectors using algorithms like k-means.</p></li>
<li><p><strong>Edge Formation</strong>: The algorithm examines the vectors within each node and establishes edges between the node and those nodes containing the most similar vectors.</p></li>
<li><p><strong>Query Process</strong>: When querying an HNSW index, the algorithm navigates the hierarchical structure, visiting nodes that are likely to contain the closest vectors to the query vector.</p></li>
</ul>


<p><img src="https://rishijeet.github.io/images/vector_hnsw.png" height="300" width="900" alt="Alt text" /><em>Source: Pinecone</em></p>

<a name="Similarity-Measures"></a>
<h3>Similarity Measures</h3>

<p>The choice of similarity measure plays a crucial role in vector database performance. Common similarity measures include:</p>

<ul>
<li><p><strong>Cosine Similarity</strong>: Measures the cosine of the angle between two vectors, with a range from -1 to 1. It signifies the degree of similarity between vectors.</p></li>
<li><p><strong>Euclidean Distance</strong>: Measures the straight-line distance between vectors in a vector space, with a range from 0 to infinity.</p></li>
<li><p><strong>Dot Product</strong>: Measures the product of the magnitudes of two vectors and the cosine of the angle between them, with a range from -∞ to ∞.</p></li>
</ul>


<p>The selection of the appropriate similarity measure depends on the specific use case and requirements.</p>

<a name="Filtering"></a>
<h3>Filtering</h3>

<p>Each vector stored in the database includes associated metadata. Vector databases can filter query results based on metadata queries, typically maintaining both vector and metadata indexes. The filtering process can occur before or after the vector search, with trade-offs in terms of efficiency.</p>

<ul>
<li><p><strong>Pre-filtering</strong>: Filters are applied before the vector search. While reducing the search space, it may exclude relevant results not meeting metadata filter criteria and add computational overhead.</p></li>
<li><p><strong>Post-filtering</strong>: Filters are applied after the vector search. This ensures all relevant results are considered but may introduce additional processing overhead.</p></li>
</ul>


<p><img src="https://rishijeet.github.io/images/vector_filter.png" height="300" width="900" alt="Alt text" /><em>Source: Pinecone</em></p>

<p>Optimizing the filtering process involves techniques like advanced indexing for metadata and parallel processing to balance performance and accuracy.</p>

<a name="Vector-Database-vs.-Vector-Index"></a>
<h3>Vector Database vs. Vector Index</h3>

<p>While standalone vector indices like FAISS (Facebook AI Similarity Search) can enhance the search and retrieval of vector embeddings, they lack essential database features. Vector databases offer several advantages over standalone vector indices, including:</p>

<ol>
<li><p><strong>Data Management</strong>: Vector databases provide traditional database features for easy data management, such as insertion, deletion, and updating. This simplifies vector data management compared to standalone vector indices like FAISS, which require additional integration with storage solutions.</p></li>
<li><p><strong>Metadata Storage and Filtering</strong>: Vector databases can store metadata associated with each vector entry. Users can query the database using additional metadata filters for more granular queries.</p></li>
<li><p><strong>Scalability</strong>: Vector databases are designed for scalability, supporting the growth of data volumes and user demands. They excel in distributed and parallel processing, while standalone vector indices may require custom solutions for similar scalability.</p></li>
<li><p><strong>Real-time Updates</strong>: Vector databases often support real-time data updates, allowing dynamic changes to the data. Standalone vector indexes may require time-consuming and computationally expensive full re-indexing to incorporate new data.</p></li>
<li><p><strong>Backups and Collections</strong>: Vector databases handle data backup operations, and users can selectively choose specific indexes to back up in the form of &ldquo;collections.&rdquo; This feature ensures data resilience and retrievability.</p></li>
<li><p><strong>Ecosystem Integration</strong>: Vector databases can seamlessly integrate with other components of a data processing ecosystem, streamlining data management workflows. This integration extends to AI-related tools, fostering a comprehensive ecosystem for AI applications.</p></li>
<li><p><strong>Data Security and Access Control</strong>: Vector databases typically include built-in data security features and access control mechanisms to safeguard sensitive information. These security measures may not be available in standalone vector index solutions.</p></li>
</ol>


<p>In summary, vector databases are purpose-built for managing vector embeddings, addressing the limitations of standalone vector indices and offering a more effective and streamlined data management experience.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>In the age of AI, efficient data processing and retrieval are paramount for applications relying on vector embeddings. Vector databases are purpose-built to handle these complex data types, offering advanced capabilities for storage, retrieval, and analysis. Understanding the architecture and capabilities of vector databases empowers organizations to unlock the full potential of their AI applications, gaining a competitive edge in the rapidly evolving AI landscape.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Innovative GenAI Applications with the GenAI Stack: Unleashing the Power of Docker]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/building-innovative-genai-applications-with-the-genai-stack-unleashing-the-power-of-docker/"/>
    <updated>2023-11-04T22:49:05+05:30</updated>
    <id>https://rishijeet.github.io/blog/building-innovative-genai-applications-with-the-genai-stack-unleashing-the-power-of-docker</id>
    <content type="html"><![CDATA[<p>In the fast-evolving landscape of artificial intelligence, Generative AI (GenAI) is at the forefront, opening up exciting opportunities for developers and businesses. One of the most significant challenges in GenAI development is creating a robust, efficient, and scalable infrastructure that harnesses the power of AI models. To address this challenge, the GenAI Stack has emerged as a game-changer, combining cutting-edge technologies like Docker, LangChain, Neo4j, and Ollama. In this article, we will delve into the intricacies of these technologies and explore how they work together to build innovative GenAI applications.</p>

<a name="Understanding-the-GenAI-Stack"></a>
<h2>Understanding the GenAI Stack</h2>

<p>Before we dive into the technical details, let&rsquo;s establish a clear understanding of what the GenAI Stack is and what it aims to achieve.</p>

<p>The GenAI Stack is a comprehensive environment designed to facilitate the development and deployment of GenAI applications. It provides a seamless integration of various components, including a management tool for local Large Language Models (LLMs), a database for grounding, and GenAI apps powered by LangChain. Here&rsquo;s a breakdown of these components and their roles:</p>

<ol>
<li><p><strong>Docker:</strong> Docker is a containerization platform that allows developers to package applications and their dependencies into containers. These containers are lightweight, portable, and provide consistent runtime environments, making them an ideal choice for deploying GenAI applications.</p></li>
<li><p><strong>LangChain:</strong> LangChain is a powerful tool that orchestrates GenAI applications. It&rsquo;s the brains behind the application logic and ensures that the various components of the GenAI Stack work harmoniously together. LangChain simplifies the process of building and orchestrating GenAI applications.</p></li>
<li><p><strong>Neo4j:</strong> Neo4j is a highly versatile graph database that serves as the backbone of GenAI applications. It provides a robust foundation for building knowledge graph-based applications. Neo4j&rsquo;s graph database capabilities are instrumental in managing and querying complex relationships and data structures.</p></li>
<li><p><strong>Ollama:</strong> Ollama represents the core of the GenAI Stack. It is a local LLM container that brings the power of large language models to your GenAI applications. Ollama enables you to run LLMs on your infrastructure or even on your local machine, providing more control and flexibility over your GenAI models.</p></li>
</ol>


<!-- more -->


<a name="Docker:-The-Containerization-Revolution"></a>
<h2>Docker: The Containerization Revolution</h2>

<p>Docker has revolutionized application deployment and management. It introduces the concept of containerization, allowing developers to bundle their applications and dependencies into containers. These containers are isolated and share the host operating system&rsquo;s kernel, making them lightweight and efficient. Docker&rsquo;s advantages include:</p>

<ul>
<li><p><strong>Portability:</strong> Containers can run on any platform that supports Docker, ensuring consistency across different environments.</p></li>
<li><p><strong>Scalability:</strong> Docker&rsquo;s container orchestration tools, such as Kubernetes, make it easy to scale applications horizontally.</p></li>
<li><p><strong>Resource Efficiency:</strong> Containers consume fewer resources compared to traditional virtual machines, allowing for better resource utilization.</p></li>
</ul>


<p><img src="https://rishijeet.github.io/images/docker.png" height="300" width="900" alt="Alt text" /><em>Source: Whizlabs</em></p>

<p>In the GenAI Stack, Docker is the foundation that ensures all components work seamlessly together, providing a consistent and controlled environment for GenAI applications.</p>

<a name="LangChain:-Orchestrating-GenAI-Applications"></a>
<h2>LangChain: Orchestrating GenAI Applications</h2>

<p>LangChain is the orchestrator of GenAI applications within the GenAI Stack. It is designed to simplify the process of building, managing, and deploying GenAI applications. Key features of LangChain include:</p>

<ul>
<li><p><strong>Application Logic:</strong> LangChain houses the application logic in Python, allowing developers to create GenAI apps easily.</p></li>
<li><p><strong>User Interface:</strong> LangChain leverages Streamlit for creating user interfaces, enabling developers to build interactive and user-friendly applications.</p></li>
<li><p><strong>Docker Integration:</strong> LangChain seamlessly integrates with Docker, facilitating containerization and deployment of GenAI apps.</p></li>
<li><p><strong>Development Environment:</strong> LangChain provides a development environment that supports rapid feedback loops, making it easier for developers to iterate on their applications.</p></li>
</ul>


<p><img src="https://rishijeet.github.io/images/langchain.png" height="300" width="900" alt="Alt text" /><em>Source: Packt</em></p>

<p>LangChain is the bridge that connects various components of the GenAI Stack, ensuring that they work together cohesively to bring GenAI applications to life.</p>

<a name="Neo4j:-Powering-Knowledge-Graph-2d-Based-Applications"></a>
<h2>Neo4j: Powering Knowledge Graph-Based Applications</h2>

<p>Knowledge graphs have become a pivotal component in GenAI applications. Neo4j, a graph database, plays a crucial role in managing the intricate relationships and data structures that underpin these applications. Key attributes of Neo4j include:</p>

<ul>
<li><p><strong>Graph Database:</strong> Neo4j stores and manages data in a graph format, making it ideal for applications that require intricate data relationships.</p></li>
<li><p><strong>Querying Capabilities:</strong> Neo4j provides powerful querying capabilities, allowing developers to retrieve and manipulate data in a flexible and efficient manner.</p></li>
<li><p><strong>Scalability:</strong> Neo4j can scale horizontally to accommodate growing data and application demands.</p></li>
</ul>


<p><img src="https://rishijeet.github.io/images/neo4j.svg" height="300" width="900" alt="Alt text" /><em>Source: Neo4j</em></p>

<p>In GenAI applications, Neo4j serves as the foundation for creating knowledge graph-based applications. It allows developers to model and query complex relationships, ultimately enhancing the accuracy and relevance of GenAI responses.</p>

<a name="Ollama:-The-Power-of-Local-LLMs"></a>
<h2>Ollama: The Power of Local LLMs</h2>

<p>Large Language Models (LLMs) are at the heart of GenAI applications. Ollama, an integral part of the GenAI Stack, brings LLMs to the local environment, offering more control and flexibility. Key advantages of Ollama include:</p>

<ul>
<li><p><strong>Open Source:</strong> Ollama is an open-source project, enabling developers to run LLMs without depending on external providers.</p></li>
<li><p><strong>Data Control:</strong> Ollama allows developers to have complete control over data flows, storage, and sharing.</p></li>
<li><p><strong>Local Deployment:</strong> Developers can run Ollama on their infrastructure or even on a local machine, making it a versatile choice for GenAI development.</p></li>
</ul>


<p><img src="https://rishijeet.github.io/images/ollama.png" height="300" width="900" alt="Alt text" /><em>Source: Ollama</em></p>

<p>Ollama represents a significant step forward in GenAI development by providing a seamless solution for setting up and running local LLMs, removing dependencies on external providers, and offering more control over the data flow.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>The GenAI Stack powered by Docker, LangChain, Neo4j, and Ollama is a formidable combination for building innovative GenAI applications. It simplifies the development process, provides the infrastructure for knowledge graph-based applications, and empowers developers with local LLM capabilities. With these technologies at your disposal, you can create GenAI applications that are accurate, relevant, and highly customizable.</p>

<p>As the GenAI landscape continues to evolve, the GenAI Stack is a beacon of innovation, enabling developers to unlock the full potential of artificial intelligence. Whether you&rsquo;re building chatbots, support agents, or knowledge retrieval systems, the GenAI Stack has the tools you need to make your GenAI applications shine.</p>

<p>It&rsquo;s time to explore the possibilities, experiment with GenAI, and build the next generation of intelligent applications using the GenAI Stack. The future of GenAI is here, and it&rsquo;s waiting for your creative ideas and innovations to transform it.</p>

<p><em>Disclaimer: The images and URLs in this blog are for illustrative purposes only and may not represent real services or websites.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Webhook vs. WebSocket: Choosing the Right Communication Mechanism for Your Application]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/webhook-vs-websocket-choosing-the-right-communication-mechanism-for-your-application/"/>
    <updated>2023-11-04T20:56:03+05:30</updated>
    <id>https://rishijeet.github.io/blog/webhook-vs-websocket-choosing-the-right-communication-mechanism-for-your-application</id>
    <content type="html"><![CDATA[<p>In today&rsquo;s digital age, communication between applications is crucial, and it&rsquo;s the APIs (Application Programming Interfaces) that act as the mediators. APIs provide a standardized way for software modules, applications, and devices to exchange data and instructions. However, not all communication needs can be met by APIs alone. In this article, we&rsquo;ll explore three different communication mechanisms: API, WebHook, and WebSocket, and help you understand when to use each one.</p>

<a name="Understanding-API-Interfaces"></a>
<h2>Understanding API Interfaces</h2>

<p>APIs are the backbone of modern application development. They guide machines, devices, and applications on how to interact with each other, just like human language allows us to express our thoughts. APIs define the rules and methods for data exchange between the client-side application and the server-side infrastructure.</p>

<p>There are three primary types of APIs:</p>

<ol>
<li><strong>Private API:</strong> Restricted to authorized personnel within an organization.</li>
<li><strong>Public API:</strong> Accessible to anyone without restrictions.</li>
<li><strong>Partner API:</strong> Used to enable business partnerships and third-party integrations.</li>
</ol>


<p>APIs are essential for ensuring secure and efficient communication between various components of an application. Poor API security can lead to data corruption and pose a significant risk to the entire application.</p>

<a name="WebHook:-Reverse-API-for-Event-2d-Driven-Communication"></a>
<h2>WebHook: Reverse API for Event-Driven Communication</h2>

<p>WebHooks can be thought of as reverse APIs since they operate in the opposite direction. While APIs allow clients to request data from the server, WebHooks enable servers to push information to other servers or applications. They are often referred to as server-to-server push notifications.</p>

<p>WebHooks are highly versatile and are ideal for handling integrations between different solutions or applications. They are typically used to notify an application or web app about specific events, such as receiving a message, processing a payment, or any other update.</p>

<a name="WebSocket:-Real-2d-Time-2c--Bidirectional-Communication"></a>
<h2>WebSocket: Real-Time, Bidirectional Communication</h2>

<p>WebSocket is a communication protocol that enables full-duplex, bidirectional communication over a single TCP connection. Unlike HTTP-based APIs, WebSocket maintains a continuous, open connection, making it suitable for real-time applications. It is considered a stateful protocol because the communication remains active until one of the parties terminates it, and it employs a 3-way handshake for connection establishment.</p>

<p>WebSocket is perfect for applications that demand real-time communication, as it allows information exchange at any time and from anywhere. It is particularly useful for collaborative tools, data visualization applications, and chat applications, where immediate and bidirectional communication is essential.</p>

<!-- more -->


<a name="When-to-Use-API-Interfaces-2c--WebHooks-2c--and-WebSockets"></a>
<h2>When to Use API Interfaces, WebHooks, and WebSockets</h2>

<p>Choosing the right communication mechanism depends on the specific needs of your application:</p>

<p><strong>API Interfaces:</strong>
- Ideal for applications that require an easy interface for end-users.
- Suitable for CRUD operations from mobile and web apps, data transfer using XML or JSON, and frequent data changes.
- Useful for applications that demand instant responses to user requests (e.g., live chat applications, messenger apps, IoT devices, and wearable devices).
<img src="https://rishijeet.github.io/images/API%20Interface.jpg" height="300" width="900" alt="Alt text" /><em>Source: wallarm</em></p>

<p><strong>WebSockets:</strong>
- Perfect for applications that require real-time communication.
- Promotes bidirectional communication and maintains an open connection.
- Suited for collaborative and chat-centric applications (e.g., modern browsers, data visualization tools, and chat applications).
<img src="https://rishijeet.github.io/images/websockets.jpg" height="300" width="900" alt="Alt text" /><em>Source: mirrorfly</em></p>

<p><strong>WebHooks:</strong>
- Best for making backend calls and handling one-way event-driven communication.
- Ideal when your application needs to fetch data from a third-party application.
- Preferred for applications deployed on the cloud, where open communication is not necessary (e.g., Discord Bots).
<img src="https://rishijeet.github.io/images/webhooks.jpg" height="300" width="900" alt="Alt text" /><em>Source: wallarm</em></p>

<p>In conclusion, the effectiveness of an application often hinges on how well server-client communication is implemented. APIs, WebHooks, and WebSockets are three essential ways to facilitate this communication. APIs are the foundation, while WebSockets excel in event-driven scenarios, and WebHooks are best for one-way event-infused communication. Choose the communication mechanism that aligns with your application&rsquo;s requirements for optimal functionality and user experience.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Revolutionizing AI Inference: Lightmatter's Envise Chip]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/revolutionizing-ai-inference-lightmatters-envise-chip/"/>
    <updated>2023-06-18T22:24:50+05:30</updated>
    <id>https://rishijeet.github.io/blog/revolutionizing-ai-inference-lightmatters-envise-chip</id>
    <content type="html"><![CDATA[<p>Artificial Intelligence (AI) is rapidly transforming various industries, from autonomous driving and robotics to healthcare and customer service. As the demand for AI applications grows, so does the need for more powerful and energy-efficient processors. In this context, Lightmatter, a company at the forefront of photonic processors, has developed the Envise chip—an innovative solution that promises unprecedented performance and energy efficiency in AI inference.</p>

<a name="Unleashing-Unprecedented-Power-and-Efficiency"></a>
<h5>Unleashing Unprecedented Power and Efficiency</h5>

<p>The Envise chip is a game-changer in the world of AI inference. It features 16 Envise Chips in a 4-U server configuration, consuming only 3kW of power. This remarkable power efficiency enables the chip to run the largest neural networks developed to date with exceptional performance. In fact, Lightmatter claims that the Envise chip delivers three times higher instructions per second (IPS) than the Nvidia DGX-A100, while achieving eight times the IPS per watt on BERT-Base SQuAD. These numbers are staggering and highlight the potential of the Envise chip to redefine AI inference capabilities.<a href="">^1</a></p>

<a name="Unmatched-Specifications"></a>
<h5>Unmatched Specifications</h5>

<p>The Envise chip boasts several cutting-edge features that contribute to its remarkable performance. Its on-chip activation and weight storage eliminate the need to transfer data to external memory, enabling state-of-the-art neural network execution within the processor itself. Additionally, the chip utilizes a standards-based host and interconnect interface, offering seamless integration into existing systems. The inclusion of RISC cores per Envise processor provides generic off-load capabilities, enhancing the chip&rsquo;s versatility. Its ultra-high-performance out-of-order super-scalar processing architecture further optimizes computation efficiency.</p>

<!-- more -->


<p><img src="https://rishijeet.github.io/images/Photonics.jpg" height="400" width="900" alt="Alt text" /><em>Source: Lightmatter</em></p>

<a name="Applications-Across-Industries"></a>
<h5>Applications Across Industries</h5>

<p>The applications of the Envise chip are vast and span various industries. In the automotive sector, it can power autonomous driving systems, improving safety and efficiency on the road. In robotics, the chip enables advanced vision and control capabilities, empowering robots to perform complex tasks with precision. In e-commerce and advertising, it facilitates accurate product recommendations, enhancing customer experiences. The chip finds utility in healthcare for pharmaceutical research, pathology analysis, and cancer detection. Moreover, it enhances customer service through digital assistants and chatbots. Its potential also extends to signal processing and natural language processing, enabling tasks such as digital signal analysis, text-to-speech, and language translation.</p>

<a name="A-Sustainable-and-Economical-Solution"></a>
<h5>A Sustainable and Economical Solution</h5>

<p>Lightmatter&rsquo;s Envise chip not only delivers superior performance but also addresses the pressing concern of power consumption in data centers. With ICT energy consumption projected to increase significantly in the coming years, solutions that offer high compute capabilities with reduced energy consumption are crucial for sustainable and cost-effective data centers. The Envise chip&rsquo;s photonic architecture leverages silicon photonics, consuming significantly less energy than traditional CMOS solutions. By reducing power demands, the chip helps mitigate the environmental impact and supports the growth of energy-efficient data centers.</p>

<a name="Looking-Ahead"></a>
<h5>Looking Ahead</h5>

<p>The Envise chip represents a significant milestone in the advancement of AI inference technology. With its impressive performance, energy efficiency, and versatile applications, it has the potential to reshape industries and accelerate AI adoption. Lightmatter&rsquo;s dedication to bringing its product to market, as demonstrated by its recent funding and strategic board appointments, underscores its commitment to revolutionizing the AI landscape.</p>

<p><img src="https://rishijeet.github.io/images/Hot-Chips-32-Lightmatter-Software.jpg" height="300" width="900" alt="Alt text" /><em>Source: Lightmatter</em></p>

<p>Lightmatter&rsquo;s Envise chip stands as a testament to the rapid evolution of AI inference processors. Its exceptional performance, energy efficiency, and broad applications make it a force to be reckoned with in the AI industry. As more companies explore photonic processors and accelerators, the development of specialized computing devices like the Envise chip paves the way for a future where AI capabilities are maximized while minimizing energy consumption. The Envise chip is poised to transform industries and contribute to the realization of sustainable and economical data centers.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AI Deep Learning: Unleashing the Power of Neural Networks]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/ai-deep-learning-unleashing-the-power-of-neural-networks/"/>
    <updated>2023-05-23T23:35:46+05:30</updated>
    <id>https://rishijeet.github.io/blog/ai-deep-learning-unleashing-the-power-of-neural-networks</id>
    <content type="html"><![CDATA[<p>Artificial intelligence (AI) and its subset, deep learning, have revolutionized numerous industries, from healthcare to autonomous vehicles. Deep learning, an approach within AI, has garnered significant attention for its ability to process vast amounts of data and extract complex patterns. In this advanced tech article, we will delve into the core concepts and techniques of deep learning, exploring its architecture, training process, and real-world applications.</p>

<a name="The-Basics-of-Deep-Learning"></a>
<h5>The Basics of Deep Learning</h5>

<ul>
<li><p>Neural Networks: Deep learning relies on neural networks, inspired by the human brain&rsquo;s structure and functioning. Neural networks consist of interconnected layers of artificial neurons, with each neuron performing a weighted computation and applying an activation function.</p></li>
<li><p>Deep Neural Networks (DNNs): DNNs are neural networks with multiple hidden layers, enabling them to learn hierarchical representations of data. These layers enable deep learning models to capture intricate patterns and relationships within complex datasets.</p></li>
</ul>


<a name="Deep-Learning-Architectures"></a>
<h5>Deep Learning Architectures</h5>

<a name="Convolutional-Neural-Networks--28-CNNs-29-"></a>
<h6>Convolutional Neural Networks (CNNs)</h6>

<p>CNNs are designed for image and video analysis. They employ convolutional layers to extract local features from the input, pooling layers for downsampling, and fully connected layers for classification.</p>

<p>Convolutional Neural Networks (CNNs) Example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Define the CNN model</span>
</span><span class='line'><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">&#39;relu&#39;</span><span class="p">))</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">&#39;softmax&#39;</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Compile and train the model</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">&#39;adam&#39;</span><span class="p">,</span>
</span><span class='line'>              <span class="n">loss</span><span class="o">=</span><span class="s">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
</span><span class='line'>              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;accuracy&#39;</span><span class="p">])</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<!--more-->


<a name="Recurrent-Neural-Networks--28-RNNs-29-"></a>
<h6>Recurrent Neural Networks (RNNs)</h6>

<p>RNNs are suitable for sequential data, such as text or time-series data. They utilize recurrent connections to capture temporal dependencies and process variable-length sequences.</p>

<p>Recurrent Neural Networks (RNNs) Example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Define the RNN model</span>
</span><span class='line'><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">&#39;softmax&#39;</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Compile and train the model</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">&#39;adam&#39;</span><span class="p">,</span>
</span><span class='line'>              <span class="n">loss</span><span class="o">=</span><span class="s">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
</span><span class='line'>              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;accuracy&#39;</span><span class="p">])</span>
</span><span class='line'><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_sequences</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">test_sequences</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<a name="Generative-Adversarial-Networks--28-GANs-29-"></a>
<h6>Generative Adversarial Networks (GANs)</h6>

<p>GANs consist of a generator and a discriminator, engaged in a competitive training process. GANs generate new data samples that closely resemble the training data, making them useful for tasks like image generation and data synthesis.</p>

<p>Generative Adversarial Networks (GANs) Example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Define the generator model</span>
</span><span class='line'><span class="n">generator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
</span><span class='line'><span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,),</span> <span class="n">activation</span><span class="o">=</span><span class="s">&#39;relu&#39;</span><span class="p">))</span>
</span><span class='line'><span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">&#39;tanh&#39;</span><span class="p">))</span>
</span><span class='line'><span class="n">generator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Reshape</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Define the discriminator model</span>
</span><span class='line'><span class="n">discriminator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
</span><span class='line'><span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
</span><span class='line'><span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">&#39;relu&#39;</span><span class="p">))</span>
</span><span class='line'><span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">&#39;sigmoid&#39;</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Combine the generator and discriminator into a GAN</span>
</span><span class='line'><span class="n">gan</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">generator</span><span class="p">,</span> <span class="n">discriminator</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Compile and train the GAN</span>
</span><span class='line'><span class="n">discriminator</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">&#39;binary_crossentropy&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">discriminator</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">False</span>
</span><span class='line'><span class="n">gan</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">&#39;binary_crossentropy&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">gan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note: These code snippets provide a basic structure for each model and may require additional adjustments based on your specific use case and dataset. Make sure to import the necessary libraries, preprocess your data, and customize the models accordingly.</p>

<a name="Training-Deep-Learning-Models"></a>
<h5>Training Deep Learning Models</h5>

<p>a. Backpropagation: Backpropagation is a key algorithm used to train deep learning models. It calculates the gradients of the model&rsquo;s parameters with respect to a loss function, allowing the network to update its weights and improve its performance.</p>

<p>b. Optimization Algorithms: Various optimization algorithms, such as stochastic gradient descent (SGD), Adam, and RMSprop, help find the optimal set of weights for deep learning models. These algorithms aim to minimize the loss function and improve model accuracy.</p>

<a name="Conclusion"></a>
<h5>Conclusion</h5>

<p>Deep learning is at the forefront of AI advancements, enabling machines to learn complex patterns and make accurate predictions. With neural networks as their foundation, deep learning models like CNNs, RNNs, and GANs have transformed various domains, including computer vision, natural language processing, and autonomous systems. Understanding the architecture, training process, and real-world applications of deep learning empowers developers and researchers to harness its immense potential. As deep learning continues to evolve, it holds the key to solving increasingly complex problems and driving innovation across industries.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What's new in Java 20?]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/whats-new-in-java-20/"/>
    <updated>2023-05-23T23:03:47+05:30</updated>
    <id>https://rishijeet.github.io/blog/whats-new-in-java-20</id>
    <content type="html"><![CDATA[<p>Java, being one of the most widely used programming languages, continues to evolve with each new release, bringing enhancements, features, and improvements to the development community. In this tech article, we will explore the exciting new features introduced in Java 20, highlighting the advancements that developers can leverage to build robust, efficient, and modern applications.</p>

<a name="Improved-Pattern-Matching-for-instanceof"></a>
<h5>Improved Pattern Matching for instanceof</h5>

<p>Java 20 introduces further improvements to pattern matching for the instanceof operator, building upon the enhancements introduced in previous versions. Developers can now use patterns in switch statements with instanceof, simplifying code and reducing the need for explicit casting.</p>

<a name="Records"></a>
<h5>Records</h5>

<p>Java 20 introduces the records feature, which provides a concise syntax for defining immutable data classes. Records eliminate the need for boilerplate code by automatically generating constructors, accessors, and other methods. They promote readability, immutability, and ease of use when working with data-centric classes.</p>

<a name="Sealed-Classes"></a>
<h5>Sealed Classes</h5>

<p>Sealed classes offer enhanced control over class inheritance and improve code maintainability. Java 20 introduces sealed classes that allow developers to define a limited set of subclasses that can extend them. This feature helps enforce encapsulation, restrict inheritance, and make code more predictable.</p>

<!--more-->


<a name="Vector-API--28-Incubator-29-"></a>
<h5>Vector API (Incubator)</h5>

<p>The Vector API, introduced as an incubating feature in Java 20, provides a platform-independent way to express vector computations that can leverage hardware-specific vector units. This API allows developers to write high-performance, portable code for vector operations, enabling efficient use of hardware capabilities.</p>

<a name="Foreign-Function--26-amp-3b--Memory-API--28-Incubator-29-"></a>
<h5>Foreign Function &amp; Memory API (Incubator)</h5>

<p>Java 20 introduces the Foreign Function &amp; Memory API as an incubating feature. This API allows Java programs to interoperate with native code, enabling developers to call native functions and access native memory directly. It simplifies integration with existing native libraries and provides more flexibility in Java programming.</p>

<a name="Enhanced-Garbage-Collection"></a>
<h5>Enhanced Garbage Collection</h5>

<p>Java 20 brings advancements in garbage collection algorithms, including the Concurrent Mark and Sweep (CMS) algorithm and the G1 garbage collector. These improvements focus on reducing pause times, improving memory management, and optimizing garbage collection performance. Developers can expect more predictable behavior and enhanced application performance.</p>

<a name="Performance-and-Security-Enhancements"></a>
<h5>Performance and Security Enhancements</h5>

<p>Java 20 includes various performance and security enhancements. These include improved startup times, optimized code execution, reduced memory footprint, enhanced security features, and updates to cryptographic algorithms. These improvements contribute to better application performance, security, and overall user experience.</p>

<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>Java 20 introduces several exciting features and improvements that enhance developer productivity, code readability, performance, and security. The advancements in pattern matching, sealed classes, records, and the Vector API empower developers to write cleaner, more concise code and leverage hardware capabilities efficiently. The incubating features, such as the Foreign Function &amp; Memory API, offer new possibilities for integration with native code. Additionally, the enhanced garbage collection algorithms and performance optimizations contribute to better application performance.</p>

<p>As a Java developer, it is essential to stay updated with the latest features and best practices introduced in Java 20. By leveraging these advancements, developers can build robust, efficient, and secure applications that meet the demands of modern software development.</p>

<a name="References"></a>
<h3>References</h3>

<ul>
<li>OpenJDK. &ldquo;JEPs in JDK 20.&rdquo; <a href="https://openjdk.java.net/projects/jdk/20/">https://openjdk.java.net/projects/jdk/20/</a></li>
<li>Oracle. &ldquo;Java 20 Release Notes.&rdquo; <a href="https://www.oracle.com/java/technologies/javase/20-relnotes.html">https://www.oracle.com/java/technologies/javase/20-relnotes.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine Learning and AI Revolutionizing the e-Trading Market]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/machine-learning-and-ai-revolutionizing-the-e-trading-market/"/>
    <updated>2023-05-23T21:44:08+05:30</updated>
    <id>https://rishijeet.github.io/blog/machine-learning-and-ai-revolutionizing-the-e-trading-market</id>
    <content type="html"><![CDATA[<p>The world of electronic trading (e-Trading) has undergone a profound transformation with the emergence of machine learning and artificial intelligence (AI). These technologies have revolutionized how financial markets operate, empowering traders with advanced tools and insights to make more informed decisions. In this blog, we will explore the significant impact of machine learning and AI on the e-Trading market, highlighting their transformative potential and the benefits they bring to traders and investors.</p>

<a name="Enhanced-Data-Analysis-and-Decision-2d-Making"></a>
<h5>Enhanced Data Analysis and Decision-Making</h5>

<p>Machine learning algorithms excel at analyzing vast amounts of financial data, identifying patterns, and extracting valuable insights. By processing market data in real-time, AI-powered systems can recognize complex patterns and relationships that might not be apparent to human traders. This enables more accurate predictions and informed decision-making, empowering traders to seize opportunities and mitigate risks effectively.</p>

<a name="Algorithmic-Trading-and-Execution"></a>
<h5>Algorithmic Trading and Execution</h5>

<p>One of the prominent applications of machine learning and AI in e-Trading is algorithmic trading. AI algorithms can automatically execute trades based on predefined rules, market conditions, and predictive models. These algorithms leverage historical and real-time data, continuously learning and adapting to changing market dynamics. Algorithmic trading not only improves execution speed but also reduces human errors and emotions, leading to more efficient and precise trading strategies.</p>

<a name="Risk-Management-and-Fraud-Detection"></a>
<h5>Risk Management and Fraud Detection</h5>

<p>Machine learning algorithms play a crucial role in risk management within e-Trading. By analyzing historical data and real-time market indicators, AI models can identify potential risks and deviations from normal trading patterns. This allows traders to implement risk mitigation strategies and protect their portfolios. Additionally, AI-powered systems can detect and prevent fraudulent activities, such as market manipulation or insider trading, ensuring a fair and transparent trading environment.</p>

<!--more-->


<a name="Sentiment-Analysis-and-News-Impact"></a>
<h5>Sentiment Analysis and News Impact</h5>

<p>The ability to analyze and interpret market sentiment and news impact is vital in e-Trading. Machine learning and AI algorithms can process vast amounts of textual and sentiment data from news articles, social media, and other sources. By gauging market sentiment and assessing the impact of news events, traders can make more informed decisions and adjust their strategies accordingly. This enhances their ability to capitalize on market movements driven by news and sentiment shifts.</p>

<a name="Market-Prediction-and-Forecasting"></a>
<h5>Market Prediction and Forecasting</h5>

<p>Machine learning models, including neural networks and deep learning algorithms, have demonstrated remarkable capabilities in market prediction and forecasting. These models learn from historical data, capturing complex patterns and relationships, and generate predictions about future market movements. Traders can leverage these predictive insights to identify potential entry and exit points, optimize trading strategies, and improve overall performance in the e-Trading market.</p>

<a name="High-2d-Frequency-Trading--28-HFT-29-"></a>
<h5>High-Frequency Trading (HFT)</h5>

<p>High-frequency trading has seen a significant impact from machine learning and AI. HFT algorithms leverage powerful computational capabilities to analyze and execute trades at lightning speed, taking advantage of small price discrepancies and fleeting market opportunities. Machine learning techniques enable HFT systems to adapt to changing market conditions, optimize trade execution, and generate profits in highly competitive and fast-paced trading environments.</p>

<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>Machine learning and AI have revolutionized the e-Trading market, empowering traders with advanced tools, insights, and automation capabilities. From enhanced data analysis and algorithmic trading to risk management and market prediction, these technologies have transformed how financial markets operate. As machine learning and AI continue to evolve, we can expect further advancements in e-Trading, driving efficiency, accuracy, and profitability for traders and investors.</p>

<p>It&rsquo;s important to note that while AI brings significant benefits, human expertise remains crucial in interpreting AI-generated insights, ensuring regulatory compliance, and making strategic decisions. Combining the power of AI with human judgment and experience will lead to optimal results in the dynamic and complex world of e-Trading.</p>

<a name="References"></a>
<h3>References</h3>

<ul>
<li>Prendergast, K. (2018). &ldquo;Machine Learning in Algorithmic Trading.&rdquo; <a href="https://www.cognizant.com/whitepapers/machine-learning-in-algorithmic-trading-codex4391.pdf">https://www.cognizant.com/whitepapers/machine-learning-in-algorithmic-trading-codex4391.pdf</a></li>
<li>Zhang, H. (2018). &ldquo;Artificial Intelligence in Finance: Applications and Possibilities.&rdquo; <a href="https://www.cognizant.com/whitepapers/artificial-intelligence-in-finance-applications-and-possibilities-codex4583.pdf">https://www.cognizant.com/whitepapers/artificial-intelligence-in-finance-applications-and-possibilities-codex4583.pdf</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unleashing the Power of AI Transformer: Revolutionizing Artificial Intelligence]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/unleashing-the-power-of-ai-transformer-revolutionizing-artificial-intelligence/"/>
    <updated>2023-05-22T18:57:12+05:30</updated>
    <id>https://rishijeet.github.io/blog/unleashing-the-power-of-ai-transformer-revolutionizing-artificial-intelligence</id>
    <content type="html"><![CDATA[<p>In recent years, the field of artificial intelligence (AI) has witnessed a groundbreaking advancement with the introduction of the AI Transformer model. Inspired by the Transformer architecture, which gained fame for its effectiveness in natural language processing tasks, the AI Transformer has emerged as a powerful tool that revolutionizes various domains, including language translation, image recognition, and speech synthesis. In this blog, we will explore the capabilities and impact of the AI Transformer model, shedding light on its remarkable contributions to the world of AI.</p>

<a name="Understanding-the-Transformer-Architecture"></a>
<h5>Understanding the Transformer Architecture</h5>

<p>The Transformer architecture, initially introduced for machine translation tasks, reshaped the landscape of AI. Unlike traditional recurrent neural networks (RNNs) or convolutional neural networks (CNNs), the Transformer model leverages a self-attention mechanism, enabling it to capture global dependencies in the input data efficiently. This architecture eliminates the need for sequential processing and allows for parallelization, resulting in faster and more accurate predictions.</p>

<a name="Language-Translation-Advancements"></a>
<h5>Language Translation Advancements</h5>

<p>One of the key applications of the AI Transformer is language translation. With its ability to handle long-range dependencies and capture contextual information effectively, the AI Transformer has significantly improved the quality of machine translation systems. The model&rsquo;s attention mechanism enables it to attend to relevant parts of the input text, producing more accurate and coherent translations across different languages. This breakthrough has bridged communication gaps and fostered cross-cultural understanding on a global scale.</p>

<a name="Image-Recognition-and-Computer-Vision"></a>
<h5>Image Recognition and Computer Vision</h5>

<p>The impact of the AI Transformer extends beyond natural language processing. In the realm of computer vision, the model has demonstrated remarkable performance in image recognition tasks. By leveraging the self-attention mechanism, the AI Transformer can analyze and interpret complex visual data, leading to more accurate object detection, image segmentation, and scene understanding. This has paved the way for advancements in autonomous vehicles, robotics, medical imaging, and various other industries reliant on computer vision technologies.</p>

<!-- more -->


<a name="Speech-Synthesis-and-Natural-Language-Generation"></a>
<h5>Speech Synthesis and Natural Language Generation</h5>

<p>Another domain where the AI Transformer has left an indelible mark is speech synthesis and natural language generation. By leveraging its ability to learn dependencies and patterns in sequential data, the AI Transformer can generate human-like speech and produce coherent and contextually relevant text. This has found applications in voice assistants, audiobooks, accessibility technologies, and more, enhancing the overall user experience and accessibility of information.</p>

<a name="Challenges-and-Future-Directions"></a>
<h5>Challenges and Future Directions</h5>

<p>While the AI Transformer has achieved remarkable success, there are still challenges to overcome. The model&rsquo;s immense computational requirements and memory constraints can pose difficulties for real-time and resource-limited applications. Researchers are continuously exploring techniques to optimize and compress the AI Transformer, enabling its deployment on edge devices and enhancing its efficiency.</p>

<p>The future of the AI Transformer holds tremendous promise. As advancements continue, we can expect the model to tackle more complex tasks, push the boundaries of AI capabilities, and facilitate breakthroughs in areas such as drug discovery, personalized medicine, recommendation systems, and intelligent virtual assistants.</p>

<a name="Conclusion"></a>
<h5>Conclusion</h5>

<p>The AI Transformer has emerged as a game-changer in the field of artificial intelligence. Its ability to capture long-range dependencies and understand context has revolutionized language translation, image recognition, speech synthesis, and natural language generation. As we delve deeper into the potential of the AI Transformer, we can anticipate transformative advancements across various domains, propelling us toward a future where AI seamlessly integrates into our daily lives.</p>

<p>Through continued research and development, the AI Transformer will undoubtedly contribute to the evolution of AI, driving innovation and enhancing the way we interact with technology. Brace yourself for a future where the power of the AI Transformer shapes the world as we know it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Dynamic Web Applications with React and Firebase]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/building-dynamic-web-applications-with-react-and-firebase/"/>
    <updated>2023-05-22T13:22:00+05:30</updated>
    <id>https://rishijeet.github.io/blog/building-dynamic-web-applications-with-react-and-firebase</id>
    <content type="html"><![CDATA[<p>In recent years, React has emerged as a popular JavaScript library for building user interfaces, while Firebase has become a powerful platform for developing and deploying web applications. When combined, React and Firebase provide developers with a robust toolkit for creating dynamic and real-time web applications. In this blog, we will explore the integration of React and Firebase, highlighting the benefits and demonstrating how they work seamlessly together.</p>

<a name="An-Overview-of-React-and-Firebase"></a>
<h4>An Overview of React and Firebase</h4>

<p>React is a JavaScript library developed by Facebook, designed to build reusable and interactive user interfaces. It follows a component-based architecture that allows developers to create modular and reusable UI elements, making it easier to manage complex web applications.</p>

<p>Firebase, on the other hand, is a comprehensive platform developed by Google for building web and mobile applications. It offers a wide range of services, including real-time database, authentication, hosting, cloud functions, and more. Firebase simplifies the backend infrastructure, enabling developers to focus on the frontend development and user experience.</p>

<a name="Setting-Up-a-React-App-with-Firebase"></a>
<h4>Setting Up a React App with Firebase</h4>

<p>To get started with React and Firebase, you&rsquo;ll need to set up a React project and integrate Firebase into it. This involves creating a new React app using tools like Create React App and configuring Firebase SDKs and authentication methods. Once set up, you can leverage Firebase services within your React components, making API calls, handling user authentication, and storing data.</p>

<!-- more -->


<a name="Real-2d-time-Data-Synchronization-with-Firebase-Realtime-Database"></a>
<h4>Real-time Data Synchronization with Firebase Realtime Database</h4>

<p>Firebase Realtime Database is a NoSQL cloud database that allows you to store and synchronize data in real-time across multiple clients. With React, you can seamlessly integrate Firebase Realtime Database to create real-time collaborative applications, chat applications, live dashboards, and more. React&rsquo;s state management and Firebase&rsquo;s real-time synchronization capabilities work together to provide a smooth and responsive user experience.</p>

<a name="User-Authentication-with-Firebase-Authentication"></a>
<h4>User Authentication with Firebase Authentication</h4>

<p>Firebase Authentication provides an easy-to-use authentication system that allows users to sign up, sign in, and manage their accounts securely. React can leverage Firebase Authentication to implement features like user registration, login, password reset, and social media authentication within your application. React&rsquo;s component-driven approach can help create a seamless and intuitive user interface for handling authentication flows.</p>

<a name="Deploying-React-Apps-with-Firebase-Hosting"></a>
<h4>Deploying React Apps with Firebase Hosting</h4>

<p>Once your React app is ready, Firebase Hosting enables you to deploy your application with ease. It provides a fast and secure hosting solution for your static assets, including HTML, CSS, JavaScript, and other resources. Firebase Hosting also supports features like custom domains, SSL certificates, and automatic deployments, simplifying the process of launching your React app to the web.</p>

<a name="Cloud-Functions-and-Serverless-Computing"></a>
<h4>Cloud Functions and Serverless Computing</h4>

<p>Firebase Cloud Functions allows you to extend the functionality of your React app by running server-side code in a serverless environment. With Cloud Functions, you can perform server-side operations, process data, trigger events, and integrate with other services. React components can interact with Cloud Functions to offload heavy computation or perform backend tasks asynchronously.</p>

<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>React and Firebase provide a powerful combination for building dynamic and real-time web applications. React&rsquo;s component-driven architecture, along with Firebase&rsquo;s suite of services for data storage, authentication, hosting, and more, enables developers to create modern, responsive, and feature-rich web applications with ease. By leveraging the capabilities of React and Firebase, developers can focus on delivering exceptional user experiences while minimizing the complexity of backend infrastructure development. Whether you&rsquo;re building a small project or a large-scale application, the React-Firebase duo offers a comprehensive toolkit to bring your ideas to life.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web 3.0 - How does it impacts IOT ?]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/web-3-dot-0-how-does-it-impacts-iot/"/>
    <updated>2023-05-22T13:13:54+05:30</updated>
    <id>https://rishijeet.github.io/blog/web-3-dot-0-how-does-it-impacts-iot</id>
    <content type="html"><![CDATA[<p>Web 3.0 has a significant impact on the Internet of Things (IoT) by enhancing its capabilities, security, and interoperability. Here are some key ways in which Web 3.0 transforms the IoT landscape:</p>

<ul>
<li><p>Decentralized Data Management: Web 3.0 leverages blockchain technology to create decentralized data marketplaces and storage solutions. This allows IoT devices to securely and autonomously store and exchange data without relying on centralized servers or intermediaries. Decentralization increases data privacy and reduces the risk of data breaches.</p></li>
<li><p>Enhanced Security and Privacy: With Web 3.0, IoT devices can leverage blockchain&rsquo;s cryptographic techniques to establish secure communication channels and ensure data integrity. By eliminating single points of failure and relying on consensus mechanisms, Web 3.0 provides a more robust security framework for IoT devices, mitigating risks associated with hacking, tampering, and unauthorized access.</p></li>
<li><p>Interoperability and Standardization: Web 3.0 fosters interoperability among diverse IoT devices and platforms. By utilizing decentralized protocols and standards, Web 3.0 enables seamless communication and data exchange between different IoT devices and ecosystems. This interoperability unlocks new possibilities for cross-domain collaborations, creating a more connected and efficient IoT ecosystem.</p></li>
</ul>


<!-- more -->


<ul>
<li><p>Autonomous Device-to-Device Transactions: Web 3.0, powered by smart contracts, enables autonomous transactions between IoT devices. Devices can negotiate and execute agreements based on predefined conditions, eliminating the need for intermediaries. For example, smart contracts can enable devices to autonomously manage energy consumption, negotiate pricing, or perform self-maintenance tasks, enhancing the efficiency and automation of IoT networks.</p></li>
<li><p>Monetization of IoT Data: Web 3.0 introduces decentralized data marketplaces, where IoT device owners can securely and transparently monetize their data. Through blockchain-based platforms, device-generated data can be tokenized, allowing users to retain ownership and control over their data while selling or sharing it with interested parties. This opens up new revenue streams and incentives for IoT device owners.</p></li>
<li><p>Edge Computing and Reduced Latency: Web 3.0 leverages edge computing to process and analyze IoT data at the network edge, closer to the devices generating the data. This reduces latency and enables real-time decision-making, making IoT applications more responsive and efficient. Edge computing also reduces the reliance on centralized cloud servers, improving scalability and reliability in IoT deployments.</p></li>
<li><p>Trust and Accountability: Web 3.0&rsquo;s transparent and immutable nature, powered by blockchain, enhances trust and accountability in the IoT ecosystem. Device behavior and data transactions can be recorded on the blockchain, creating an auditable and tamper-proof record. This fosters trust among stakeholders and enables better accountability in areas such as supply chain management, autonomous vehicles, and healthcare.</p></li>
</ul>


<p>In conclusion, Web 3.0 revolutionizes the Internet of Things by providing a decentralized, secure, and interoperable framework. It enhances data privacy, enables autonomous transactions, fosters trust, and unlocks new opportunities for monetization and collaboration. Web 3.0&rsquo;s integration with IoT promises a more connected, efficient, and trustworthy future for smart devices and applications.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web 3.0 - Decentralizing Internet]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/web-3-dot-0-decentralizing-internet/"/>
    <updated>2022-10-29T22:04:22+05:30</updated>
    <id>https://rishijeet.github.io/blog/web-3-dot-0-decentralizing-internet</id>
    <content type="html"><![CDATA[<p>The Internet has become an integral part of our lives, transforming the way we communicate, work, and access information. From the early days of Web 1.0, where static websites provided basic information, to the dynamic and interactive Web 2.0 era that brought social media, online collaboration, and user-generated content, the Internet has continuously evolved. Now, a new paradigm shift is on the horizon - Web 3.0. In this blog, we will explore the exciting possibilities and potential of Web 3.0, a decentralized and user-centric vision of the future internet.</p>

<ul>
<li>Defining Web 3.0: Decentralization and Interoperability</li>
</ul>


<p>Web 3.0, often referred to as the &ldquo;Decentralized Web,&rdquo; represents a departure from the centralized systems that dominate the current internet landscape. It is built on principles of decentralization, interoperability, and enhanced user control. Unlike Web 2.0, which relies heavily on centralized platforms and intermediaries, Web 3.0 envisions a distributed network where users have greater ownership and control over their data and digital identities.</p>

<ul>
<li>Blockchain Technology: The Backbone of Web 3.0</li>
</ul>


<p>At the core of Web 3.0 lies blockchain technology, the decentralized ledger system that underpins cryptocurrencies like Bitcoin and Ethereum. Blockchain provides a transparent, tamper-proof, and secure way to record and verify digital transactions. With Web 3.0, blockchain expands its scope beyond financial applications, enabling the development of decentralized applications (dApps), smart contracts, and decentralized autonomous organizations (DAOs).</p>

<!-- more -->


<ul>
<li>Decentralized Applications (dApps): Empowering Users</li>
</ul>


<p>Web 3.0 empowers users by placing them at the center of the internet experience. Decentralized applications (dApps) are one of the cornerstones of Web 3.0, offering users greater control, privacy, and ownership of their data. dApps leverage blockchain&rsquo;s decentralized nature to eliminate middlemen, reduce censorship, and enable direct peer-to-peer interactions. These applications span various domains, including finance, healthcare, supply chain management, and social media.</p>

<ul>
<li>Smart Contracts: Trust and Automation</li>
</ul>


<p>Smart contracts, powered by blockchain technology, are self-executing agreements that automatically enforce the terms and conditions encoded within them. Web 3.0 leverages smart contracts to facilitate trust and automation in a wide range of transactions. These contracts eliminate the need for intermediaries, reducing costs, increasing efficiency, and ensuring transparency. Smart contracts have the potential to revolutionize industries such as real estate, insurance, and intellectual property rights.</p>

<ul>
<li>Enhanced Privacy and Security</li>
</ul>


<p>Web 3.0 addresses growing concerns about data privacy and security. By leveraging decentralized systems and cryptographic techniques, Web 3.0 offers enhanced privacy protection. Users have greater control over their personal information, deciding when and how it is shared. Moreover, the decentralized nature of Web 3.0 reduces the risk of data breaches and single points of failure, enhancing overall security and resilience.</p>

<ul>
<li>The Internet of Things (IoT) in Web 3.0</li>
</ul>


<p>Web 3.0 integrates the Internet of Things (IoT) into its fabric, enabling seamless connectivity and communication between devices.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rest API with Go &amp; Gorilla Mux]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/rest-api-with-go-and-gorilla-mux/"/>
    <updated>2021-02-20T23:12:49+05:30</updated>
    <id>https://rishijeet.github.io/blog/rest-api-with-go-and-gorilla-mux</id>
    <content type="html"><![CDATA[<p>Gorilla is a web toolkit for the Go programming language. The gorilla/mux implements a request router and dispatcher for matching incomings requests to the respective handlers.</p>

<p>One of the cool feature it has is that the registered URLs can be built or reversed which helps maintaining the references to resources and nested routes are only tested if the parent route matches. This is useful to define groups of routes that share common conditions like a host, a path prefix or other repeated attributes.</p>

<!-- more -->


<p>The routes can be declared as mentioned below</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">func</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">r</span> <span class="o">:=</span> <span class="nx">mux</span><span class="p">.</span><span class="nx">NewRouter</span><span class="p">()</span>
</span><span class='line'>    <span class="nx">r</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/&quot;</span><span class="p">,</span> <span class="nx">HomeHandler</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">r</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/users&quot;</span><span class="p">,</span> <span class="nx">UsersHandler</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">r</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/blogs&quot;</span><span class="p">,</span> <span class="nx">BlogHandler</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">http</span><span class="p">.</span><span class="nx">Handle</span><span class="p">(</span><span class="s">&quot;/&quot;</span><span class="p">,</span> <span class="nx">r</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The basic http server code</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="c1">// Author: Rishijeet Mishra</span>
</span><span class='line'><span class="kn">package</span> <span class="nx">main</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="p">(</span>
</span><span class='line'>    <span class="s">&quot;net/http&quot;</span>
</span><span class='line'>    <span class="s">&quot;encoding/json&quot;</span>
</span><span class='line'>    <span class="s">&quot;log&quot;</span>
</span><span class='line'>    <span class="s">&quot;github.com/gorilla/mux&quot;</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="kd">func</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">router</span> <span class="o">:=</span> <span class="nx">mux</span><span class="p">.</span><span class="nx">NewRouter</span><span class="p">()</span>
</span><span class='line'>    <span class="c1">// Routes consist of a path and a handler function.</span>
</span><span class='line'>    <span class="nx">router</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/myhandler&quot;</span><span class="p">,</span> <span class="nx">MyHandler</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Bind to a port and pass our router in</span>
</span><span class='line'>    <span class="nx">log</span><span class="p">.</span><span class="nx">Fatal</span><span class="p">(</span><span class="nx">http</span><span class="p">.</span><span class="nx">ListenAndServe</span><span class="p">(</span><span class="s">&quot;:5000&quot;</span><span class="p">,</span> <span class="nx">router</span><span class="p">))</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kd">func</span> <span class="nx">MyHandler</span><span class="p">(</span><span class="nx">w</span> <span class="nx">http</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span> <span class="nx">r</span> <span class="o">*</span><span class="nx">http</span><span class="p">.</span><span class="nx">Request</span><span class="p">){</span>
</span><span class='line'>    <span class="c1">//w.Write([]byte(&quot;The page to be rendered&quot;))</span>
</span><span class='line'>    <span class="nx">w</span><span class="p">.</span><span class="nx">Header</span><span class="p">().</span><span class="nx">Set</span><span class="p">(</span><span class="s">&quot;Content-Type&quot;</span><span class="p">,</span> <span class="s">&quot;application/json&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">json</span><span class="p">.</span><span class="nx">NewEncoder</span><span class="p">(</span><span class="nx">w</span><span class="p">).</span><span class="nx">Encode</span><span class="p">(</span><span class="kd">struct</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="nx">key</span> <span class="kt">string</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="s">&quot;value&quot;</span>
</span><span class='line'>    <span class="p">}</span> <span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s add the POST method</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="c1">// Add the route</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="nx">r</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/add/{item}&quot;</span><span class="p">,</span> <span class="nx">addItem</span><span class="p">).</span><span class="nx">Methods</span><span class="p">(</span><span class="s">&quot;POST&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">//Add the func</span>
</span><span class='line'>
</span><span class='line'><span class="kd">func</span> <span class="nx">addItem</span><span class="p">(</span><span class="nx">w</span> <span class="nx">http</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span> <span class="nx">r</span> <span class="o">*</span><span class="nx">http</span><span class="p">.</span><span class="nx">Request</span><span class="p">){</span>
</span><span class='line'>    <span class="nx">itemholder</span>  <span class="o">:=</span> <span class="nx">mux</span><span class="p">.</span><span class="nx">Vars</span><span class="p">(</span><span class="nx">r</span><span class="p">)[</span><span class="err">&#39;</span><span class="nx">item</span><span class="err">&#39;</span><span class="p">]</span>
</span><span class='line'>    <span class="nx">data</span> <span class="p">=</span> <span class="nb">append</span><span class="p">(</span> <span class="nx">data</span><span class="p">,</span> <span class="nx">itemholder</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">json</span><span class="p">.</span><span class="nx">NewEncoder</span><span class="p">(</span><span class="nx">w</span><span class="p">).</span><span class="nx">Encode</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s add the GET</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="c1">// The struct for grouping</span>
</span><span class='line'><span class="kd">type</span> <span class="nx">Item</span> <span class="kd">struct</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">Data</span> <span class="kt">string</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kd">var</span> <span class="nx">data</span> <span class="p">[]</span><span class="nx">Item</span> <span class="p">=</span> <span class="p">[]</span><span class="nx">Item</span><span class="p">{}</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="kd">func</span> <span class="nx">addItem</span><span class="p">(</span><span class="nx">w</span> <span class="nx">http</span><span class="p">.</span><span class="nx">ResponseWriter</span><span class="p">,</span> <span class="nx">r</span> <span class="o">*</span><span class="nx">http</span><span class="p">.</span><span class="nx">Request</span><span class="p">){</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">var</span> <span class="nx">latestItem</span> <span class="nx">Item</span>
</span><span class='line'>    <span class="nx">json</span><span class="p">.</span><span class="nx">NewDecoder</span><span class="p">(</span><span class="nx">r</span><span class="p">.</span><span class="nx">Body</span><span class="p">).</span><span class="nx">Decode</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">latestItem</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">data</span> <span class="p">=</span> <span class="nb">append</span><span class="p">(</span> <span class="nx">data</span><span class="p">,</span> <span class="nx">latestItem</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// output the json</span>
</span><span class='line'>    <span class="nx">w</span><span class="p">.</span><span class="nx">Header</span><span class="p">().</span><span class="nx">Set</span><span class="p">(</span><span class="s">&quot;Content-Type&quot;</span><span class="p">,</span> <span class="s">&quot;application/json&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">json</span><span class="p">.</span><span class="nx">NewEncoder</span><span class="p">(</span><span class="nx">w</span><span class="p">).</span><span class="nx">Encode</span><span class="p">(</span><span class="nx">data</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Mux supports the addition of middlewares to a Router, which are executed in the order they are added if a match is found, including its subrouters. Middlewares are (typically) small pieces of code which take one request, do something with it, and pass it down to another middleware or the final handler.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='batch'><span class='line'>type MiddlewareFunc func(http.Handler) http.Handler
</span><span class='line'>
</span><span class='line'><span class="n">//Add</span> the middleware to the route
</span><span class='line'>r :<span class="o">=</span> mux.NewRouter()
</span><span class='line'>r.HandleFunc(<span class="s2">&quot;/&quot;</span><span class="p">,</span> handler)
</span><span class='line'>r.Use(loggingMiddleware)
</span></code></pre></td></tr></table></div></figure>


<p>Click for more details on the <a href="https://github.com/gorilla/mux">gorilla/mux</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tuning Apache Kafka’s performance]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/tuning-apache-kafkas-performance/"/>
    <updated>2019-07-11T11:42:32+05:30</updated>
    <id>https://rishijeet.github.io/blog/tuning-apache-kafkas-performance</id>
    <content type="html"><![CDATA[<p>Well, Apache Kafka is one of the best pub-sub messaging system used widely across several technology’s based industries. Originated at LinkedIn and was open sourced in early 2011.</p>

<p>Ok, so what so special about <strong>Apache Kafka</strong> ? Here are the few things Kafka is meant to handle.</p>

<ul>
<li>High throughput to support large volume event feeds.</li>
<li>Real time processing of enormous amount of data.</li>
<li>Support large data backlogs to handle periodic ingestion from offline systems.</li>
<li>Support low - latency delivery of the messages compared to other messaging systems</li>
<li>High Availability, Fault Tolerance.</li>
</ul>


<p>So what else are you looking ?</p>

<!--more-->


<p>Now if you know about Apache Kafka a bit, here are few things we can fine tune to make it better in terms of performance. Let’s categories the system into the following aspects and see what could be done in each space.</p>

<ul>
<li>Producers</li>
<li>Brokers</li>
<li>Consumers</li>
</ul>


<a name="Producers"></a>
<h2>Producers</h2>

<a name="Asynchronous"></a>
<h3>Asynchronous</h3>

<p>Now think, how long you want to wait for the ack on the message sent to the broker ? Answer to this question will change the speed of handling the messages in the Kafka.</p>

<p>request.required.acks is the property of the producer.</p>

<p>Possible values for this are:</p>

<ul>
<li><code>0</code> = producer never waits for the ack from the broker. This will give you “Least durability and least latency”.</li>
<li><code>1</code> = producer gets ack from the master replica. This will give you “some durability and less latency”.</li>
<li><code>-1</code> = producer gets ack from the all the replicas. This will give you “most durability and most latency”.</li>
</ul>


<a name="Batching"></a>
<h3>Batching</h3>

<p>How about batching the messages ? Let’s use the asynchronous producers.</p>

<p><code>producer.type=1</code> to make the producers run async.</p>

<p>You can get the “callback” for the messages here to know their status. Now batch your messages to the brokers in different threads, this will improve the throughput. Some configuration to handle the messages in this scenario are:</p>

<ul>
<li><code>queue.buffer.max.ms</code> - Duration of the batch window.</li>
<li><code>batch.num.messages</code> - Number of messages to be sent in a batch.</li>
</ul>


<a name="Compression"></a>
<h3>Compression</h3>

<p>Use the compression property to reduces the I/O on the machine. We might also want to think of the CPU load when it decompresses the message object back. So, maintain a balance between the two. compression.codec - Values are none, gzip and snappy</p>

<p>For presumably large messages say - 10G , you might want to pass the file location of the share drive in the maessage rather than the payload itself. This would be tremendously faster.</p>

<a name="Timeout"></a>
<h3>Timeout</h3>

<p>Don’t wait for the message unnecessarily unless its is really really required. Have a “timeout”</p>

<p><code>request.timeout.ms</code> - The time until the broker waits before sending error back to the client.
Amount of time to block before dropping the messages when running in async mode ( default = indefinitely )</p>

<a name="Brokers"></a>
<h2>Brokers</h2>

<a name="Partition"></a>
<h3>Partition</h3>

<p>Plan to have as number of partitions = number of consumers. This will increase the concurrency, the more the partitions the more the concurrency. Remember, more the partitions more the latency too. Also, recommended to have one partition per physical disk to ensure I/O is not the bottleneck while writing the logs.</p>

<p>Use “kafka-reassign-partitions.sh” to ensure partition is not overloaded.</p>

<p>Some of the configurations worth mentioning here are:</p>

<ul>
<li><code>num.io.threads</code> - The number of I/O threads server uses to execute the requests.</li>
<li><code>num.partitions</code> - Number of partitions per topic</li>
<li><code>log.flush.interval,messages</code> - The number of messages written to the log partition before we force an fsync on the log.</li>
</ul>


<a name="Consumers"></a>
<h2>Consumers</h2>

<p>The max number of consumers for the topic is equal to number of partitions. Have enough partitions to handle all the consumers in your Kafka’s ecosystem.</p>

<p>Consumer in the same consumer group split the partitions among themselves. Adding more consumers to a group can enhance performance.</p>

<p>Performance is not affected by adding more consumer groups</p>

<p><code>replica.high.watermark.checkpoint.interval.ms</code> can affect the throughput. When reading from partition, you can mark the last point where you read the information. If you set checkpoint watermark for every event, you will have high durability but hit on the performance. Rather, set it to check the offset for every x number of messages wherein you have margin of safety and will less impact your throughput.</p>

<a name="Timeout"></a>
<h3>Timeout</h3>

<p>Choose the timeouts and onward pipeline properly. Also, refer to Apache Kafka doc for setting fetch size, time, auto-commit etc.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Blockchain - Really worth in elections ?]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/blockchain-really-worth-in-elections/"/>
    <updated>2017-05-12T10:37:14+05:30</updated>
    <id>https://rishijeet.github.io/blog/blockchain-really-worth-in-elections</id>
    <content type="html"><![CDATA[<p>Issues with <strong>EVM ( Electronic Voting Machine )</strong> have been the talk of the town for quite a while in India nowadays. Political parties have been taking about going back to voting mechanism using ballot boxes, wherein there would be very less possibility of non-legitimate voting. EVMs are prone to hacking, untrusted votes, digital errors as explained by these political parties.</p>

<p>I ask you political parties this, why ballot boxes or directly &ldquo;why papers&rdquo; ? Why cut trees to achieve your goal considering the fact that, we are living in the - digital era with brilliant minds across the country to make things possible using technology.</p>

<p>The recent government (people too) has been keen towards its programme of Digital India.</p>

<!--more-->


<p>As the website says -</p>

<p><em>The Digital India programme is a flagship programme of the Government of India with a vision to transform India into a digitally empowered society and knowledge economy.</em></p>

<p>So why paper for casting votes ?</p>

<p>The question is - Can the blockchain technology solve this problem ?</p>

<p>The answer to the question is - Yes</p>

<p>Adopting to the Blockchain technology will not only ensure, that the vote casted is trusted but will also eradicate the underlying issues of hacking, third party dependency, voting transactions, fraud &amp; other securities hacks.</p>

<p>Importantly it will reduce the cost of elections drastically and the government could utilise its funds in other major projects. Note, the Loksabha election 2014 costed around <strong>3,500 crore</strong>.</p>

<p><img src="https://rishijeet.github.io/images/myimages/voting_places.png" alt="Alt text" /></p>

<p>Simple mechanism to understand this from blockchain perspective.</p>

<ul>
<li>Voting could be casted from any place on a particular day. This could be translated as <strong>NODES</strong> in blockchain.</li>
<li>Voting done at nodes could be validated by a elected nodes or electoral offices. This translates to <strong>MINERS</strong> in blockchain.</li>
<li>Elected nodes or electoral offices would update their transactions. This translates to <strong>SYNCHRONISATION</strong> ledger in blockchain.</li>
<li>Transactions are up to date at any electoral offices and results could be declared instantly on the same day if required.</li>
</ul>


<p>Government should just ensure the infrastructure is developed for this and is prioritise.</p>

<p>Let&rsquo;s all participate in making India a - <strong>Digital India</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fancybox2 to Fancybox3 for image gallery]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/fancybox2-to-fancybox3-for-image-gallery/"/>
    <updated>2017-05-12T09:58:37+05:30</updated>
    <id>https://rishijeet.github.io/blog/fancybox2-to-fancybox3-for-image-gallery</id>
    <content type="html"><![CDATA[<p>I recently migrated my image gallery to Fancybox3 from Fancybox2. Fancybox3 has some of the advantages over its previous version.
The important one I like is the fact that you have to code less.</p>

<ul>
<li>Import the javascript</li>
<li>Wrap the images with class and the work is done.</li>
<li>It supports the image security too. <i class="em em---1"></i>
<!-- more --></li>
</ul>


<p>Personally, I like the masonry style more and working on moving towards its soon. Still exploring the feasibility.
The details on the masonry grid could be found <a href="https://masonry.desandro.com/">here</a>.</p>

<p>Did you notice the masonry grid used in <a href="http://iam.beyonce.com/tagged/my_work">Beyonce&rsquo;s Website</a> ? <i class="em em-blush"></i></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Distributed Computing - Quorum]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/distributed-computing/"/>
    <updated>2016-09-04T18:40:02+05:30</updated>
    <id>https://rishijeet.github.io/blog/distributed-computing</id>
    <content type="html"><![CDATA[<p>In a distributed database system, a transaction could be executing its operations at multiple sites. Since atomicity requires every distributed transaction to be atomic, the transaction must have the same fate (commit or abort) at every site. In case of network partitioning, sites are partitioned and the partitions may not be able to communicate with each other. This is where a quorum-based technique comes in. The fundamental idea is that a transaction is executed if the majority of sites vote to execute it.</p>

<a name="Quorum-Consensus-Protocol"></a>
<h4>Quorum Consensus Protocol</h4>

<p>This is one of the distributed lock manager based concurrency control protocol in distributed database systems. It works as follows;</p>

<ul>
<li>The protocol assigns each site that have a replica with a weight.</li>
<li>For any data item, the protocol assigns a read quorum Qr and write quorum Qw. Here, Qr and Qw are two integers (sum of weights of some sites). And, these two integers are chosen according to the following conditions put together;</li>
</ul>


<p><code>Qr + Qw &gt; S - rule which avoids read-write conflict. (i.e, two transactions cannot read and write concurrently)</code></p>

<p><code>2 * Qw &gt; S - rule which avoids write-write conflict. (i.e, two transactions cannot write concurrently)</code></p>

<p>Here, S is the total weight of all sites in which the data item replicated.</p>

<!-- more -->


<a name="How-do-we-perform-read-and-write-on-replicas-3f-"></a>
<h4>How do we perform read and write on replicas?</h4>

<ul>
<li>A transaction that needs a data item for reading purpose has to lock enough sites. ie, it has lock sites with the sum of their weight >= Qr. Read quorum must always intersect with write quorum.</li>
<li>A transaction that needs a data item for writing purpose has to lock enough sites. ie, it has lock sites with the sum of their weight >= Qw.</li>
</ul>


<a name="How-does-it-work-3f-"></a>
<h4>How does it work?</h4>

<p>Let us assume a fully replicated distributed database with four sites S1, S2, S3, and S4.</p>

<ol>
<li><p>According to the protocol, we need to assign a weight to every site. (This weight can be chosen on many factors like the availability of the site, latency etc.). For simplicity, let us assume the weight as 1 for all sites.</p></li>
<li><p>Let us choose the values for Qr and Qw as 2 and 3. Our total weight S is 4. And according to the conditions, our Qr and Qw values are correct;
<br>
<code>Qr + Qw &gt; S =&gt; 2 + 3 &gt; 4               True</code>
<br>
<code>2 * Qw  &gt; S =&gt; 2 * 3 &gt; 4               True</code>
<br></p></li>
<li>Now, a transaction which needs a read lock on a data item has to lock 2 sites. A transaction which needs a write lock on data item has to lock 3 sites.</li>
</ol>


<a name="Case-1-3c-code-3e--26-sup1-3b--3c--2f-code-3e-"></a>
<h6>Case 1<code>&sup1;</code></h6>

<p>Read Quorum Qr = 2, Write Quorum Qw = 3, Site’s weight = 1, Total weight of sites S = 4</p>

<ul>
<li>Read Lock

<ol>
<li>Read request has to lock at least two replicas (2 sites in our example)</li>
<li>Any two sites can be locked</li>
</ol>
</li>
<li>Write Lock

<ol>
<li>Write request has to lock at least three replicas (3 sites in our example)</li>
</ol>
</li>
</ul>


<a name="Case-2"></a>
<h6>Case 2</h6>

<p>Read Quorum Qr = 1, Write Quorum Qw = 4, Site’s weight = 1, Total weight of sites S = 4</p>

<ul>
<li>Read Lock

<ol>
<li>Read lock requires one site</li>
</ol>
</li>
<li>Write Lock

<ol>
<li>Write lock requires 4 sites</li>
</ol>
</li>
</ul>


<p><em><code>&sup1;</code>Points and example taken from web.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Is Microsoft biased towards Linux]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/is-microsoft-biased-towards-linux/"/>
    <updated>2016-03-11T09:45:09+05:30</updated>
    <id>https://rishijeet.github.io/blog/is-microsoft-biased-towards-linux</id>
    <content type="html"><![CDATA[<p>I see news about Microsoft crafted a switch OS on Debian Linux platform,  announcing its SQL server of Linux and may be some more. Though this is a surprising news as Microsoft windows has released its best OS so far, which is more stable and fast compare to its ancestors, so what could be the reason to move towards Linux is a question. Is this related to the security aspect of the operating system or is it the open source nature of the platform and the community support it has or is it just the recent decision to move towards it ? Whatever it is, I see this as a strong move towards making its environment and platform more robust and performant.</p>

<!-- more -->


<p>According to the Microsoft&rsquo;s Blog</p>

<p><i>
These improvements, and many more, are all built into SQL Server and bring you not just a new database but a complete platform for data management, business analytics and intelligent apps – one that can be used in a consistent way across both on-premises and the cloud. In fact, over the last year we’ve been using the SQL Server 2016 code-base to run in production more than 1.4 million SQL Databases in the cloud using our Azure SQL Database as a Service offering, and this real-world experience has made SQL Server 2016 an incredibly robust and battle-hardened data platform.
</i></p>


<p>
As the executive tells the New York Times, this is all about &#8220;market expansion.&#8221; Microsoft would rather corner the server software space, which has been shifting toward Linux, than insist on a Windows-only policy out of stubborn pride. It&#8217;s tough to know if the Linux server crowd will warm up to its longtime arch-rival, but those more open-minded firms are now free to integrate Microsoft without making a wholesale switch.
</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Memory Management in Python]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/memory-management-in-python/"/>
    <updated>2015-04-22T09:54:01+05:30</updated>
    <id>https://rishijeet.github.io/blog/memory-management-in-python</id>
    <content type="html"><![CDATA[<p>I came across the interesting write up somewhere on website on memory management in Python. Here are some data facts
which I liked,</p>

<p>Python allocates memory transparently, manages objects using a reference count system, and frees memory when an object’s reference count falls to zero. In theory, it’s swell. In practice, you need to know a few things about Python memory management to get a memory-efficient program running. One of the things you should know, or at least get a good feel about, is the sizes of basic Python objects. Another thing is how Python manages its memory internally.</p>

<p>So let us begin with the size of basic objects. In Python, there’s not a lot of primitive data types: there are ints, longs (an unlimited precision version of ints), floats (which are doubles), tuples, strings, lists, dictionaries, and classes.</p>

<!-- more -->


<p>What is the size of int? A programmer with a C or C++ background will probably guess that the size of a machine-specific int is something like 32 bits, maybe 64; and that therefore it occupies at most 8 bytes. But is that so in Python?</p>

<p>Let us first write a function that shows the sizes of objects (recursively if necessary):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">show_sizeof</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">print</span> <span class="s">&quot;</span><span class="se">\t</span><span class="s">&quot;</span> <span class="o">*</span> <span class="n">level</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">__class__</span><span class="p">,</span> <span class="n">sys</span><span class="o">.</span><span class="n">getsizeof</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s">&#39;__iter__&#39;</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s">&#39;items&#39;</span><span class="p">):</span>
</span><span class='line'>            <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span class='line'>                <span class="n">show_sizeof</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">level</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span class='line'>        <span class="k">else</span><span class="p">:</span>
</span><span class='line'>            <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
</span><span class='line'>                <span class="n">show_sizeof</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">level</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>We can now use the function to inspect the sizes of the different basic data types:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">show_sizeof</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
</span><span class='line'><span class="n">show_sizeof</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</span><span class='line'><span class="n">show_sizeof</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">63</span><span class="p">)</span>
</span><span class='line'><span class="n">show_sizeof</span><span class="p">(</span><span class="mi">102947298469128649161972364837164</span><span class="p">)</span>
</span><span class='line'><span class="n">show_sizeof</span><span class="p">(</span><span class="mi">918659326943756134897561304875610348756384756193485761304875613948576297485698417</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#If you have a 32-bit 2.7x Python, you’ll see:</span>
</span><span class='line'>
</span><span class='line'><span class="mi">8</span> <span class="bp">None</span>
</span><span class='line'><span class="mi">12</span> <span class="mi">3</span>
</span><span class='line'><span class="mi">22</span> <span class="mi">9223372036854775808</span>
</span><span class='line'><span class="mi">28</span> <span class="mi">102947298469128649161972364837164</span>
</span><span class='line'><span class="mi">48</span> <span class="mi">918659326943756134897561304875610348756384756193485761304875613948576297485698417</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="c">#and if you have a 64-bit 2.7x Python, you’ll see:</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="mi">16</span> <span class="bp">None</span>
</span><span class='line'><span class="mi">24</span> <span class="mi">3</span>
</span><span class='line'><span class="mi">36</span> <span class="mi">9223372036854775808</span>
</span><span class='line'><span class="mi">40</span> <span class="mi">102947298469128649161972364837164</span>
</span><span class='line'><span class="mi">60</span> <span class="mi">918659326943756134897561304875610348756384756193485761304875613948576297485698417</span>
</span></code></pre></td></tr></table></div></figure>


<p>Let us focus on the 64-bit version (mainly because that’s what we need the most often in our case). None takes 16 bytes. int takes 24 bytes, three times as much memory as a C int64_t, despite being some kind of “machine-friendly” integer. Long integers (unbounded precision), used to represent integers larger than 263-1, have a minimum size of 36 bytes. Then it grows linearly in the logarithm of the integer represented.</p>

<p>Python’s floats are implementation-specific but seem to be C doubles. However, they do not eat up only 8 bytes:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">show_sizeof</span><span class="p">(</span><span class="mf">3.14159265358979323846264338327950288</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Output</span>
</span><span class='line'>
</span><span class='line'><span class="mi">16</span> <span class="mf">3.14159265359</span>
</span><span class='line'>
</span><span class='line'><span class="c">#on a 32-bit platform and</span>
</span><span class='line'>
</span><span class='line'><span class="mi">24</span> <span class="mf">3.14159265359</span>
</span><span class='line'><span class="c">#on a 64-bit platform.</span>
</span></code></pre></td></tr></table></div></figure>


<p>That’s again, three times the size a C programmer would expect. Now, what about strings?</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">show_sizeof</span><span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">show_sizeof</span><span class="p">(</span><span class="s">&quot;My hovercraft is full of eels&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>outputs, on a 32 bit platform:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="mi">21</span>
</span><span class='line'><span class="mi">50</span> <span class="n">My</span> <span class="n">hovercraft</span> <span class="ow">is</span> <span class="n">full</span> <span class="n">of</span> <span class="n">eels</span>
</span></code></pre></td></tr></table></div></figure>


<p>and</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="mi">37</span>
</span><span class='line'><span class="mi">66</span> <span class="n">My</span> <span class="n">hovercraft</span> <span class="ow">is</span> <span class="n">full</span> <span class="n">of</span> <span class="n">eels</span>
</span></code></pre></td></tr></table></div></figure>


<p>An empty string costs 37 bytes in a 64-bit environment! Memory used by string then linearly grows in the length of the (useful) string.</p>

<p>Other structures commonly used, tuples, lists, and dictionaries are worthwhile to examine. Lists (which are implemented as array lists, not as linked lists, with everything it entails) are arrays of references to Python objects, allowing them to be heterogeneous. Let us look at our sizes:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">show_sizeof</span><span class="p">([])</span>
</span><span class='line'><span class="n">show_sizeof</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="s">&quot;toaster&quot;</span><span class="p">,</span> <span class="mf">230.1</span><span class="p">])</span>
</span><span class='line'><span class="c">#outputs</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="mi">32</span> <span class="p">[]</span>
</span><span class='line'><span class="mi">44</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="s">&#39;toaster&#39;</span><span class="p">,</span> <span class="mf">230.1</span><span class="p">]</span>
</span><span class='line'><span class="c">#on a 32-bit platform and</span>
</span><span class='line'>
</span><span class='line'><span class="mi">72</span> <span class="p">[]</span>
</span><span class='line'><span class="mi">96</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="s">&#39;toaster&#39;</span><span class="p">,</span> <span class="mf">230.1</span><span class="p">]</span>
</span><span class='line'><span class="c">#on a 64-bit platform. </span>
</span></code></pre></td></tr></table></div></figure>


<p>An empty list eats up 72 bytes. The size of an empty, 64-bit C++ std::list() is only 16 bytes,
 4-5 times less. What about tuples? (and dictionaries?):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">show_sizeof</span><span class="p">({})</span>
</span><span class='line'><span class="n">show_sizeof</span><span class="p">({</span><span class="s">&#39;a&#39;</span><span class="p">:</span><span class="mi">213</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">:</span><span class="mi">2131</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>outputs, on a 32-bit box</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="mi">136</span> <span class="p">{}</span>
</span><span class='line'> <span class="mi">136</span> <span class="p">{</span><span class="s">&#39;a&#39;</span><span class="p">:</span> <span class="mi">213</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">:</span> <span class="mi">2131</span><span class="p">}</span>
</span><span class='line'>        <span class="mi">32</span> <span class="p">(</span><span class="s">&#39;a&#39;</span><span class="p">,</span> <span class="mi">213</span><span class="p">)</span>
</span><span class='line'>                <span class="mi">22</span> <span class="n">a</span>
</span><span class='line'>                <span class="mi">12</span> <span class="mi">213</span>
</span><span class='line'>        <span class="mi">32</span> <span class="p">(</span><span class="s">&#39;b&#39;</span><span class="p">,</span> <span class="mi">2131</span><span class="p">)</span>
</span><span class='line'>                <span class="mi">22</span> <span class="n">b</span>
</span><span class='line'>                <span class="mi">12</span> <span class="mi">2131</span>
</span><span class='line'><span class="ow">and</span>
</span><span class='line'>
</span><span class='line'><span class="mi">280</span> <span class="p">{}</span>
</span><span class='line'> <span class="mi">280</span> <span class="p">{</span><span class="s">&#39;a&#39;</span><span class="p">:</span> <span class="mi">213</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">:</span> <span class="mi">2131</span><span class="p">}</span>
</span><span class='line'>        <span class="mi">72</span> <span class="p">(</span><span class="s">&#39;a&#39;</span><span class="p">,</span> <span class="mi">213</span><span class="p">)</span>
</span><span class='line'>                <span class="mi">38</span> <span class="n">a</span>
</span><span class='line'>                <span class="mi">24</span> <span class="mi">213</span>
</span><span class='line'>        <span class="mi">72</span> <span class="p">(</span><span class="s">&#39;b&#39;</span><span class="p">,</span> <span class="mi">2131</span><span class="p">)</span>
</span><span class='line'>                <span class="mi">38</span> <span class="n">b</span>
</span><span class='line'>                <span class="mi">24</span> <span class="mi">2131</span>
</span><span class='line'>
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>


<p>for a 64-bit box.</p>

<p>This last example is particularly interesting because it “doesn’t add up.” If we look at individual key/value pairs, they take 72 bytes (while their components take 38+24=62 bytes, leaving 10 bytes for the pair itself), but the dictionary takes 280 bytes (rather than a strict minimum of 144=72×2 bytes). The dictionary is supposed to be an efficient data structure for search and the two likely implementations will use more space that strictly necessary. If it’s some kind of tree, then we should pay the cost of internal nodes that contain a key and two pointers to children nodes; if it’s a hash table, then we must have some room with free entries to ensure good performance.</p>

<p>The (somewhat) equivalent <code>std::map</code> C++ structure takes 48 bytes when created (that is,
empty). An empty C++ string takes 8 bytes (then allocated size grows linearly the size of the string). An integer takes 4 bytes (32 bits).</p>

<p>Why does all this matter? It seems that whether an empty string takes 8 bytes or 37 doesn’t change anything much
. That’s true. That’s true until you need to scale. Then, you need to be really careful about how many objects you
create to limit the quantity of memory your program uses. It is a problem in real-life applications. However, to devise a really good strategy about memory management, we must not only consider the sizes of objects, but how many and in which order they are created. It turns out to be very important for Python programs. One key element to understand is how Python allocates its memory internally, which we will discuss next.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VMware Player and Hyper-V are not compatible]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/vmware-player-and-hyper-v-are-not-compatible/"/>
    <updated>2015-04-12T11:28:34+05:30</updated>
    <id>https://rishijeet.github.io/blog/vmware-player-and-hyper-v-are-not-compatible</id>
    <content type="html"><![CDATA[<p>I run my VMs using vmware player for multiple operating system like Ubuntu, CentOS, Fedora, Suse,
Mint Linux. One fine day I noticed this error &ldquo;VMware Player and Hyper-V are not compatible&rdquo; from the vmplayer while
starting Ubuntu. This was bit surprising for me as I had run the same vm couple of times.</p>

<p>I realized that disabling the hyper-V could fix this problem, but I was still curious,
as of why could this start all of sudden?</p>

<!-- more -->


<p>The fix was simple as I said, to disable hyper-V</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='batch'><span class='line'>bcdedit <span class="n">/set</span> hypervisorlaunchtype <span class="k">off</span>
</span></code></pre></td></tr></table></div></figure>


<p>Rebooting the window&rsquo;s machine after running above command from command prompt with admin privilege fixes the problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jekyll Simply So Simple]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/jekyll-simply-so-simple/"/>
    <updated>2014-09-15T22:36:38+05:30</updated>
    <id>https://rishijeet.github.io/blog/jekyll-simply-so-simple</id>
    <content type="html"><![CDATA[<p><img src="https://rishijeet.github.io/images/jekyll.png" height="100" width="100" alt="Alt text" /></p>

<p>Jekyll one of the fast and simple static html page generator is really easy to start of with. I am so addicted to it now. Still exploring it more, there are so many features available and installing it
is as easy as it can be.</p>

<!-- more -->


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="o">~</span> <span class="err">$</span> <span class="n">gem</span> <span class="n">install</span> <span class="n">jekyll</span>
</span><span class='line'><span class="o">~</span> <span class="err">$</span> <span class="n">jekyll</span> <span class="kp">new</span> <span class="n">my</span><span class="o">-</span><span class="n">awesome</span><span class="o">-</span><span class="n">site</span>
</span><span class='line'><span class="o">~</span> <span class="err">$</span> <span class="n">cd</span> <span class="n">my</span><span class="o">-</span><span class="n">awesome</span><span class="o">-</span><span class="n">site</span>
</span><span class='line'><span class="o">~</span><span class="sr">/my-awesome-site $ jekyll serve</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PyCon India 2014]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/pycon-india-2014/"/>
    <updated>2014-09-15T21:57:01+05:30</updated>
    <id>https://rishijeet.github.io/blog/pycon-india-2014</id>
    <content type="html"><![CDATA[<p><img src="https://rishijeet.github.io/images/pycon.png" height="100" width="100" alt="Alt text" /> Yes, PyCon India 2014 is happening in Bangalore. <a href="http://in.pycon.org/2014/schedule.html#schedule_conference">Interesting topics</a> are on there for you on day 2.
Workshops are also been conducted as a part of day 1 program. I have attended the one in year 2012 and some of the topics were really good to know and worth attending.
The topics which focus on large data processing, performance, high scalable application in python, complex data structure would be worth to attend.</p>

<!-- more -->


<p>So as I see the topics on the PyCon India Website, if not changed, my favorite topic would be,<br/>
<a href="http://in.pycon.org/funnel/2014/108-python-spark-lightning-fast-cluster-computing">Python + Spark: Lightning Fast Cluster Computing</a><br/>
<a href="http://in.pycon.org/funnel/2014/227-django-design-patterns">Django Design Patterns</a><br/>
<a href="http://in.pycon.org/funnel/2014/150-new-scientific-plotting-in-python">New Scientific Plotting in Python</a><br/>
<a href="http://in.pycon.org/funnel/2014/165-faster-data-processing-in-python">Faster data processing in Python</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Convert from epoch to human readable date]]></title>
    <summary><![CDATA[]]></summary>
    <link href="https://rishijeet.github.io/blog/convert-from-epoch-to-human-readable-date/"/>
    <updated>2014-09-12T23:50:56+05:30</updated>
    <id>https://rishijeet.github.io/blog/convert-from-epoch-to-human-readable-date</id>
    <content type="html"><![CDATA[<p>I was stuck with an issue of converting the epoch time to human readable format, in my case
the epoch time was in milli sec, and I was getting all sort of <code>python ValueError: (22, 'Invalid argument')</code></p>

<!-- more -->


<p>The fix was simple, to convert the epoch in milli sec to exact <code>date +%s</code> format
by slicing <code>[:3]</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">time</span>
</span><span class='line'><span class="n">time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s">&quot;%a, </span><span class="si">%d</span><span class="s"> %b %Y %H:%M:%S +0000&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">localtime</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="c">#Replace time.localtime with time.gmtime for GMT time.</span>
</span><span class='line'>
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
</feed>
