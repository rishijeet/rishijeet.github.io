<!doctype html>
    <!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
    <!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
    <!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
    <!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->

    
      
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Buddhi: Pushing the Boundaries of Long-Context Open-Source AI - Rishijeet Mishra</title>
        <meta name="author" content="Rishijeet Mishra">
        
        <meta name="description" content="Rishijeet Mishra's Blog Site">
        
        <meta name="viewport" content="width=device-width">
        <meta name="google-site-verification" content="k3jIYcr9jzBS7xC3F_CC0Eqc-szFtcR-JBr1Wwqnk6w" />
        <link rel="canonical" href="https://rishijeet.github.io/blog/buddhi-pushing-the-boundaries-of-long-context-open-source-ai">

        <link href='http://fonts.googleapis.com/css?family=Droid+Serif:400,400italic' rel='stylesheet' type='text/css'>
        <link href="http://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">

        
        <link href="/favicon.svg" rel="icon">
        <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet">
        <link href="/stylesheets/style.css" rel="stylesheet">
        <link href="" rel="alternate" title="Rishijeet Mishra" type="application/atom+xml">
    </head>


    <body >

        <header id="header">
    <div class="row">
    <div class="col-xs-12 col-sm-8 col-md-4">
        <a href="/" class="site-title">Rishijeet Mishra</a>
    </div>
    <div class="col-xs-12 col-sm-4 col-md-8">
    <nav>
    <input type="checkbox" id="toggle">
    <label for="toggle" class="toggle" data-open="Main Menu" data-close="Close Menu"></label>
    <ul class="menu">
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/blog/archives/">Archive</a></li>
    <li><a href="/lenswork/">Photography</a></li>
    <li><a href="/about/">About</a></li>
</ul>

</nav>

    </div>
</div>

</header>


        <div id="main-content">

            

            

            <div class="row top-xs center-sm center-md center-lg site-wrapper">
                
                <div class="col-xs-12 col-lg-10">
                
                    <link href="https://afeld.github.io/emoji-css/emoji.css" rel="stylesheet" type='text/css'>
<article class="article article--single">
    <header class="article__header">
    
        <h1 class="article__title">Buddhi: Pushing the Boundaries of Long-Context Open-Source AI</h1>
    

    
        <div class="article__meta clearfix">
            






    <time class="article__date pull-left" datetime="2025-03-25T08:24:38+05:30" pubdate><i class="fa fa-calendar"></i> Mar 25th, 2025</time>




            

    <div class="article__tags pull-left">
        <i class="fa fa-tags"></i>
        <ul class="unstyled">
        

            
                <li><a class='category' href='/blog/categories/ai/'>ai</a></li>
            
                <li><a class='category' href='/blog/categories/llm/'>llm</a></li>
            
                <li><a class='category' href='/blog/categories/genai/'>genai</a></li>
            
        
        </ul>
    </div>


            
        </div>
    
</header>




    <p>AI Planet has introduced Buddhi-128K-Chat-7B, an open-source chat model distinguished by its expansive 128,000-token context window. This advancement enables the model to process and retain extensive contextual information, enhancing its performance in tasks requiring deep context understanding.</p>

<p><img src="/images/2025/buddhi.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Model-Architecture"></a>
<h2>Model Architecture</h2>

<p>Buddhi-128K-Chat-7B is fine-tuned from the Mistral-7B Instruct v0.2 base model, selected for its superior reasoning capabilities. The Mistral-7B architecture incorporates features such as Grouped-Query Attention and a Byte-fallback BPE tokenizer, originally supporting a maximum of 32,768 position embeddings. To extend this to 128K, the Yet another Rope Extension (YaRN) technique was employed, modifying positional embeddings to accommodate the increased context length.</p>

<!--more-->


<a name="Dataset-Composition"></a>
<h2>Dataset Composition</h2>

<p>The training dataset comprises three sections tailored for chat model development:</p>

<ul>
<li><strong>Stack Exchange Data</strong>: Consists of question-and-answer pairs, refined using the Mistral model to enhance
formatting for chat applications.</li>
<li><strong>PG19-Based Data with Alpaca Formatting</strong>: Utilizes the PG19 dataset as context, with question-answer pairs
generated by GPT-3.</li>
<li><strong>PG19-Based Data with GPT-4</strong>: Similar to the previous section but with question-answer pairs generated by GPT-4,
ensuring a diverse conversational scope.</li>
</ul>


<p>This strategic composition ensures comprehensive coverage of dialogue scenarios, optimizing the model&rsquo;s performance across various contexts.</p>

<a name="Benchmark-Performance"></a>
<h2>Benchmark Performance</h2>

<p>Buddhi-128K-Chat-7B has been evaluated using both short and long context benchmarks:</p>

<p><strong>Short Context Benchmarks</strong>: The model&rsquo;s performance on tasks like HellaSwag, ARC Challenge, MMLU, TruthfulQA, and Winogrande has been assessed, with metrics available on the Open LLM Leaderboard.</p>

<p><img src="/images/2025/buddhi_bench.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p><strong>Long Context Benchmarks</strong>: Evaluations on datasets such as Banking77 have demonstrated the model&rsquo;s capability to handle extensive context effectively.</p>

<p><img src="/images/2025/buddhi_bench_lc.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>These benchmarks indicate that Buddhi-128K-Chat-7B matches or surpasses other models in its size class, particularly in handling long-context scenarios.</p>

<a name="Inference-and-Hardware-Requirements"></a>
<h2>Inference and Hardware Requirements</h2>

<p>To utilize the full 128K context length, the following hardware specifications are recommended:</p>

<ul>
<li><strong>128K Context Length</strong>: Requires 80GB VRAM, with A100 GPUs preferred.</li>
<li><strong>32K Context Length</strong>: Requires 40GB VRAM, with A100 GPUs preferred.</li>
</ul>


<p><img src="/images/2025/a100.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>For optimized inference, integrating vLLM, which employs Paged Attention to reduce memory footprint, is advisable. Additionally, bitsandbytes quantization can enable the model to run on GPUs with lower VRAM, such as T4 GPUs.</p>

<a name="Use-Cases-and-Applications"></a>
<h2>Use Cases and Applications</h2>

<p>The extended context window of Buddhi-128K-Chat-7B unlocks several practical applications:</p>

<ul>
<li><strong>Enhanced Memory and Recall</strong>: The model can reference earlier parts of a conversation, leading to more coherent and natural dialogues.</li>
<li><strong>Accurate Instruction Following</strong>: Capable of retaining and executing multi-step instructions without missing details.</li>
<li><strong>Efficient Workflow Automation</strong>: Suitable for processing large datasets in fields like legal document review and medical records analysis.</li>
<li><strong>Improved Coherence in Text Generation</strong>: Able to generate long-form content without losing context, ensuring consistency throughout the text.</li>
<li><strong>Deep Analysis and Insight Generation</strong>: Facilitates comprehensive analysis in research-intensive fields by understanding extensive documents in a single pass.</li>
</ul>


<p>While Buddhi-128K-Chat-7B offers significant advancements, it also presents challenges such as increased computational requirements and potential latency issues. Ongoing research and development are expected to address these limitations, further enhancing the model&rsquo;s efficiency and accessibility.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>In conclusion, Buddhi-128K-Chat-7B represents a notable step forward in open-source chat models, offering an extended context window that enhances its applicability across various domains requiring deep contextual understanding.</p>



    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6086670860734956"
     crossorigin="anonymous"></script>
</article>


<section id="disqus">
    <h1 class="disqus__title">Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>


                </div>

                
            </div>
        </div>

        

    
    




<footer class="footer">
    <div class="row middle-xs">
        
        <div class="col-xs-12 col-sm-6 col-md-6 col-lg-6">
            <p class="footer__copyright">
    Copyright &copy; 2014 - 2025 - Rishijeet Mishra
</p>

        </div>
        
        
        <div class="col-xs-12 col-sm-6 col-md-6 col-lg-6">
            <div>
    



    




<div class="hire hire--unavailable">
    
        
    
</div>

</div>
        </div>
        
    </div>
</footer>


        
<!--Adding the Mathjax support -->
<script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>

<script src="/javascripts/md5.js"></script>

<!--Octopress JS added to the site -->
<script defer src="/javascripts/octopress.js"></script>

<!--Ad thingy added by Rishi -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6086670860734956"
     crossorigin="anonymous"></script>


<!--Some analytics -->

<script>
    var _gaq=[['_setAccount','G-1P58V2BBV4'],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
</script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1P58V2BBV4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1P58V2BBV4');
</script>



<!--DisQus thingy -->

<script>
    var disqus_shortname = 'rishijeet';
    
        
        // var disqus_developer = 1;
        var disqus_identifier = 'https://rishijeet.github.io/blog/buddhi-pushing-the-boundaries-of-long-context-open-source-ai/';
        var disqus_url = 'https://rishijeet.github.io/blog/buddhi-pushing-the-boundaries-of-long-context-open-source-ai/';
        var disqus_script = 'embed.js';
    
    (function () {
        // Only if disqus_thread id is defined load the embed script
        if (document.getElementById('disqus_thread')) {
        var your_sub_domain = ''; // Here goes your subdomain
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        }
    })();
</script>




	<!-- 1. Add latest jQuery and fancyBox files -->
<!--Migrated to Fancybox 3 - -->

<script src="//code.jquery.com/jquery-3.2.1.min.js"></script>

<link rel="stylesheet" href="/css/jquery.fancybox.min.css" />
<script src="/javascripts/jquery.fancybox.min.js"></script>

<script type="text/javascript">
	$("[data-fancybox]").fancybox({
		// Options will go here
		image : {
		protect: true
				}
	});
</script>
<!--Adding some more restriction on photos-->
  <script type="text/javascript">
      document.addEventListener("contextmenu", (event) => {
         event.preventDefault();
      });
  </script> 
    </body>

</html>
