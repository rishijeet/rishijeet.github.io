<!doctype html>
    <!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
    <!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
    <!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
    <!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->

    
      
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Supercharge Reasoning in AI: Hands-On Chain of Thought Builds - Rishijeet Mishra | Technologist | Tech Trends & Development Blog</title>
        <meta name="author" content="Rishijeet Mishra">
        
        <meta name="description" content="Bridging tech and education - Rishijeet Mishra's insights on digital learning">
        
        <meta name="viewport" content="width=device-width">
        <meta name="google-site-verification" content="k3jIYcr9jzBS7xC3F_CC0Eqc-szFtcR-JBr1Wwqnk6w" />
        <link rel="canonical" href="https://rishijeet.github.io/blog/supercharge-reasoning-in-ai-hands-on-chain-of-thought-builds">

        <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,400italic' rel='stylesheet' type='text/css'>
        <link href="https://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">

        
        <link href="/favicon.svg" rel="icon">
        <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet">
        <link href="/stylesheets/style.css" rel="stylesheet">
        <link href="" rel="alternate" title="Rishijeet Mishra | Technologist | Tech Trends & Development Blog" type="application/atom+xml">
    </head>


    <body >

        <header id="header">
    <div class="row">
    <div class="col-xs-12 col-sm-8 col-md-4">
        <a href="/" class="site-title">Rishijeet Mishra</a>
    </div>
    <div class="col-xs-12 col-sm-4 col-md-8">
    <nav>
    <input type="checkbox" id="toggle">
    <label for="toggle" class="toggle" data-open="Main Menu" data-close="Close Menu"></label>
    <ul class="menu">
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/blog/archives/">Archive</a></li>
</ul>

</nav>

    </div>
</div>

</header>


        <div id="main-content">

            

            

            <div class="row top-xs center-sm center-md center-lg site-wrapper">
                
                <div class="col-xs-12 col-lg-10">
                
                    <link href="https://afeld.github.io/emoji-css/emoji.css" rel="stylesheet" type='text/css'>
<article class="article article--single">
    <header class="article__header">
    
        <h1 class="article__title">Supercharge Reasoning in AI: Hands-On Chain of Thought Builds</h1>
    

    
        <div class="article__meta clearfix">
            






    <time class="article__date pull-left" datetime="2025-08-29T13:26:07+05:30" pubdate><i class="fa fa-calendar"></i> Aug 29th, 2025</time>




            

    <div class="article__tags pull-left">
        <i class="fa fa-tags"></i>
        <ul class="unstyled">
        

            
                <li><a class='category' href='/blog/categories/cot/'>cot</a></li>
            
                <li><a class='category' href='/blog/categories/ai/'>ai</a></li>
            
                <li><a class='category' href='/blog/categories/llm/'>llm</a></li>
            
                <li><a class='category' href='/blog/categories/ml/'>ml</a></li>
            
                <li><a class='category' href='/blog/categories/rag/'>rag</a></li>
            
        
        </ul>
    </div>


            
        </div>
    
</header>




    <p>Chain of Thought (CoT) is a prompting technique introduced in a 2022 paper by Google researchers (Wei et al., &ldquo;Chain-of-Thought Prompting Elicits Reasoning in Large Language Models&rdquo;). The core idea is simple: instead of asking an LLM for a direct answer, you instruct it to <strong>reason step by step</strong>. This elicits better performance on tasks requiring logic, math, commonsense, or multi-step planning.</p>

<p><img src="/images/2025/cot.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>For example:</p>

<ul>
<li><strong>Direct Prompt</strong>: &ldquo;What is 15% of 200?&rdquo;</li>
<li><strong>CoT Prompt</strong>: &ldquo;What is 15% of 200? Let&rsquo;s think step by step.&rdquo;</li>
</ul>


<p>The LLM might respond:</p>

<ul>
<li>&ldquo;Step 1: 15% means 15 per 100, so 15/100 = 0.15.</li>
<li>Step 2: Multiply by 200: 0.15 * 200 = 30. So, the answer is 30.&#8221;</li>
</ul>


<!--more-->


<p>This &ldquo;thinking&rdquo; process isn&rsquo;t magic—it&rsquo;s emergent from the model&rsquo;s training on vast datasets where step-by-step explanations are common. CoT shines in zero-shot (no examples) or few-shot (with examples) scenarios, and variants like <strong>Tree of Thoughts</strong> or <strong>Self-Consistency</strong> build on it for even more robustness.</p>

<a name="Why-Does-CoT-Work-3f-"></a>
<h3>Why Does CoT Work?</h3>

<ul>
<li><strong>Decomposes Complexity</strong>: Breaks problems into manageable sub-steps, reducing error rates.</li>
<li><strong>Transparency</strong>: Users see the &ldquo;thought process,&rdquo; building trust and allowing debugging.</li>
<li><strong>Scalability</strong>: Works with any LLM API; no need for fine-tuning.</li>
<li><strong>Applications</strong>: Math solvers, code debuggers, decision-making tools, chatbots that explain reasoning.</li>
</ul>


<p>Research shows CoT improves accuracy by 10-50% on benchmarks like GSM8K (math) or CommonsenseQA. In interactive apps, it can stream thoughts progressively, giving users a &ldquo;processing&rdquo; indicator.</p>

<a name="Evolution-and-Variants-of-CoT"></a>
<h2>Evolution and Variants of CoT</h2>

<p>CoT has evolved rapidly:</p>

<ul>
<li><strong>Zero-Shot CoT</strong>: Just add &ldquo;Let&rsquo;s think step by step&rdquo; to the prompt.</li>
<li><strong>Few-Shot CoT</strong>: Provide 2-5 examples of step-by-step reasoning before the query.</li>
<li><strong>Automatic CoT</strong>: Use LLMs to generate CoT examples dynamically.</li>
<li><strong>Tree of Thoughts (ToT)</strong>: Explores multiple reasoning paths like a tree search.</li>
<li><strong>Graph of Thoughts</strong>: Models reasoning as a graph for non-linear problems.</li>
</ul>


<p>In 2025, with models like Grok 4, CoT is often combined with tools (e.g., code execution or web search) for agentic systems—AI agents that plan, act, and reflect.</p>

<a name="Building-a-Chain-of-Thought-Application:-Step-2d-by-2d-Step-Guide"></a>
<h2>Building a Chain of Thought Application: Step-by-Step Guide</h2>

<p>To build a CoT application, we&rsquo;ll create a Python-based tool that:</p>

<ol>
<li>Takes user input.</li>
<li>Applies CoT prompting via an LLM API.</li>
<li>Streams the response to show &ldquo;thinking&rdquo; in real-time (using API streaming features).</li>
<li>Parses the final answer for clarity.</li>
</ol>


<p>We&rsquo;ll use OpenAI&rsquo;s API as an example. Assumptions:</p>

<ul>
<li>You have an API key.</li>
<li>Focus on a math/word problem solver, but extensible to any domain.</li>
</ul>


<a name="Step-1:-Set-Up-Your-Environment"></a>
<h3>Step 1: Set Up Your Environment</h3>

<p>Install required libraries:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><pre><code class="bash"><span class='line'>pip install openai requests
</span></code></pre></div></figure>


<a name="Step-2:-Basic-CoT-Implementation"></a>
<h3>Step 2: Basic CoT Implementation</h3>

<p>Start with a simple non-streaming version. This script prompts the LLM with CoT and prints the full response.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><pre><code class="python"><span class='line'><span class="kn">import</span> <span class="nn">openai</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Set your API key</span>
</span><span class='line'><span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="s">&quot;your-openai-api-key&quot;</span>  <span class="c"># Replace with actual key</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">cot_reasoning</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s">&quot;gpt-4o&quot;</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    Applies Chain of Thought prompting to a query.</span>
</span><span class='line'><span class="sd">    </span>
</span><span class='line'><span class="sd">    Args:</span>
</span><span class='line'><span class="sd">    - query (str): The user&#39;s question.</span>
</span><span class='line'><span class="sd">    - model (str): LLM model to use.</span>
</span><span class='line'><span class="sd">    </span>
</span><span class='line'><span class="sd">    Returns:</span>
</span><span class='line'><span class="sd">    - str: The reasoned response.</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="c"># CoT Prompt Template (Few-Shot for better results)</span>
</span><span class='line'>    <span class="n">prompt</span> <span class="o">=</span> <span class="s">&quot;&quot;&quot;</span>
</span><span class='line'><span class="s">    Solve the following problem step by step.</span>
</span><span class='line'><span class="s">    </span>
</span><span class='line'><span class="s">    Example 1:</span>
</span><span class='line'><span class="s">    Question: If a car travels 60 miles in 1.5 hours, what is its speed?</span>
</span><span class='line'><span class="s">    Step 1: Speed is distance divided by time.</span>
</span><span class='line'><span class="s">    Step 2: Distance = 60 miles, Time = 1.5 hours.</span>
</span><span class='line'><span class="s">    Step 3: Speed = 60 / 1.5 = 40 mph.</span>
</span><span class='line'><span class="s">    Answer: 40 mph.</span>
</span><span class='line'><span class="s">    </span>
</span><span class='line'><span class="s">    Example 2:</span>
</span><span class='line'><span class="s">    Question: What is the next number in the sequence: 2, 4, 8, 16?</span>
</span><span class='line'><span class="s">    Step 1: Observe the pattern: each number is doubled.</span>
</span><span class='line'><span class="s">    Step 2: 2 * 2 = 4, 4 * 2 = 8, 8 * 2 = 16.</span>
</span><span class='line'><span class="s">    Step 3: Next is 16 * 2 = 32.</span>
</span><span class='line'><span class="s">    Answer: 32.</span>
</span><span class='line'><span class="s">    </span>
</span><span class='line'><span class="s">    Now, your question:</span>
</span><span class='line'><span class="s">    Question: {query}</span>
</span><span class='line'><span class="s">    &quot;&quot;&quot;</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">formatted_prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span class='line'>        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span class='line'>        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s">&quot;role&quot;</span><span class="p">:</span> <span class="s">&quot;user&quot;</span><span class="p">,</span> <span class="s">&quot;content&quot;</span><span class="p">:</span> <span class="n">formatted_prompt</span><span class="p">}]</span>
</span><span class='line'>    <span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Usage</span>
</span><span class='line'><span class="n">query</span> <span class="o">=</span> <span class="s">&quot;What is 25</span><span class="si">% o</span><span class="s">f 400?&quot;</span>
</span><span class='line'><span class="n">result</span> <span class="o">=</span> <span class="n">cot_reasoning</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</span></code></pre></div></figure>


<p><strong>Expected Output</strong>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><pre><code class="python"><span class='line'><span class="n">Step</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">25</span><span class="o">%</span> <span class="n">means</span> <span class="mi">25</span> <span class="n">per</span> <span class="mi">100</span><span class="p">,</span> <span class="n">so</span> <span class="mf">0.25</span><span class="o">.</span>
</span><span class='line'><span class="n">Step</span> <span class="mi">2</span><span class="p">:</span> <span class="n">Multiply</span> <span class="n">by</span> <span class="mi">400</span><span class="p">:</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="mi">400</span> <span class="o">=</span> <span class="mf">100.</span>
</span><span class='line'><span class="n">Answer</span><span class="p">:</span> <span class="mf">100.</span>
</span></code></pre></div></figure>


<p>This shows the &ldquo;thinking&rdquo; steps. To make it interactive, add a loop for multiple queries.</p>

<a name="Step-3:-Adding-Real-2d-Time-Processing-Feedback"></a>
<h3>Step 3: Adding Real-Time Processing Feedback</h3>

<p>To &ldquo;let you know that it is processing these steps,&rdquo; use streaming. OpenAI supports response streaming, printing tokens as they arrive—simulating thinking.</p>

<p>Modify the function:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><pre><code class="python"><span class='line'><span class="kn">import</span> <span class="nn">openai</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'>
</span><span class='line'><span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="s">&quot;your-openai-api-key&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">cot_streaming_reasoning</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s">&quot;gpt-4o&quot;</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    Streams Chain of Thought reasoning in real-time.</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">prompt</span> <span class="o">=</span> <span class="s">&quot;&quot;&quot;</span>
</span><span class='line'><span class="s">    Solve the following problem step by step. Think out loud.</span>
</span><span class='line'><span class="s">    </span>
</span><span class='line'><span class="s">    # Few-shot examples here (same as above)</span>
</span><span class='line'><span class="s">    </span>
</span><span class='line'><span class="s">    Question: {query}</span>
</span><span class='line'><span class="s">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">formatted_prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">stream</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span class='line'>        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span class='line'>        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s">&quot;role&quot;</span><span class="p">:</span> <span class="s">&quot;user&quot;</span><span class="p">,</span> <span class="s">&quot;content&quot;</span><span class="p">:</span> <span class="n">formatted_prompt</span><span class="p">}],</span>
</span><span class='line'>        <span class="n">stream</span><span class="o">=</span><span class="bp">True</span>  <span class="c"># Enable streaming</span>
</span><span class='line'>    <span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Thinking...&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">full_response</span> <span class="o">=</span> <span class="s">&quot;&quot;</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;content&quot;</span><span class="p">):</span>
</span><span class='line'>            <span class="n">content</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span>
</span><span class='line'>            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>  <span class="c"># Print incrementally</span>
</span><span class='line'>            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</span><span class='line'>            <span class="n">full_response</span> <span class="o">+=</span> <span class="n">content</span>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Done!&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">full_response</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Usage</span>
</span><span class='line'><span class="n">query</span> <span class="o">=</span> <span class="s">&quot;If I have 3 apples and eat 2, how many are left?&quot;</span>
</span><span class='line'><span class="n">cot_streaming_reasoning</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</span></code></pre></div></figure>


<p><strong>How It Works</strong>:</p>

<ul>
<li>The <code>stream=True</code> parameter yields partial responses.</li>
<li>We print each chunk, showing steps like &ldquo;Step 1: &hellip;&rdquo; as they generate.</li>
<li>This creates a &ldquo;processing&rdquo; effect—users see thoughts unfolding.</li>
</ul>


<p>For a web app, use Flask or Streamlit to stream via WebSockets.</p>

<a name="Step-4:-Advanced-Features--e2--80--93--Parsing-and-Error-Handling"></a>
<h3>Step 4: Advanced Features – Parsing and Error Handling</h3>

<p>To extract the final answer reliably, parse the response. Add self-consistency by generating multiple CoTs and voting.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><pre><code class="python"><span class='line'><span class="k">def</span> <span class="nf">parse_final_answer</span><span class="p">(</span><span class="n">response</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">    Extracts the final answer from CoT response.</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="n">lines</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">lines</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&quot;Answer:&quot;</span><span class="p">):</span>
</span><span class='line'>            <span class="k">return</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot;Answer:&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
</span><span class='line'>    <span class="k">return</span> <span class="s">&quot;No clear answer found.&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="c"># In your main function:</span>
</span><span class='line'><span class="n">result</span> <span class="o">=</span> <span class="n">cot_streaming_reasoning</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</span><span class='line'><span class="n">final_answer</span> <span class="o">=</span> <span class="n">parse_final_answer</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">&quot;Final Answer: {final_answer}&quot;</span><span class="p">)</span>
</span></code></pre></div></figure>


<p>For robustness (Self-Consistency CoT):</p>

<ul>
<li>Run 3-5 CoT generations.</li>
<li>Use majority vote on answers.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><pre><code class="python"><span class='line'><span class="k">def</span> <span class="nf">self_consistent_cot</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
</span><span class='line'>    <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
</span><span class='line'>        <span class="n">response</span> <span class="o">=</span> <span class="n">cot_reasoning</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>  <span class="c"># Or streaming version</span>
</span><span class='line'>        <span class="n">answer</span> <span class="o">=</span> <span class="n">parse_final_answer</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="n">answers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># Simple majority vote</span>
</span><span class='line'>    <span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
</span><span class='line'>    <span class="n">most_common</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">most_common</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">most_common</span> <span class="k">else</span> <span class="s">&quot;Inconsistent results&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Usage</span>
</span><span class='line'><span class="n">consistent_answer</span> <span class="o">=</span> <span class="n">self_consistent_cot</span><span class="p">(</span><span class="s">&quot;A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much is the ball?&quot;</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">consistent_answer</span><span class="p">)</span>  <span class="c"># Should be $0.05</span>
</span></code></pre></div></figure>


<a name="Step-5:-Building-a-Full-Application"></a>
<h3>Step 5: Building a Full Application</h3>

<p>For a complete app, use Streamlit for a UI:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><pre><code class="python"><span class='line'><span class="kn">import</span> <span class="nn">streamlit</span> <span class="kn">as</span> <span class="nn">st</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">openai</span>
</span><span class='line'>
</span><span class='line'><span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="s">&quot;your-openai-api-key&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="n">st</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;Chain of Thought Reasoner&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">query</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">text_input</span><span class="p">(</span><span class="s">&quot;Enter your question:&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="n">st</span><span class="o">.</span><span class="n">button</span><span class="p">(</span><span class="s">&quot;Reason&quot;</span><span class="p">):</span>
</span><span class='line'>    <span class="k">with</span> <span class="n">st</span><span class="o">.</span><span class="n">spinner</span><span class="p">(</span><span class="s">&quot;Thinking step by step...&quot;</span><span class="p">):</span>
</span><span class='line'>        <span class="n">response</span> <span class="o">=</span> <span class="n">cot_streaming_reasoning</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>  <span class="c"># Use non-streaming for simplicity, or adapt</span>
</span><span class='line'>        <span class="n">st</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="n">final</span> <span class="o">=</span> <span class="n">parse_final_answer</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</span><span class='line'>        <span class="n">st</span><span class="o">.</span><span class="n">success</span><span class="p">(</span><span class="n">f</span><span class="s">&quot;Final Answer: {final}&quot;</span><span class="p">)</span>
</span></code></pre></div></figure>


<p>Run with <code>streamlit run app.py</code>. This creates a web interface where users input queries and see the CoT process.</p>

<a name="Challenges-and-Best-Practices"></a>
<h2>Challenges and Best Practices</h2>

<ul>
<li><strong>Token Limits</strong>: CoT increases prompt length; use efficient models.</li>
<li><strong>Bias in Reasoning</strong>: LLMs can hallucinate steps—validate with tools (e.g., code execution for math).</li>
<li><strong>Customization</strong>: For domains like code generation, add &ldquo;Step 1: Understand requirements. Step 2: Plan code structure.&rdquo;</li>
<li><strong>Integration with Agents</strong>: Combine CoT with ReAct (Reason + Act) for tool-using agents.</li>
<li><strong>Ethics</strong>: Ensure transparency; CoT doesn&rsquo;t make AI infallible.</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Chain of Thought applications transform LLMs from black boxes into transparent reasoners. By building step-by-step processing into your prompts and code, you create tools that not only solve problems but explain how.</p>



    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6086670860734956"
     crossorigin="anonymous"></script>
</article>


<section id="disqus">
    <h1 class="disqus__title">Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</section>


                </div>

                
            </div>
        </div>

        

    
    




<footer class="footer">
    <div class="row middle-xs">
        
        <div class="col-xs-12 col-sm-6 col-md-6 col-lg-6">
            <p class="footer__copyright">
    Copyright &copy; 2014 - 2025 - Rishijeet Mishra
</p>

        </div>
        
        
        <div class="col-xs-12 col-sm-6 col-md-6 col-lg-6">
            <div>
    



    




<div class="hire hire--unavailable">
    
        
    
</div>

</div>
        </div>
        
    </div>
</footer>


        
<!--Adding the Mathjax support -->
<script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>

<script src="/javascripts/md5.js"></script>

<!--Octopress JS added to the site -->
<script defer src="/javascripts/octopress.js"></script>

<!--Ad thingy added by Rishi -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6086670860734956"
     crossorigin="anonymous"></script>


<!--Some analytics -->

<script>
    var _gaq=[['_setAccount','G-1P58V2BBV4'],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
</script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1P58V2BBV4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1P58V2BBV4');
</script>



<!--DisQus thingy -->

<script>
    var disqus_shortname = 'rishijeet';
    
        
        // var disqus_developer = 1;
        var disqus_identifier = 'https://rishijeet.github.io/blog/supercharge-reasoning-in-ai-hands-on-chain-of-thought-builds/';
        var disqus_url = 'https://rishijeet.github.io/blog/supercharge-reasoning-in-ai-hands-on-chain-of-thought-builds/';
        var disqus_script = 'embed.js';
    
    (function () {
        // Only if disqus_thread id is defined load the embed script
        if (document.getElementById('disqus_thread')) {
        var your_sub_domain = ''; // Here goes your subdomain
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        }
    })();
</script>




	<!-- 1. Add latest jQuery and fancyBox files -->
<!--Migrated to Fancybox 3 - -->

<script src="//code.jquery.com/jquery-3.2.1.min.js"></script>

<link rel="stylesheet" href="/css/jquery.fancybox.min.css" />
<script src="/javascripts/jquery.fancybox.min.js"></script>

<script type="text/javascript">
	$("[data-fancybox]").fancybox({
		// Options will go here
		image : {
		protect: true
				}
	});
</script>
<!--Adding some more restriction on photos-->
  <script type="text/javascript">
      document.addEventListener("contextmenu", (event) => {
         event.preventDefault();
      });
  </script> 
    </body>

</html>
