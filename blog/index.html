<!doctype html>
    <!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
    <!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
    <!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
    <!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->

    
      
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Blogs - Rishijeet Mishra</title>
        <meta name="author" content="Rishijeet Mishra">
        
        <meta name="description" content="Rishijeet Mishra's Blog Site">
        
        <meta name="viewport" content="width=device-width">
        <meta name="google-site-verification" content="k3jIYcr9jzBS7xC3F_CC0Eqc-szFtcR-JBr1Wwqnk6w" />
        <link rel="canonical" href="https://rishijeet.github.io/blog">

        <link href='http://fonts.googleapis.com/css?family=Droid+Serif:400,400italic' rel='stylesheet' type='text/css'>
        <link href="http://fonts.googleapis.com/css?family=Droid+Sans" rel="stylesheet" type="text/css">

        
        <link href="/favicon.svg" rel="icon">
        <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet">
        <link href="/stylesheets/style.css" rel="stylesheet">
        <link href="" rel="alternate" title="Rishijeet Mishra" type="application/atom+xml">
    </head>


    <body >

        <header id="header">
    <div class="row">
    <div class="col-xs-12 col-sm-8 col-md-4">
        <a href="/" class="site-title">Rishijeet Mishra</a>
    </div>
    <div class="col-xs-12 col-sm-4 col-md-8">
    <nav>
    <input type="checkbox" id="toggle">
    <label for="toggle" class="toggle" data-open="Main Menu" data-close="Close Menu"></label>
    <ul class="menu">
    <li><a href="/">Home</a></li>
    <li><a href="/blog/">Blog</a></li>
    <li><a href="/blog/archives/">Archive</a></li>
    <li><a href="/lenswork/">Photography</a></li>
    <li><a href="/about/">About</a></li>
</ul>

</nav>

    </div>
</div>

</header>


        <div id="main-content">

            

            

            <div class="row top-xs center-sm center-md center-lg site-wrapper">
                
                <div class="col-xs-12 col-sm-10 col-md-10 col-lg-10">
                
                    <link href="https://afeld.github.io/emoji-css/emoji.css" rel="stylesheet">
<article class="page">

    
    <header>
        <h1 class="page__title">
            Blogs
        </h1>
    </header>
    <hr class="divider">
    

        
    
        
        <article class="article article--index">
            <header class="article__header">
    
        <h1 class="h2 article__title">
            <a href="/blog/advanced-apache-kafka-anatomy-delving-deep-into-the-core-components/">Advanced Apache Kafka Anatomy: Delving Deep into the Core Components</a>
        </h1>
    

    
        <div class="article__meta clearfix">
            






    <time class="article__date pull-left" datetime="2024-06-27T09:55:12+05:30" pubdate><i class="fa fa-calendar"></i> Jun 27th, 2024</time>




            

    <div class="article__tags pull-left">
        <i class="fa fa-tags"></i>
        <ul class="unstyled">
        
            
                <li><a class='category' href='/blog/categories/kafka/'>kafka</a></li>
            
                <li><a class='category' href='/blog/categories/architecture/'>architecture</a></li>
            
            
        </ul>
    </div>


            
        </div>
    
</header>




    <p>Apache Kafka has become a cornerstone of modern data architectures, renowned for its ability to handle high-throughput, low-latency data streams. While its fundamental concepts are widely understood, a deeper dive into Kafka’s advanced components and features reveals the true power and flexibility of this distributed event streaming platform. This blog aims to unravel the advanced anatomy of Apache Kafka, offering insights into its core components, configurations, and best practices for optimizing performance.</p>

<a name="Core-Components-of-Kafka"></a>
<h2>Core Components of Kafka</h2>

<a name="Brokers"></a>
<h3>Brokers</h3>

<p><strong>Brokers</strong> are the backbone of a Kafka cluster, responsible for managing data storage, processing requests from clients, and replicating data to ensure fault tolerance.</p>

<p><img src="/images/2024/kafka_broker.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>Leader and Follower Roles</strong>: Each topic partition has a leader broker that handles all read and write requests for that partition, while follower brokers replicate the leader’s data to ensure high availability.</li>
<li><strong>Scalability</strong>: Kafka’s design allows for easy scaling by adding more brokers to distribute the load and improve throughput.</li>
</ul>


<a name="Topics-and-Partitions"></a>
<h3>Topics and Partitions</h3>

<p><strong>Topics</strong> are categories to which records are published. Each topic can be divided into multiple partitions, which are the basic unit of parallelism and scalability in Kafka.</p>

<ul>
<li><strong>Partitioning Strategy</strong>: Proper partitioning is crucial for load balancing and ensuring efficient data distribution across the cluster. Common strategies include key-based partitioning and round-robin distribution.</li>
<li><strong>Replication</strong>: Partitions can be replicated across multiple brokers to provide redundancy and high availability. The replication factor determines the number of copies of a partition in the cluster.</li>
</ul>


<a name="Producers"></a>
<h3>Producers</h3>

<p><strong>Producers</strong> are responsible for publishing records to Kafka topics.</p>

<p><img src="/images/2024/kafka_producers.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>Acknowledgments</strong>: Configurable acknowledgment settings (<code>acks</code>) determine how many broker acknowledgments the producer requires before considering a request complete (<code>acks=0</code>, <code>acks=1</code>, or <code>acks=all</code>).</li>
<li><strong>Batching and Compression</strong>: Producers can batch multiple records into a single request to improve throughput and enable data compression to reduce the size of the data being transferred.</li>
</ul>


<a name="Consumers"></a>
<h3>Consumers</h3>

<p><strong>Consumers</strong> subscribe to topics and process the records published to them.</p>

<ul>
<li><strong>Consumer Groups</strong>: Consumers operate as part of a group, where each consumer in a group reads from a unique set of partitions. This allows for parallel processing and ensures that records are processed by a single consumer.</li>
<li><strong>Offset Management</strong>: Consumers track their position in each partition by maintaining offsets, which can be automatically committed at intervals or manually managed for precise control over record processing.</li>
</ul>


<a name="ZooKeeper"></a>
<h3>ZooKeeper</h3>

<p><strong>ZooKeeper</strong> is a critical component in Kafka&rsquo;s ecosystem, used for cluster coordination and configuration management.</p>

<ul>
<li><strong>Leader Election</strong>: ZooKeeper helps manage the leader election process for partition leaders and the Kafka controller.</li>
<li><strong>Metadata Storage</strong>: Stores metadata about the Kafka cluster, including broker information, topic configurations, and access control lists.</li>
</ul>


<a name="Advanced-Kafka-Features"></a>
<h2>Advanced Kafka Features</h2>

<a name="Kafka-Connect"></a>
<h3>Kafka Connect</h3>

<p><strong>Kafka Connect</strong> is a robust framework for integrating Kafka with external systems.</p>

<p><img src="/images/2024/kafka_connect.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>Source Connectors</strong>: Import data from external systems (e.g., databases, file systems) into Kafka topics.</li>
<li><strong>Sink Connectors</strong>: Export data from Kafka topics to external systems (e.g., databases, data lakes).</li>
</ul>


<a name="Kafka-Streams"></a>
<h3>Kafka Streams</h3>

<p><strong>Kafka Streams</strong> is a powerful library for building stream processing applications on top of Kafka.</p>

<p><img src="/images/2024/kafka_streams.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>KStream and KTable</strong>: Core abstractions for modeling streams of records and tables of changelog records, respectively.</li>
<li><strong>Stateful Processing</strong>: Enables operations like joins, aggregations, and windowing, with support for local state stores and fault-tolerant state management.</li>
</ul>


<a name="Schema-Registry"></a>
<h3>Schema Registry</h3>

<p><strong>Schema Registry</strong> is a centralized service for managing and validating schemas used by Kafka producers and consumers.</p>

<p><img src="/images/2024/schema-registry-and-kafka.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<ul>
<li><strong>Avro, JSON, and Protobuf</strong>: Supports multiple schema formats, ensuring data consistency and compatibility across different applications.</li>
<li><strong>Schema Evolution</strong>: Facilitates schema versioning and evolution, allowing for backward and forward compatibility.</li>
</ul>


<a name="Best-Practices-for-Kafka-Performance-Optimization"></a>
<h2>Best Practices for Kafka Performance Optimization</h2>

<a name="Configuring-Brokers"></a>
<h3>Configuring Brokers</h3>

<ul>
<li><strong>Heap Size</strong>: Set an appropriate heap size for Kafka brokers to prevent memory issues. Typically, 4-8 GB is recommended.</li>
<li><strong>Log Retention</strong>: Configure log retention policies (<code>log.retention.hours</code>, <code>log.retention.bytes</code>) to manage disk usage and comply with data retention requirements.</li>
</ul>


<a name="Optimizing-Producers"></a>
<h3>Optimizing Producers</h3>

<ul>
<li><strong>Batch Size and Linger</strong>: Adjust <code>batch.size</code> and <code>linger.ms</code> to balance latency and throughput. Larger batch sizes and longer linger times can improve throughput at the cost of increased latency.</li>
<li><strong>Compression Type</strong>: Enable compression (<code>compression.type</code>) to reduce network bandwidth usage. Common options include <code>gzip</code>, <code>snappy</code>, and <code>lz4</code>.</li>
</ul>


<a name="Tuning-Consumers"></a>
<h3>Tuning Consumers</h3>

<ul>
<li><strong>Fetch Size</strong>: Configure <code>fetch.min.bytes</code> and <code>fetch.max.wait.ms</code> to control the amount of data fetched in each request and the maximum wait time, balancing latency and throughput.</li>
<li><strong>Offset Commit Frequency</strong>: Adjust <code>auto.commit.interval.ms</code> for automatic offset commits or implement manual offset management for finer control over record processing.</li>
</ul>


<a name="Ensuring-High-Availability"></a>
<h3>Ensuring High Availability</h3>

<ul>
<li><strong>Replication Factor</strong>: Set an appropriate replication factor for topics to ensure data redundancy and fault tolerance. A replication factor of 3 is common in production environments.</li>
<li><strong>ISR (In-Sync Replicas)</strong>: Monitor the number of in-sync replicas (<code>min.insync.replicas</code>) to ensure that there are enough replicas to maintain data consistency and durability.</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Apache Kafka’s advanced anatomy reveals a powerful and flexible system capable of handling the most demanding data streaming requirements. By understanding its core components, leveraging advanced features like Kafka Connect and Kafka Streams, and adhering to best practices for performance optimization, you can harness the full potential of Kafka in your data architecture. Whether you’re building real-time analytics, event-driven microservices, or data integration pipelines, Kafka provides the foundation for scalable, resilient, and high-performance data streaming solutions.</p>



        </article>
        <hr>
    
        
        <article class="article article--index">
            <header class="article__header">
    
        <h1 class="h2 article__title">
            <a href="/blog/exploring-grpc-the-next-generation-of-remote-procedure-calls/">Exploring gRPC: The Next Generation of Remote Procedure Calls</a>
        </h1>
    

    
        <div class="article__meta clearfix">
            






    <time class="article__date pull-left" datetime="2024-06-26T09:54:48+05:30" pubdate><i class="fa fa-calendar"></i> Jun 26th, 2024</time>




            

    <div class="article__tags pull-left">
        <i class="fa fa-tags"></i>
        <ul class="unstyled">
        
            
                <li><a class='category' href='/blog/categories/grpc/'>grpc</a></li>
            
                <li><a class='category' href='/blog/categories/rest/'>rest</a></li>
            
                <li><a class='category' href='/blog/categories/http/'>http</a></li>
            
            
        </ul>
    </div>


            
        </div>
    
</header>




    <div class="article__content clearfix">
        <p>In the realm of distributed systems and microservices, effective communication between services is paramount. For many years, REST (Representational State Transfer) has been the dominant paradigm for building APIs. However, gRPC (gRPC Remote Procedure Calls) is emerging as a powerful alternative, offering several advantages over traditional REST APIs. In this blog, we&rsquo;ll explore what gRPC is, how it works, and why it might be a better choice than REST for certain applications.</p>

<a name="What-is-gRPC-3f-"></a>
<h2>What is gRPC?</h2>

<p>gRPC, originally developed by Google, is an open-source framework that enables high-performance remote procedure calls (RPC). It leverages HTTP/2 for transport, Protocol Buffers (Protobuf) as the interface definition language (IDL), and provides features like bi-directional streaming, authentication, and load balancing out-of-the-box.</p>

<p><img src="/images/2024/grpc.png" height="300" width="900" alt="Alt text" /><em>Source: gRPC</em></p>

<a name="Key-Components-of-gRPC"></a>
<h3>Key Components of gRPC</h3>

<ul>
<li><strong>Protocol Buffers (Protobuf)</strong>: A language-neutral, platform-neutral, extensible mechanism for serializing
structured data. It serves as both the IDL and the message format.</li>
<li><strong>HTTP/2</strong>: The transport protocol used by gRPC, which provides benefits like multiplexing, flow control, header
compression, and low-latency communication.</li>
<li><strong>Stub</strong>: Generated client code that provides the same methods as the server, making remote calls appear as local
method calls.</li>
</ul>


<a name="How-gRPC-Works"></a>
<h3>How gRPC Works</h3>

<ul>
<li><strong>Define the Service</strong>: Use Protobuf to define the service and its methods, along with the request and response
message types.</li>
<li><strong>Generate Code</strong>: Use the Protobuf compiler to generate client and server code in your preferred programming
languages.</li>
<li><strong>Implement the Service</strong>: Write the server-side logic to handle the defined methods.</li>
<li><strong>Call the Service</strong>: Use the generated client code to call the methods on the server as if they were local functions.</li>
</ul>



        <a class="btn pull-right" href="/blog/exploring-grpc-the-next-generation-of-remote-procedure-calls/">Read on &rarr;</a>
    </div>


        </article>
        <hr>
    
        
        <article class="article article--index">
            <header class="article__header">
    
        <h1 class="h2 article__title">
            <a href="/blog/event-driven-architecture-unlocking-modern-application-potential/">Event-Driven Architecture: Unlocking Modern Application Potential</a>
        </h1>
    

    
        <div class="article__meta clearfix">
            






    <time class="article__date pull-left" datetime="2024-06-26T09:27:40+05:30" pubdate><i class="fa fa-calendar"></i> Jun 26th, 2024</time>




            

    <div class="article__tags pull-left">
        <i class="fa fa-tags"></i>
        <ul class="unstyled">
        
            
                <li><a class='category' href='/blog/categories/architecture/'>architecture</a></li>
            
                <li><a class='category' href='/blog/categories/event/'>event</a></li>
            
                <li><a class='category' href='/blog/categories/mq/'>mq</a></li>
            
                <li><a class='category' href='/blog/categories/kafka/'>kafka</a></li>
            
            
        </ul>
    </div>


            
        </div>
    
</header>




    <div class="article__content clearfix">
        <p>In today&rsquo;s fast-paced digital landscape, real-time data processing and responsive systems are becoming increasingly crucial. Traditional request-response architectures often struggle to keep up with the demands of modern applications, which require scalable, resilient, and decoupled systems. Enter event-based architecture—a paradigm that addresses these challenges by enabling systems to react to changes and events as they happen.</p>

<p>In this blog, we&rsquo;ll explore the key concepts, benefits, and components of modern event-based architecture, along with practical examples and best practices for implementation.</p>

<a name="What-is-Event-2d-Based-Architecture-3f-"></a>
<h2>What is Event-Based Architecture?</h2>

<p>Event-based architecture is a design pattern in which system components communicate by producing and consuming events. An event is a significant change in state or an occurrence that is meaningful to the system, such as a user action, a data update, or an external trigger. Instead of directly calling methods or services, components publish events to an event bus, and other components subscribe to these events to perform actions in response.</p>

<p><img src="/images/2024/glossary-eda.svg" height="300" width="900" alt="Alt text" /><em>Source: Hazelcast</em></p>

<a name="Components-of-Modern-Event-2d-Based-Architecture"></a>
<h2>Components of Modern Event-Based Architecture</h2>

<a name="Event-Producers"></a>
<h3>Event Producers</h3>

<p>Event producers are responsible for generating events. These can be user interfaces, IoT devices, data ingestion services, or any other source that generates meaningful events. Producers publish events to the event bus without needing to know who will consume them.</p>

<a name="Event-Consumers"></a>
<h3>Event Consumers</h3>

<p>Event consumers subscribe to specific events and react to them. Consumers can perform various actions, such as updating databases, triggering workflows, sending notifications, or invoking other services. Each consumer processes events independently, allowing for parallel and asynchronous processing.</p>

<a name="Event-Bus"></a>
<h3>Event Bus</h3>

<p>The event bus is the backbone of an event-based architecture. It routes events from producers to consumers, ensuring reliable and scalable communication. Common implementations of an event bus include message brokers like Apache Kafka, RabbitMQ, and Amazon SNS/SQS.</p>

<a name="Event-Streams-and-Storage"></a>
<h3>Event Streams and Storage</h3>

<p>Event streams are continuous flows of events that can be processed in real-time or stored for batch processing and historical analysis. Stream processing frameworks like Apache Kafka Streams, Apache Flink, and Apache Storm enable real-time processing of event streams.</p>

<a name="Event-Processing-and-Transformation"></a>
<h3>Event Processing and Transformation</h3>

<p>Event processing involves filtering, aggregating, and transforming events to derive meaningful insights and trigger actions. Complex Event Processing (CEP) engines and stream processing frameworks are often used to handle sophisticated event processing requirements.</p>


        <a class="btn pull-right" href="/blog/event-driven-architecture-unlocking-modern-application-potential/">Read on &rarr;</a>
    </div>


        </article>
        <hr>
    
        
        <article class="article article--index">
            <header class="article__header">
    
        <h1 class="h2 article__title">
            <a href="/blog/understanding-the-bloom-filter/">Understanding the Bloom filter</a>
        </h1>
    

    
        <div class="article__meta clearfix">
            






    <time class="article__date pull-left" datetime="2024-06-11T10:09:01+05:30" pubdate><i class="fa fa-calendar"></i> Jun 11th, 2024</time>




            

    <div class="article__tags pull-left">
        <i class="fa fa-tags"></i>
        <ul class="unstyled">
        
            
                <li><a class='category' href='/blog/categories/bloom-filter/'>bloom_filter</a></li>
            
                <li><a class='category' href='/blog/categories/algorithm/'>algorithm</a></li>
            
                <li><a class='category' href='/blog/categories/data-structure/'>data_structure</a></li>
            
            
        </ul>
    </div>


            
        </div>
    
</header>




    <div class="article__content clearfix">
        <p>A Bloom filter is a probabilistic data structure used to test whether an element is a member of a set. It is highly space-efficient and allows for fast query operations, but it has a small risk of false positives (reporting that an element is in the set when it is not) while guaranteeing no false negatives (an element that is in the set will always be reported as such).</p>

<a name="How-Bloom-Filters-Work"></a>
<h2>How Bloom Filters Work</h2>

<p>A Bloom filter uses a bit array of fixed size and a set of hash functions. Here is a simplified example of how it works:</p>

<p><strong>Initialization</strong>:</p>

<ul>
<li>Create a bit array of size \(m\) and initialize all bits to 0.</li>
</ul>


<p><strong>Adding an Element</strong>:</p>

<ul>
<li>Compute \(k\) hash values of the element using \(k\) different hash functions.</li>
<li>Set the bits at the positions determined by the hash values to 1 in the bit array.</li>
</ul>


<p><strong>Checking Membership</strong>:</p>

<ul>
<li>Compute the \(k\) hash values of the element.</li>
<li>Check the bits at the positions determined by the hash values.</li>
<li>If all bits are set to 1, the element is considered to be possibly in the set (with a risk of false positive).</li>
<li>If any bit is 0, the element is definitely not in the set.</li>
</ul>


<p>The underlying architecture of a Bloom filter consists of three main components: a bit array, a set of hash functions, and the operations for adding elements and checking membership. Below is a detailed breakdown of each component and the overall architecture:</p>

<a name="Components-of-a-Bloom-Filter"></a>
<h2>Components of a Bloom Filter</h2>

<p><strong>Bit Array</strong>:</p>

<ul>
<li>A Bloom filter uses a bit array of fixed size \( m \). This array is initialized with all bits set to 0.</li>
<li>The size of the bit array \( m \) is chosen based on the expected number of elements \( n \) and the desired
false positive rate \( p \).</li>
</ul>


<p><strong>Hash Functions</strong>:</p>

<ul>
<li>A Bloom filter uses \( k \) different hash functions. Each hash function maps an input element to one of the
positions in the bit array uniformly at random.</li>
<li>The number of hash functions \( k \) is optimized to minimize the false positive rate.</li>
</ul>



        <a class="btn pull-right" href="/blog/understanding-the-bloom-filter/">Read on &rarr;</a>
    </div>


        </article>
        <hr>
    
        
        <article class="article article--index">
            <header class="article__header">
    
        <h1 class="h2 article__title">
            <a href="/blog/cassandra-under-the-hood/">Cassandra - Under the hood</a>
        </h1>
    

    
        <div class="article__meta clearfix">
            






    <time class="article__date pull-left" datetime="2024-05-22T23:48:44+05:30" pubdate><i class="fa fa-calendar"></i> May 22nd, 2024</time>




            

    <div class="article__tags pull-left">
        <i class="fa fa-tags"></i>
        <ul class="unstyled">
        
            
                <li><a class='category' href='/blog/categories/database/'>database</a></li>
            
                <li><a class='category' href='/blog/categories/cassandra/'>cassandra</a></li>
            
                <li><a class='category' href='/blog/categories/nosql/'>nosql</a></li>
            
            
        </ul>
    </div>


            
        </div>
    
</header>




    <div class="article__content clearfix">
        <p>Apache Cassandra is designed to handle large amounts of data across many commodity servers without any single point of failure. This architecture allows it to provide high availability and fault tolerance, making it an excellent choice for large-scale, mission-critical applications. Below, we&rsquo;ll delve into the key components and architecture of Cassandra.</p>

<a name="Key-Components"></a>
<h3>Key Components</h3>

<ul>
<li><strong>Nodes</strong>: Individual machines running Cassandra.</li>
<li><strong>Clusters</strong>: A collection of nodes that work together.</li>
<li><strong>Data Centers</strong>: Groupings of nodes within a cluster, typically corresponding to physical or logical locations.</li>
<li><strong>Keyspace</strong>: A namespace for tables, analogous to a database in SQL.</li>
<li><strong>Tables</strong>: Collections of rows, each row containing columns, similar to tables in an RDBMS.</li>
<li><strong>Commit Log</strong>: A log of all write operations, used for crash recovery.</li>
<li><strong>Memtable</strong>: An in-memory structure where data is first written.</li>
<li><strong>SSTable</strong>: Immutable on-disk storage files created from flushed Memtables.</li>
<li><strong>Bloom Filters</strong>: Probabilistic data structures that help determine whether an SSTable might contain a requested row.</li>
</ul>


<a name="Architecture-Overview"></a>
<h3>Architecture Overview</h3>

<a name="Cluster-Management"></a>
<h4>Cluster Management</h4>

<p>Cassandra&rsquo;s cluster architecture ensures high availability and fault tolerance. The cluster is a set of nodes, and data is distributed among these nodes using consistent hashing. Key features include:</p>

<ul>
<li><strong>Gossip Protocol</strong>: Nodes communicate with each other using a peer-to-peer gossip protocol to share state information.</li>
<li><strong>Snitches</strong>: Determine the relative distance between nodes to route requests efficiently.</li>
<li><strong>Replication</strong>: Data is replicated across multiple nodes. The replication strategy and factor determine how and where data is replicated.</li>
</ul>



        <a class="btn pull-right" href="/blog/cassandra-under-the-hood/">Read on &rarr;</a>
    </div>


        </article>
        <hr>
    

    <div class="pagination">
    
        <a class="btn pull-left" href="/blog/2">&larr; Older</a>
    

    
    </div>


</article>

                </div>

                
            </div>
        </div>

        

    
    




<footer class="footer">
    <div class="row middle-xs">
        
        <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
            <p class="footer__copyright">
    Copyright &copy; 2014 - 2024 - Rishijeet Mishra
</p>

        </div>
        
        
    </div>
</footer>


        
<!--Adding the Mathjax support -->
<script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>

<script src="/javascripts/md5.js"></script>

<!--Octopress JS added to the site -->
<script defer src="/javascripts/octopress.js"></script>

<!--Ad thingy added by Rishi -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6086670860734956"
     crossorigin="anonymous"></script>


<!--Some analytics -->

<script>
    var _gaq=[['_setAccount','G-1P58V2BBV4'],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
</script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-1P58V2BBV4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1P58V2BBV4');
</script>



<!--DisQus thingy -->

<script>
    var disqus_shortname = 'rishijeet';
    
        
        // var disqus_developer = 1;
        var disqus_identifier = 'https://rishijeet.github.io/blog/index.html';
        var disqus_url = 'https://rishijeet.github.io/blog/index.html';
        var disqus_script = 'embed.js';
    
    (function () {
        // Only if disqus_thread id is defined load the embed script
        if (document.getElementById('disqus_thread')) {
        var your_sub_domain = ''; // Here goes your subdomain
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        }
    })();
</script>




	<!-- 1. Add latest jQuery and fancyBox files -->
<!--Migrated to Fancybox 3 - -->

<script src="//code.jquery.com/jquery-3.2.1.min.js"></script>

<link rel="stylesheet" href="/css/jquery.fancybox.min.css" />
<script src="/javascripts/jquery.fancybox.min.js"></script>

<script type="text/javascript">
	$("[data-fancybox]").fancybox({
		// Options will go here
		image : {
		protect: true
				}
	});
</script>
<!--Adding some more restriction on photos-->
  <script type="text/javascript">
      document.addEventListener("contextmenu", (event) => {
         event.preventDefault();
      });
  </script> 
    </body>

</html>
