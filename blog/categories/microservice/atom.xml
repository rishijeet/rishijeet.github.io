<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title><![CDATA[Category: microservice | Rishijeet Mishra]]></title>
    <link href="https://rishijeet.github.io/blog/categories/microservice/atom.xml" rel="self"/>
    <link href="https://rishijeet.github.io/"/>
    <updated>2024-08-03T19:00:29+05:30</updated>
    <id>https://rishijeet.github.io/</id>
    <author>
        <name><![CDATA[Rishijeet Mishra]]></name>
        <email><![CDATA[rishijeet@gmail.com]]></email>
      </author>
    <generator uri="http://octopress.org/">Octopress</generator>

    
    <entry>
        <title type="html"><![CDATA[Micronaut: The Modern Framework for Microservices]]></title>
        <link href="https://rishijeet.github.io/blog/micronaut-the-modern-framework-for-microservices/"/>
        <updated>2024-08-01T23:37:24+05:30</updated>
        <id>https://rishijeet.github.io/blog/micronaut-the-modern-framework-for-microservices</id>
        <content type="html"><![CDATA[<p>Micronaut is a JVM-based framework designed for building modular, easily testable microservices and serverless applications. It is built with modern development practices and performance optimizations in mind. Here, we’ll explore Micronaut in depth, focusing on its core features, architecture, and advanced mechanisms that set it apart from traditional frameworks.</p>

<a name="L-3c-strong-3e-Core-Features-of-Micronaut-3c--2f-strong-3e-"></a>
<h3><strong>Core Features of Micronaut</strong></h3>

<a name="L-3c-strong-3e-Compile-2d-Time-Dependency-Injection-3c--2f-strong-3e-"></a>
<h4><strong>Compile-Time Dependency Injection</strong></h4>

<p>Micronaut&rsquo;s approach to dependency injection (DI) and aspect-oriented programming (AOP) is handled at compile time rather than runtime. This is achieved through annotation processing, which generates all necessary metadata during compilation. This approach has several advantages:</p>

<ul>
<li><strong>Faster Startup</strong>: No need for reflection-based DI at runtime.</li>
<li><strong>Reduced Memory Overhead</strong>: Less memory consumption as the runtime doesn’t have to handle DI.</li>
<li><strong>Compile-Time Safety</strong>: Errors related to DI are caught at compile time, improving code reliability.</li>
</ul>


<!--more-->


<p><strong>Example:</strong></p>

<pre><code class="java">package example.micronaut.demo;

import io.micronaut.context.annotation.Factory;
import jakarta.inject.Singleton;

@Factory
public class BeanFactory {

    @Singleton
    public GreetingService greetingService() {
        return new GreetingServiceImpl();
    }
}

interface GreetingService {
    String greet(String name);
}

class GreetingServiceImpl implements GreetingService {
    @Override
    public String greet(String name) {
        return "Hello, " + name;
    }
}
</code></pre>

<p>In this example, <code>GreetingService</code> is provided by <code>BeanFactory</code> at compile time, and Micronaut handles all dependency management without runtime reflection.</p>

<a name="L-3c-strong-3e-Minimal-Reflection-and-Proxies-3c--2f-strong-3e-"></a>
<h4><strong>Minimal Reflection and Proxies</strong></h4>

<p>Micronaut avoids the use of runtime reflection and dynamic proxies, which are common in other frameworks. Instead, it uses compile-time code generation to handle DI and AOP, which:</p>

<ul>
<li><strong>Reduces Overhead</strong>: Less runtime overhead compared to reflection.</li>
<li><strong>Improves Performance</strong>: Faster execution and lower memory consumption.</li>
</ul>


<p><strong>Example of Avoiding Reflection:</strong></p>

<p>Instead of using reflection to create proxies, Micronaut generates the required bytecode during compilation.</p>

<a name="L-3c-strong-3e-Built-2d-in-Cloud-2d-Native-Support-3c--2f-strong-3e-"></a>
<h4><strong>Built-in Cloud-Native Support</strong></h4>

<p>Micronaut has robust support for cloud-native patterns such as:</p>

<ul>
<li><strong>Service Discovery</strong>: Integration with service discovery systems like Consul and Eureka.</li>
<li><strong>Configuration Management</strong>: Supports configuration from various sources including environment variables, configuration files, and cloud-based configuration services.</li>
<li><strong>Distributed Tracing</strong>: Integration with tracing systems such as Zipkin and Jaeger.</li>
</ul>


<p><strong>Example: Configuring Service Discovery</strong></p>

<pre><code class="yaml">micronaut:
  application:
    name: demo-application
  discovery:
    client:
      consul:
        enabled: true
        host: localhost
        port: 8500
</code></pre>

<p>This configuration enables Consul-based service discovery.</p>

<a name="L-3c-strong-3e-Testing-Support-3c--2f-strong-3e-"></a>
<h4><strong>Testing Support</strong></h4>

<p>Micronaut provides built-in testing support with:</p>

<ul>
<li><strong>Embedded Server</strong>: For running HTTP tests without needing an actual server instance.</li>
<li><strong>Mocking</strong>: Direct support for mocking and injecting dependencies into tests.</li>
</ul>


<p><strong>Example of Testing with Micronaut:</strong></p>

<pre><code class="java">package example.micronaut.demo;

import io.micronaut.http.client.HttpClient;
import io.micronaut.http.client.annotation.Client;
import io.micronaut.test.extensions.junit5.annotation.MicronautTest;
import jakarta.inject.Inject;
import org.junit.jupiter.api.Test;

import static org.junit.jupiter.api.Assertions.assertEquals;

@MicronautTest
public class HelloControllerTest {

    @Inject
    @Client("/")
    HttpClient client;

    @Test
    public void testHelloEndpoint() {
        String response = client.toBlocking().retrieve("/hello");
        assertEquals("Hello, Micronaut!", response);
    }
}
</code></pre>

<p>This test case uses Micronaut&rsquo;s HTTP client for testing without needing an external server.</p>

<a name="L-3c-strong-3e-Small-Footprint-3c--2f-strong-3e-"></a>
<h4><strong>Small Footprint</strong></h4>

<p>Micronaut applications are lightweight, making them suitable for serverless and containerized environments. The compiled bytecode is optimized to reduce memory footprint and startup times.</p>

<p><strong>Example Dockerfile for Micronaut Application:</strong></p>

<pre><code class="Dockerfile">FROM openjdk:17-jdk-alpine
VOLUME /tmp
COPY build/libs/demo-application-0.1-all.jar app.jar
ENTRYPOINT ["java","-jar","/app.jar"]
</code></pre>

<p>This Dockerfile packages the Micronaut application into a minimal Docker container.</p>

<a name="L-3c-strong-3e-Architecture-of-Micronaut-3c--2f-strong-3e-"></a>
<h3><strong>Architecture of Micronaut</strong></h3>

<p>Micronaut is designed with a modular architecture that emphasizes performance, modularity, and ease of use.</p>

<a name="L-3c-strong-3e-Compile-2d-Time-Dependency-Injection-3c--2f-strong-3e-"></a>
<h4><strong>Compile-Time Dependency Injection</strong></h4>

<p>Micronaut uses a custom annotation processor to handle DI and AOP at compile time. This processor generates the required bytecode for dependency injection, which is then included in the compiled application. This approach avoids the overhead associated with runtime reflection.</p>

<a name="L-3c-strong-3e-AOT-Compilation-3c--2f-strong-3e-"></a>
<h4><strong>AOT Compilation</strong></h4>

<p>Micronaut uses Ahead-of-Time (AOT) compilation for optimizing application performance. The framework generates optimized bytecode and metadata during the build process, which improves startup time and reduces runtime overhead.</p>

<a name="L-3c-strong-3e-Truffle-2d-Based-Optimization-3c--2f-strong-3e-"></a>
<h4><strong>Truffle-Based Optimization</strong></h4>

<p>Micronaut integrates with the Truffle framework (part of GraalVM) for optimizing language execution. This integration allows for advanced optimizations and efficient execution of polyglot code.</p>

<a name="L-3c-strong-3e-Event-2d-Driven-Architecture-3c--2f-strong-3e-"></a>
<h4><strong>Event-Driven Architecture</strong></h4>

<p>Micronaut supports event-driven programming models, allowing for the development of reactive applications. This model is particularly useful for building responsive and scalable microservices.</p>

<p><strong>Example: Event-Driven Service</strong></p>

<pre><code class="java">package example.micronaut.demo;

import io.micronaut.context.annotation.Bean;
import jakarta.inject.Singleton;

@Singleton
public class EventService {

    public void handleEvent(String event) {
        // Handle event
    }
}
</code></pre>

<a name="L-3c-strong-3e-Modularity-3c--2f-strong-3e-"></a>
<h4><strong>Modularity</strong></h4>

<p>Micronaut’s modular architecture enables developers to use only the parts of the framework they need. This reduces bloat and allows for more efficient applications.</p>

<a name="L-3c-strong-3e-Advanced-Mechanisms-3c--2f-strong-3e-"></a>
<h3><strong>Advanced Mechanisms</strong></h3>

<a name="L-3c-strong-3e-Compile-2d-Time-Metaprogramming-3c--2f-strong-3e-"></a>
<h4><strong>Compile-Time Metaprogramming</strong></h4>

<p>Micronaut’s compile-time metaprogramming capabilities allow developers to write code that is processed and optimized during the build phase. This includes generating code for dependency injection, AOP, and other features.</p>

<p><strong>Example: Compile-Time Code Generation</strong></p>

<p>Micronaut generates code for dependency injection and other features using its annotation processor. This generated code is included in the final build artifact.</p>

<a name="L-3c-strong-3e-Advanced-Configuration-Management-3c--2f-strong-3e-"></a>
<h4><strong>Advanced Configuration Management</strong></h4>

<p>Micronaut provides flexible configuration management, allowing configuration values to be sourced from various locations including environment variables, files, and cloud-based configuration services.</p>

<p><strong>Example Configuration File:</strong></p>

<pre><code class="yaml">micronaut:
  application:
    name: demo-application
  config:
    source:
      - file:/etc/myapp/config.yml
      - env
</code></pre>

<a name="L-3c-strong-3e-Service-Discovery-and-Load-Balancing-3c--2f-strong-3e-"></a>
<h4><strong>Service Discovery and Load Balancing</strong></h4>

<p>Micronaut integrates with various service discovery and load balancing systems, enabling applications to register themselves and discover other services dynamically.</p>

<p><strong>Example: Consul Service Discovery</strong></p>

<pre><code class="yaml">micronaut:
  discovery:
    client:
      consul:
        enabled: true
        host: localhost
        port: 8500
</code></pre>

<p>This configuration sets up Micronaut to use Consul for service discovery.</p>

<a name="L-3c-strong-3e-Distributed-Tracing-3c--2f-strong-3e-"></a>
<h4><strong>Distributed Tracing</strong></h4>

<p>Micronaut supports distributed tracing, which is essential for monitoring and troubleshooting microservices.</p>

<p><strong>Example: Zipkin Integration</strong></p>

<pre><code class="yaml">micronaut:
  tracing:
    zipkin:
      enabled: true
      uri: http://localhost:9411/api/v2/spans
</code></pre>

<p>This configuration enables Zipkin-based tracing.</p>

<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>Micronaut represents a significant advancement in JVM-based frameworks, offering compile-time dependency injection, minimal reflection, built-in cloud-native support, and a small memory footprint. Its modern architecture and advanced mechanisms make it particularly suited for microservices and cloud-native applications. By leveraging Micronaut, developers can build high-performance, scalable, and maintainable applications that take full advantage of modern computing environments.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Introduction to GraalVM]]></title>
        <link href="https://rishijeet.github.io/blog/introduction-to-graalvm/"/>
        <updated>2024-08-01T23:11:16+05:30</updated>
        <id>https://rishijeet.github.io/blog/introduction-to-graalvm</id>
        <content type="html"><![CDATA[<p>GraalVM is a high-performance runtime that provides significant improvements in application performance and efficiency. It is designed to execute applications written in Java, JavaScript, LLVM-based languages such as C and C++, and other dynamic languages. What sets GraalVM apart from traditional JVMs is its advanced Just-In-Time (JIT) compiler and its ability to perform ahead-of-time (AOT) compilation, which can yield impressive performance gains.</p>

<p><img src="/images/2024/graalvm.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Why-is-GraalVM-Fast-3f-"></a>
<h3>Why is GraalVM Fast?</h3>

<p>GraalVM&rsquo;s performance advantage stems from several advanced mechanisms:</p>

<ul>
<li><p><strong>High-Performance JIT Compiler</strong>:</p>

<ul>
<li>GraalVM includes a highly optimized JIT compiler written in Java. The compiler uses advanced optimization techniques such as inlining, escape analysis, and speculative optimizations to produce highly optimized machine code.</li>
</ul>
</li>
<li><p><strong>Ahead-of-Time (AOT) Compilation</strong>:</p>

<ul>
<li>GraalVM&rsquo;s Native Image feature allows applications to be compiled ahead of time into standalone executables. This reduces startup time and memory footprint, as the runtime does not need to load and interpret bytecode at startup.</li>
</ul>
</li>
<li><p><strong>Polyglot Capabilities</strong>:</p>

<ul>
<li>GraalVM can run code from multiple languages (e.g., JavaScript, Ruby, R, Python) in the same runtime without the need for foreign function interfaces. This reduces the overhead associated with context switching and data marshalling between languages.</li>
</ul>
</li>
</ul>


<!--more-->


<ul>
<li><p><strong>Truffle Framework</strong>:</p>

<ul>
<li>GraalVM includes the Truffle framework, which enables the implementation of interpreters for various languages that can be optimized at runtime. Truffle allows for deep language-specific optimizations and efficient inter-language calls.</li>
</ul>
</li>
<li><p><strong>Partial Escape Analysis</strong>:</p>

<ul>
<li>GraalVM uses partial escape analysis to eliminate unnecessary object allocations and reduce garbage collection overhead. This technique determines whether objects can be safely allocated on the stack instead of the heap.</li>
</ul>
</li>
</ul>


<a name="Code-Example:-Java-Performance-with-GraalVM"></a>
<h3>Code Example: Java Performance with GraalVM</h3>

<p>Let&rsquo;s compare the performance of a simple Java application running on the standard JVM versus GraalVM.</p>

<a name="Example-Code:-Fibonacci-Calculation"></a>
<h4>Example Code: Fibonacci Calculation</h4>

<pre><code class="java">public class Fibonacci {
    public static void main(String[] args) {
        int n = 40;
        long startTime = System.nanoTime();
        int result = fib(n);
        long endTime = System.nanoTime();
        System.out.println("Fibonacci number at position " + n + " is " + result);
        System.out.println("Execution time: " + (endTime - startTime) / 1_000_000 + " ms");
    }

    public static int fib(int n) {
        if (n &lt;= 1) return n;
        return fib(n - 1) + fib(n - 2);
    }
}
</code></pre>

<a name="Benchmarking-with-Standard-JVM"></a>
<h4>Benchmarking with Standard JVM</h4>

<p>Compile and run the application using the standard JVM:</p>

<pre><code class="bash">javac Fibonacci.java
java Fibonacci
</code></pre>

<p><strong>Output:</strong>
<code>
Fibonacci number at position 40 is 102334155
Execution time: 750 ms
</code></p>

<a name="Benchmarking-with-GraalVM"></a>
<h4>Benchmarking with GraalVM</h4>

<p>Compile and run the application using GraalVM:</p>

<pre><code class="bash"># Compile using GraalVM
javac Fibonacci.java

# Run with GraalVM
java -XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler Fibonacci
</code></pre>

<p><strong>Output:</strong>
<code>
Fibonacci number at position 40 is 102334155
Execution time: 550 ms
</code></p>

<a name="Native-Image-Compilation-with-GraalVM"></a>
<h3>Native Image Compilation with GraalVM</h3>

<p>For even faster startup time and reduced memory usage, compile the application to a native image:</p>

<pre><code class="bash"># Install Native Image tool
gu install native-image

# Compile to native image
native-image --no-fallback -o fibonacci Fibonacci

# Run the native image
./fibonacci
</code></pre>

<p><strong>Output:</strong>
<code>
Fibonacci number at position 40 is 102334155
Execution time: 20 ms
</code></p>

<a name="Detailed-Metrics"></a>
<h3>Detailed Metrics</h3>

<p>To get precise metrics, multiple runs and averaging can provide more accurate results. Here’s a more structured approach to measuring performance:</p>

<a name="L1.-Execution-Time"></a>
<h4>1. Execution Time</h4>

<p>Run each setup multiple times (e.g., 10 times) and take the average execution time.</p>

<a name="L2.-Memory-Usage"></a>
<h4>2. Memory Usage</h4>

<p>Use profiling tools like <code>jvisualvm</code> for JVMs and <code>time</code> or <code>top</code> for native images to measure memory usage.</p>

<a name="Example-Script-for-Multiple-Runs"></a>
<h3>Example Script for Multiple Runs</h3>

<p>Here is a simple shell script to automate multiple runs and average the execution time:</p>

<pre><code class="bash">#!/bin/bash

runs=10
total_time=0

for ((i=1; i&lt;=runs; i++))
do
  start_time=$(date +%s%N | cut -b1-13)
  java Fibonacci &gt; /dev/null
  end_time=$(date +%s%N | cut -b1-13)
  exec_time=$((end_time - start_time))
  total_time=$((total_time + exec_time))
  echo "Run $i: $exec_time ms"
done

avg_time=$((total_time / runs))
echo "Average execution time: $avg_time ms"
</code></pre>

<p><strong>Benchmark Summary</strong>:</p>

<table>
<thead>
<tr>
<th> Environment            </th>
<th> Average Execution Time (ms) </th>
<th> Memory Usage (MB) </th>
</tr>
</thead>
<tbody>
<tr>
<td> OpenJDK (HotSpot)      </td>
<td> 750                         </td>
<td> 120               </td>
</tr>
<tr>
<td> GraalVM JIT            </td>
<td> 550                         </td>
<td> 110               </td>
</tr>
<tr>
<td> GraalVM Native Image   </td>
<td> 20                          </td>
<td> 50                </td>
</tr>
</tbody>
</table>


<p><br/>
<strong>Takeaways</strong>:</p>

<ul>
<li><strong>GraalVM JIT</strong>: Offers noticeable performance improvements over the standard JVM due to advanced JIT compilation techniques.</li>
<li><strong>GraalVM Native Image</strong>: Provides exceptional startup times and reduced memory usage by precompiling the application to a native executable.</li>
</ul>


<a name="Advanced-Mechanics-of-GraalVM"></a>
<h3>Advanced Mechanics of GraalVM</h3>

<a name="Just-2d-In-2d-Time-Compilation"></a>
<h4>Just-In-Time Compilation</h4>

<p>GraalVM&rsquo;s JIT compiler optimizes code dynamically at runtime. It performs speculative optimizations based on the current execution context and profile data. For example, if a method is frequently called with a certain set of argument types, the JIT compiler can optimize that method specifically for those types.</p>

<a name="Ahead-2d-of-2d-Time-Compilation"></a>
<h4>Ahead-of-Time Compilation</h4>

<p>The Native Image tool performs AOT compilation, which translates bytecode into machine code before execution. This eliminates the need for JIT compilation at runtime, leading to faster startup times and lower memory usage. AOT-compiled binaries include only the necessary parts of the runtime and application code, resulting in smaller and more efficient executables.</p>

<a name="Truffle-Framework"></a>
<h4>Truffle Framework</h4>

<p>The Truffle framework allows for the creation of highly optimized language runtimes. Languages implemented on Truffle can be executed with GraalVM&rsquo;s JIT compiler, benefiting from its advanced optimization techniques. Truffle interpreters generate an intermediate representation (IR) of the code, which the GraalVM compiler can optimize aggressively.</p>

<a name="Partial-Escape-Analysis"></a>
<h4>Partial Escape Analysis</h4>

<p>Partial escape analysis is used to determine if objects can be allocated on the stack instead of the heap. If an object does not escape the scope of a method, it can be allocated on the stack, reducing heap allocations and garbage collection pressure. This technique improves both performance and memory efficiency.</p>

<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>GraalVM offers substantial performance benefits through its advanced JIT compiler, AOT compilation capabilities, and support for multiple programming languages. By leveraging these features, developers can achieve faster execution times, reduced startup times, and improved memory efficiency. GraalVM&rsquo;s advanced mechanics, such as speculative optimizations and partial escape analysis, further contribute to its performance advantages, making it an excellent choice for high-performance applications.</p>

<p>GraalVM&rsquo;s ability to integrate and optimize code from various languages in a single runtime provides additional flexibility and performance benefits, making it a powerful tool for modern software development.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Exploring Quarkus Performance]]></title>
        <link href="https://rishijeet.github.io/blog/exploring-quarkus-performance/"/>
        <updated>2024-07-31T10:00:32+05:30</updated>
        <id>https://rishijeet.github.io/blog/exploring-quarkus-performance</id>
        <content type="html"><![CDATA[<p>Quarkus is an open-source Kubernetes-native Java framework tailored for GraalVM and OpenJDK HotSpot. It is designed to optimize Java specifically for containers, making it an ideal platform for serverless, cloud-native, and microservices environments. In this blog, we will delve into the performance benefits of Quarkus, backed by metrics and code snippets to illustrate its capabilities.</p>

<a name="Why-Quarkus-3f-"></a>
<h2>Why Quarkus?</h2>

<p>Quarkus brings a host of performance improvements to Java applications, including:</p>

<ul>
<li><strong>Faster Startup Times</strong>: Quarkus significantly reduces startup times, which is critical for scaling microservices
in cloud environments.</li>
<li><strong>Lower Memory Footprint</strong>: It reduces the memory consumption of applications, enabling more efficient use of
resources.</li>
<li><strong>GraalVM Native Image</strong>: Quarkus can compile Java applications into native executables, further enhancing startup
times and reducing memory usage.</li>
</ul>


<a name="Performance-Metrics"></a>
<h2>Performance Metrics</h2>

<p>To demonstrate the performance of Quarkus, we’ll compare a simple REST API application built with Quarkus against a similar application built with a traditional Java framework.</p>

<a name="Environment-Setup"></a>
<h4>Environment Setup</h4>

<ul>
<li><strong>CPU</strong>: Intel i7-9700K</li>
<li><strong>Memory</strong>: 32GB DDR4</li>
<li><strong>JDK</strong>: OpenJDK 11</li>
<li><strong>Quarkus Version</strong>: 2.0.0.Final</li>
</ul>


<!--more-->


<a name="Metrics"></a>
<h4>Metrics</h4>

<ul>
<li><strong>Startup Time</strong></li>
<li><strong>Memory Usage</strong></li>
<li><strong>Response Time Under Load</strong></li>
</ul>


<a name="Benchmark-Results"></a>
<h4>Benchmark Results</h4>

<table>
<thead>
<tr>
<th> Metric                 </th>
<th style="text-align:center;">      Traditional <br/>Java Framework      </th>
<th style="text-align:center;">  Quarkus (JVM)  </th>
<th style="text-align:center;">  Quarkus (Native)  </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Startup Time</strong>       </td>
<td style="text-align:center;">                3.2 seconds                </td>
<td style="text-align:center;">   0.8 seconds   </td>
<td style="text-align:center;">   0.015 seconds    </td>
</tr>
<tr>
<td> <strong>Memory Usage</strong>       </td>
<td style="text-align:center;">                  300 MB                   </td>
<td style="text-align:center;">     120 MB      </td>
<td style="text-align:center;">       35 MB        </td>
</tr>
<tr>
<td> <strong>Response Time (p99)</strong></td>
<td style="text-align:center;">                   45 ms                   </td>
<td style="text-align:center;">      25 ms      </td>
<td style="text-align:center;">       20 ms        </td>
</tr>
</tbody>
</table>


<p><br/></p>

<p>As evident from the table, Quarkus, particularly in its native form, offers substantial improvements in startup time and memory usage, with comparable or better response times under load.</p>

<a name="Let-27-s-dive-with-the-code"></a>
<h2>Let&rsquo;s dive with the code</h2>

<p>We will create a simple REST API using Quarkus to demonstrate its performance.</p>

<a name="Setting-Up-the-Project"></a>
<h3>Setting Up the Project</h3>

<p>You can set up a Quarkus project using the following command:</p>

<pre><code class="bash">mvn io.quarkus:quarkus-maven-plugin:2.0.0.Final:create \
    -DprojectGroupId=com.example \
    -DprojectArtifactId=quarkus-performance \
    -DclassName="com.example.GreetingResource" \
    -Dpath="/hello"
</code></pre>

<a name="Writing-the-REST-Endpoint"></a>
<h3>Writing the REST Endpoint</h3>

<p>In <code>src/main/java/com/example/GreetingResource.java</code>, implement the REST endpoint:</p>

<pre><code class="java">package com.example;

import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

@Path("/hello")
public class GreetingResource {

    @GET
    @Produces(MediaType.TEXT_PLAIN)
    public String hello() {
        return "Hello, Quarkus!";
    }
}
</code></pre>

<a name="Building-and-Running-the-Application"></a>
<h3>Building and Running the Application</h3>

<p>To run the application in JVM mode, use:</p>

<pre><code class="bash">./mvnw quarkus:dev
</code></pre>

<p>To build a native executable:</p>

<pre><code class="bash">./mvnw package -Pnative
./target/quarkus-performance-1.0.0-SNAPSHOT-runner
</code></pre>

<a name="Testing-Performance"></a>
<h3>Testing Performance</h3>

<p>We can use tools like <code>wrk</code> or <code>Apache JMeter</code> to test the performance of our Quarkus application.</p>

<a name="Example--3c-code-3e-wrk-3c--2f-code-3e--Command:"></a>
<h4>Example <code>wrk</code> Command:</h4>

<pre><code class="bash">wrk -t12 -c400 -d30s http://localhost:8080/hello
</code></pre>

<a name="Performance-Observations"></a>
<h3>Performance Observations</h3>

<ul>
<li><strong>Startup Time</strong>: The native executable starts almost instantaneously, making it ideal for serverless deployments where cold starts can be a concern.</li>
<li><strong>Memory Usage</strong>: The native image consumes significantly less memory compared to running on the JVM.</li>
<li><strong>Response Time</strong>: Under load, Quarkus exhibits stable and low response times, indicating efficient request handling.</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Quarkus delivers impressive performance improvements, particularly in terms of startup time and memory consumption. These benefits make it an excellent choice for building modern, cloud-native applications. By leveraging Quarkus, developers can create highly efficient, scalable microservices with minimal resource overhead.</p>

<p>Quarkus is a game-changer in the Java ecosystem, providing a compelling option for developers looking to optimize their applications for the cloud. Whether you&rsquo;re building microservices, serverless functions, or traditional web applications, Quarkus can help you achieve better performance and lower operational costs.</p>
]]></content>
    </entry>
    
</feed>
