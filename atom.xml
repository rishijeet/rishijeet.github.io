<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title><![CDATA[Rishijeet Mishra]]></title>
    <link href="https://rishijeet.github.io/atom.xml" rel="self"/>
    <link href="https://rishijeet.github.io/"/>
    <updated>2025-07-27T23:39:48+05:30</updated>
    <id>https://rishijeet.github.io/</id>
    <author>
        <name><![CDATA[Rishijeet Mishra]]></name>
        <email><![CDATA[rishijeet@gmail.com]]></email>
    </author>
    <generator uri="http://octopress.org/">Octopress</generator>

    
    <entry>
        <title type="html"><![CDATA[Data Centers in the United States &amp; AI-Driven Developments]]></title>
        <link href="https://rishijeet.github.io/blog/data-centers-in-the-united-states-and-ai-driven-developments/"/>
        <updated>2025-07-27T23:25:21+05:30</updated>
        <id>https://rishijeet.github.io/blog/data-centers-in-the-united-states-and-ai-driven-developments</id>
        <content type="html"><![CDATA[<p>Data centers are the backbone of the digital economy, housing the servers, storage systems, and networking equipment
that power cloud computing, web services, and data-intensive applications. In the United States, data centers are strategically located to meet the demands of businesses, governments, and consumers. The rise of artificial intelligence (AI) has further amplified the importance of data centers, requiring specialized infrastructure to handle complex computational workloads. This article explores the primary locations of data centers in the US, the reasons behind their selection, and recent developments driven by AI.</p>

<p><img src="https://rishijeet.github.io/images/2025/data_center.png" height="300" width="900" alt="Alt text" /></p>

<a name="Major-Data-Center-Locations-in-the-United-States"></a>
<h2>Major Data Center Locations in the United States</h2>

<p>The US hosts approximately 5,381 data centers, with significant concentrations in specific regions that offer optimal conditions for operation. The top data center markets include:</p>

<!--more-->


<ol>
<li><strong>Northern Virginia (Ashburn)</strong>: Often called the &ldquo;Data Center Capital of the World,&rdquo; this region hosts over 250 facilities. Its proximity to Washington, D.C., provides access to dense fiber optic networks and robust connectivity, making it a hub for hyperscale and colocation providers.</li>
<li><strong>Northern California (Silicon Valley)</strong>: A center of technological innovation, Silicon Valley is home to numerous data centers supporting tech giants and startups.</li>
<li><strong>New York/New Jersey</strong>: A key financial hub, this area supports high-demand data processing for banking and trading industries.</li>
<li><strong>Chicago</strong>: Its central location and strong network infrastructure make it ideal for low-latency connections across the US.</li>
<li><strong>Dallas</strong>: Benefits from a central location, competitive energy prices, and ample land for large-scale facilities.</li>
<li><strong>Phoenix</strong>: Offers a dry climate for efficient cooling and significant land availability.</li>
<li><strong>Atlanta</strong>: A growing market with good connectivity and a business-friendly environment.</li>
<li><strong>Portland (including Hillsboro, Oregon)</strong>: Known for cool climates and access to renewable energy.</li>
<li><strong>Seattle (including Quincy, Washington)</strong>: Leverages hydroelectric power and favorable temperatures.</li>
<li><strong>Los Angeles</strong>: A major metropolitan area with high demand for data services.</li>
</ol>


<p>These locations are detailed in sources like <a href="https://www.datacentermap.com/usa/">DataCenterMap</a> and <a href="https://dgtlinfra.com/united-states-data-centers/">Dgtl Infra</a>, which highlight their strategic importance.</p>

<a name="Reasons-for-Location-Selection"></a>
<h2>Reasons for Location Selection</h2>

<p>The choice of data center locations is driven by a combination of technical, economic, and environmental factors. The following criteria are critical in site selection, as outlined in sources such as <a href="https://www.techtarget.com/searchdatacenter/tip/Considerations-for-data-center-site-selection">TechTarget</a> and <a href="https://blog.equinix.com/blog/2024/08/06/5-considerations-for-choosing-data-center-locations/">Equinix</a>:</p>

<ol>
<li><strong>Reliable and Abundant Power</strong>: Data centers consume significant electricity, often equivalent to tens of thousands of households. Locations with access to robust power grids and competitive energy rates, such as Texas with its deregulated energy market, are preferred. Renewable energy sources like solar and wind are increasingly prioritized to reduce carbon footprints.</li>
<li><strong>Fiber Optic Connectivity</strong>: Proximity to major internet exchange points and fiber networks ensures low latency and high bandwidth, critical for data transmission. Northern Virginia and Dallas are notable for their connectivity hubs.</li>
<li><strong>Land Availability</strong>: Large parcels of affordable land are necessary for current operations and future expansion. States like Arizona and Texas offer ample space for hyperscale campuses.</li>
<li><strong>Low Risk of Natural Disasters</strong>: Areas with minimal risk of earthquakes, floods, or hurricanes are favored to ensure uptime. For example, Chicago’s central location reduces exposure to coastal hazards.</li>
<li><strong>Climate and Cooling</strong>: Cooler climates, like those in Seattle or Portland, reduce cooling costs, while water availability supports cooling systems. Dry climates in Phoenix aid in efficient cooling.</li>
<li><strong>Tax Incentives and Regulations</strong>: States offering tax breaks or streamlined regulations, such as Virginia, attract data center investments. Local zoning laws must also permit industrial operations.</li>
<li><strong>Workforce Availability</strong>: Access to skilled labor for construction and operation is essential. Silicon Valley benefits from a tech-savvy workforce.</li>
<li><strong>Proximity to Customers</strong>: For latency-sensitive applications, being close to end-users or major markets enhances performance.</li>
<li><strong>Security</strong>: Physical security, including avoiding high-risk areas like major highways, is a priority.</li>
<li><strong>Data Gravity</strong>: The tendency for data to attract infrastructure means locations with existing data concentrations, like Northern Virginia, are preferred for cloud connectivity.</li>
</ol>


<p>These factors explain why regions like Northern Virginia, with its robust infrastructure and proximity to key markets, dominate the data center landscape. Similarly, Dallas’s central location and energy advantages make it a growing hub, as noted in <a href="https://www.datacenterknowledge.com/data-center-site-selection/mapping-the-best-data-center-locations-in-2024">DataCenterKnowledge</a>.</p>

<a name="Recent-Developments-in-Data-Centers-for-AI"></a>
<h2>Recent Developments in Data Centers for AI</h2>

<p>The rapid growth of AI has significantly impacted data center requirements, particularly in terms of computational power and energy consumption. AI workloads, such as machine learning and large language models, demand specialized hardware like GPUs and TPUs, as well as scalable infrastructure. Recent developments highlight the following trends:</p>

<a name="Massive-Investments"></a>
<h3>Massive Investments</h3>

<p>Major tech companies are pouring billions into data center expansions to support AI:</p>

<ul>
<li><strong>Microsoft</strong>: Plans to invest $80 billion in AI data centers in fiscal 2025, with over half allocated to US projects.</li>
<li><strong>Meta</strong>: Investing up to $65 billion in 2025 for AI data centers in Arizona and Louisiana.</li>
<li><strong>OpenAI</strong>: Secured $11.6 billion to expand a Texas data center with Crusoe, planning to house up to 50,000 Nvidia Blackwell GPUs per building.</li>
</ul>


<a name="Specialized-Infrastructure"></a>
<h3>Specialized Infrastructure</h3>

<p>Data centers are adapting to AI’s computational needs:</p>

<ul>
<li><strong>Hardware Upgrades</strong>: Facilities are incorporating GPUs and TPUs to handle AI workloads efficiently. For example, Nvidia’s Blackwell GPUs are being deployed in Texas data centers.</li>
<li><strong>Energy Efficiency</strong>: AI’s high power demands, projected to increase data center power consumption by 165% by 2030 (Goldman Sachs, <a href="https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030">link</a>), are driving innovations in cooling and renewable energy use.</li>
</ul>


<a name="Geographic-Diversification"></a>
<h3>Geographic Diversification</h3>

<p>New AI-focused data centers are emerging in states beyond traditional hubs:</p>

<ul>
<li><strong>Texas</strong>: Projects like the 2GW Sweetwater Data Center Hub in Abilene and OpenAI’s expansion highlight Texas’s appeal due to its energy market and land availability.</li>
<li><strong>Arizona</strong>: Developments include Novva Data Centers’ Project Borealis in Mesa (300 MW) and Edgecore Digital’s 450 MW expansion in Metro Phoenix (<a href="https://www.datacenterknowledge.com/data-center-construction/new-data-center-developments-june-2025">DataCenterKnowledge</a>).</li>
<li><strong>Louisiana</strong>: Meta’s planned $10 billion AI data center.</li>
<li><strong>Other States</strong>: OpenAI is considering sites in Michigan, Wisconsin, and Wyoming, renting 4.5 GW of power from Oracle.</li>
</ul>


<a name="Government-Support"></a>
<h3>Government Support</h3>

<p>Federal initiatives are facilitating AI data center growth:</p>

<ul>
<li>The Department of Energy selected four sites (Idaho, Oak Ridge, Paducah, and Savannah River) for AI data center and energy infrastructure development (<a href="https://www.energy.gov/articles/doe-announces-site-selection-ai-data-center-and-energy-infrastructure-development">DOE</a>).</li>
<li>A presidential action is accelerating permitting for AI data centers and related infrastructure (<a href="https://www.whitehouse.gov/presidential-actions/2025/07/accelerating-federal-permitting-of-data-center-infrastructure/">WhiteHouse</a>).</li>
</ul>


<a name="Challenges"></a>
<h3>Challenges</h3>

<p>Despite growth, challenges include:</p>

<ul>
<li><strong>Power Constraints</strong>: Some markets, like Virginia, face power availability issues (<a href="https://www.datacenters.com/locations/united-states">Datacenters.com</a>).</li>
<li><strong>Local Opposition</strong>: $64 billion worth of data center projects have been delayed or blocked since 2023 due to community concerns (<a href="https://www.datacenterknowledge.com/regulations/local-opposition-hinders-more-data-center-construction-projects">DataCenterKnowledge</a>).</li>
</ul>


<a name="Recent-AI-Data-Center-Projects-in-the-US"></a>
<h3>Recent AI Data Center Projects in the US</h3>

<p>  <style>
    .ai-data-center-table-container {
      font-family: &lsquo;Segoe UI&rsquo;, Tahoma, Geneva, Verdana, sans-serif;
      background-color: #f9f9f9;
      padding: 0;
      margin: 0;
    }</p>

<pre><code>.ai-data-center-table {
  width: 100%;
  border-collapse: collapse;
  margin: 0;
  background-color: #fff;
}

.ai-data-center-table thead {
  background-color: #005f73;
  color: #ffffff;
}

.ai-data-center-table th,
.ai-data-center-table td {
  padding: 12px;
  text-align: left;
  border-bottom: 1px solid #ddd;
}

.ai-data-center-table tbody tr:nth-child(even) {
  background-color: #f0f0f0;
}

.ai-data-center-table tbody tr:hover {
  background-color: #e0f7fa;
}

.ai-data-center-table a {
  color: #0077b6;
  text-decoration: none;
}

.ai-data-center-table a:hover {
  text-decoration: underline;
}
</code></pre>

<p>  </style></p>

<div class="ai-data-center-table-container">
  <table class="ai-data-center-table">
    <thead>
      <tr>
        <th>Company/Parties Involved</th>
        <th>Location</th>
        <th>Capacity/Details</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Microsoft</td>
        <td>Nationwide (US focus)</td>
        <td>$80B investment in AI data centers for 2025</td>
      </tr>
      <tr>
        <td>Meta</td>
        <td>Arizona, Louisiana</td>
        <td>Up to $65B, including $10B Louisiana data center</td>
      </tr>
      <tr>
        <td>OpenAI/Crusoe</td>
        <td>Abilene, Texas</td>
        <td>1.2 GW, up to 50,000 Nvidia Blackwell GPUs per building</td>
      </tr>
      <tr>
        <td>Novva Data Centers</td>
        <td>Mesa, Arizona</td>
        <td>Project Borealis, 300 MW total</td>
      </tr>
      <tr>
        <td>Edgecore Digital</td>
        <td>Metro Phoenix, Arizona</td>
        <td>450 MW capacity expansion</td>
      </tr>
      <tr>
        <td>Tract</td>
        <td>Caldwell County, Texas</td>
        <td>Over 2 GW at full build-out</td>
      </tr>
      <tr>
        <td>Applied Digital/CoreWeave</td>
        <td>Ellendale, North Dakota</td>
        <td>250 MW lease agreements</td>
      </tr>
    </tbody>
  </table>
</div>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Data centers in the United States are strategically located in regions like Northern Virginia, Silicon Valley, and Dallas, driven by factors such as power availability, connectivity, and economic incentives. The surge in AI applications is reshaping the data center landscape, with significant investments in infrastructure to support high-compute workloads. New projects in states like Texas, Arizona, and Louisiana, coupled with federal support, highlight the dynamic growth of this sector. As AI continues to drive demand, data centers will play a pivotal role in the digital economy, balancing innovation with challenges like power constraints and local opposition.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Energy Requirements for AI Infrastructure: Current and Future Impacts]]></title>
        <link href="https://rishijeet.github.io/blog/energy-requirements-for-ai-infrastructure-current-and-future-impacts/"/>
        <updated>2025-07-26T21:16:34+05:30</updated>
        <id>https://rishijeet.github.io/blog/energy-requirements-for-ai-infrastructure-current-and-future-impacts</id>
        <content type="html"><![CDATA[<p>The rapid expansion of artificial intelligence (AI), particularly large language models (LLMs) and generative AI, has driven an unprecedented surge in energy demand due to the computational intensity of training and operating these systems. Eric Schmidt, former Google CEO, has highlighted electricity as the primary limiter of AI growth, estimating that the U.S. will require an additional 92 gigawatts (GW) of power—equivalent to the output of 92 nuclear power plants—to sustain the AI revolution. This analysis explores the current energy consumption of major companies’ AI infrastructure, projects future energy needs through 2035, and examines how these demands will reshape the energy sector, drawing on available data from web sources and posts on X.</p>

<a name="Current-Energy-Consumption-by-Major-Companies"></a>
<h2>Current Energy Consumption by Major Companies</h2>

<a name="Overview"></a>
<h3>Overview</h3>

<p>Major tech companies, or “hyperscalers” (e.g., Microsoft, Google, Meta, Amazon, OpenAI), are the primary drivers of AI infrastructure energy demand, operating massive data centers for training and inference of AI models. Training a single state-of-the-art AI model, such as OpenAI’s GPT-4, can consume 50 gigawatt-hours (GWh) of electricity, equivalent to the annual energy use of 4,800 U.S. households. Inference (running AI models for user queries) is also energy-intensive, with a single ChatGPT query requiring approximately 2.9 watt-hours, nearly 10 times that of a Google search (0.3 watt-hours). Below is an overview of key players’ energy footprints based on available data:</p>

<p><img src="https://rishijeet.github.io/images/2025/Screenshot%202025-07-26%20at%208.43.24%E2%80%AFPM.png" height="300" width="900" alt="Alt text" /></p>

<!--more-->


<ul>
<li><p><strong>Microsoft</strong>:</p>

<ul>
<li><strong>Current Usage</strong>: Microsoft’s data centers, which support Azure and AI initiatives like Copilot, consumed an estimated 17 GW of power globally in 2023, with AI workloads accounting for a growing share. Training a single large model can require 50-100 GWh, and inference for millions of daily queries adds significantly to this demand.</li>
<li><strong>Initiatives</strong>: Microsoft has committed to purchasing 10.5 GW of renewable energy from Brookfield Asset Management between 2026 and 2030 to power its AI data centers, marking one of the largest corporate renewable energy deals to date.<a href="https://www.energypolicy.columbia.edu/projecting-the-electricity-demand-growth-of-generative-ai-large-language-models-in-the-us/"></a></li>
<li><strong>Specific Projects</strong>: Microsoft’s deal to buy power from the reopened Three Mile Island nuclear reactor (Constellation Energy) will provide 835 MW of carbon-free power for 20 years, targeting AI data center needs.<a href="https://energy.mit.edu/news/the-multi-faceted-challenge-of-powering-ai/"></a></li>
</ul>
</li>
<li><p><strong>Google</strong>:</p>

<ul>
<li><strong>Current Usage</strong>: Google’s global data center power consumption is estimated at 15-20 GW, with AI workloads (e.g., Gemini models) contributing 14% of this demand in 2023. Google expects to spend $75 billion on AI infrastructure in 2025, much of which will go toward energy-intensive data centers.<a href="https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/"></a><a href="https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030"></a></li>
<li><strong>Initiatives</strong>: Google is investing in renewable energy and has issued a roadmap emphasizing AI’s potential to drive a “new era of American innovation” through productivity gains, but acknowledges that energy demands will outpace current infrastructure.<a href="https://www.city-journal.org/article/artificial-intelligence-energy-electricity-demand"></a></li>
</ul>
</li>
<li><p><strong>Meta</strong>:</p>

<ul>
<li><strong>Current Usage</strong>: Meta’s planned $10 billion AI data center in Louisiana, set to begin operations in 2028, will require 2 GW for computation alone, with additional power for cooling. This single facility’s energy demand is equivalent to that of 200,000 households.<a href="https://www.technologyreview.com/2025/05/20/1116272/ai-natural-gas-data-centers-energy-power-plants/"></a></li>
<li><strong>Initiatives</strong>: Meta is investing over $200 million in infrastructure (roads, water systems) to support its data centers and claims to cover the full cost of utility grid upgrades to avoid passing costs to consumers.<a href="https://www.technologyreview.com/2025/05/20/1116272/ai-natural-gas-data-centers-energy-power-plants/"></a></li>
</ul>
</li>
<li><p><strong>OpenAI</strong>:</p>

<ul>
<li><strong>Current Usage</strong>: Training GPT-4 consumed an estimated 50 GWh, enough to power San Francisco for three days. With millions of daily queries, OpenAI’s inference energy demand is significant, though exact figures are undisclosed due to the company’s lack of transparency.<a href="https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/"></a><a href="https://www.forbes.com/sites/arielcohen/2024/05/23/ai-is-pushing-the-world-towards-an-energy-crisis/"></a></li>
<li><strong>Initiatives</strong>: OpenAI’s Stargate initiative, announced with President Donald Trump, aims to build data centers consuming up to 5 GW each, with a total investment of $500 billion. This project could require 15-25 GW across multiple facilities, equivalent to the power needs of a small state.<a href="https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/"></a><a href="https://www.cfr.org/blog/america-may-not-need-massive-energy-build-out-power-ai-revolution"></a></li>
</ul>
</li>
<li><p><strong>Amazon</strong>:</p>

<ul>
<li><strong>Current Usage</strong>: Amazon Web Services (AWS) operates over 100 data centers globally, with an estimated power consumption of 20 GW in 2023. AI workloads, including Amazon Bedrock and custom AI chips, are driving increased energy use, though specific AI-related figures are not publicly detailed.</li>
<li><strong>Initiatives</strong>: Amazon is investing in renewable energy and energy-efficient data center designs but faces challenges in scaling power supply to meet AI-driven demand.<a href="https://www.nature.com/articles/d41586-025-00616-z"></a></li>
</ul>
</li>
</ul>


<a name="Aggregate-Industry-Impact"></a>
<h3>Aggregate Industry Impact</h3>

<ul>
<li><strong>Global Data Center Demand</strong>: In 2023, global data centers consumed 240-340 terawatt-hours (TWh), or 1-1.3% of world electricity demand, with AI-specific data centers accounting for approximately 14 GW of additional capacity.<a href="https://www.energypolicy.columbia.edu/projecting-the-electricity-demand-growth-of-generative-ai-large-language-models-in-the-us/"></a><a href="https://www.nature.com/articles/d41586-025-00616-z"></a></li>
<li><strong>U.S. Data Center Demand</strong>: U.S. data centers used 176 TWh (4.4% of national electricity) in 2023, with AI workloads driving a significant portion. By 2027, AI data centers alone could require 68 GW globally, nearly matching California’s 2022 total power capacity of 86 GW.<a href="https://www.rand.org/pubs/research_reports/RRA3572-1.html"></a><a href="https://energy.mit.edu/news/the-multi-faceted-challenge-of-powering-ai/"></a></li>
</ul>


<a name="Future-Energy-Needs--28-2025-2d-2035-29-"></a>
<h2>Future Energy Needs (2025-2035)</h2>

<a name="Projections"></a>
<h3>Projections</h3>

<p>The energy demands of AI are expected to grow exponentially due to increasing model complexity, widespread adoption, and the shift toward AI “agents” that perform tasks autonomously. Key projections include:</p>

<p><img src="https://rishijeet.github.io/images/2025/Screenshot%202025-07-26%20at%208.43.39%E2%80%AFPM.png" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><p><strong>By 2027</strong>:</p>

<ul>
<li><strong>Global Demand</strong>: AI data centers could require 68 GW of power, doubling global data center power requirements from 2022. Training runs for advanced models may demand up to 1 GW per location, with inference needs growing as AI agents handle billions of daily queries.<a href="https://www.rand.org/pubs/research_reports/RRA3572-1.html"></a></li>
<li><strong>U.S. Demand</strong>: Goldman Sachs Research forecasts a 50% increase in data center power demand by 2027, with AI contributing 27% of the total (up from 14% in 2023). This translates to 84 GW globally, with the U.S. accounting for a significant share.<a href="https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030"></a></li>
<li><strong>Eric Schmidt’s Estimate</strong>: Schmidt’s claim of an additional 92 GW needed in the U.S. aligns with projections for AI-driven demand, equivalent to powering four to five projects on the scale of OpenAI’s Stargate (15-25 GW).<a href="https://www.cfr.org/blog/america-may-not-need-massive-energy-build-out-power-ai-revolution"></a></li>
</ul>
</li>
<li><p><strong>By 2030</strong>:</p>

<ul>
<li><strong>Global Demand</strong>: The International Energy Agency (IEA) projects global data center electricity demand to reach 945 TWh (slightly more than Japan’s current consumption), with AI-optimized data centers quadrupling in power needs.<a href="https://www.iea.org/news/ai-is-set-to-drive-surging-electricity-demand-from-data-centres-while-offering-the-potential-to-transform-how-the-energy-sector-works"></a></li>
<li><strong>U.S. Demand</strong>: U.S. data centers are expected to account for nearly half of the growth in national electricity demand, rising from 3-4% of total power in 2023 to 11-12% by 2030. This could require an additional 50 GW of capacity, with investments exceeding $500 billion in data center infrastructure alone (excluding grid upgrades).<a href="https://www.mckinsey.com/industries/private-capital/our-insights/how-data-centers-and-the-energy-sector-can-sate-ais-hunger-for-power"></a></li>
<li><strong>Training Needs</strong>: By 2030, training a single large AI model could demand up to 8 GW, equivalent to eight nuclear reactors, if current scaling trends continue.<a href="https://www.rand.org/pubs/research_reports/RRA3572-1.html"></a></li>
</ul>
</li>
<li><p><strong>By 2035</strong>:</p>

<ul>
<li><strong>Global Demand</strong>: If AI adoption and computational growth continue at current rates (doubling every 100 days), data center power demand could grow 160-165% from 2023 levels, reaching 3-4% of global electricity.<a href="https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030"></a><a href="https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand"></a></li>
<li><strong>U.S. Demand</strong>: The U.S. could see data center power consumption triple, potentially requiring 100 GW of additional capacity, as suggested by Schmidt’s estimate and supported by Duke University’s analysis of existing grid “headroom.”<a href="https://www.cfr.org/blog/america-may-not-need-massive-energy-build-out-power-ai-revolution"></a></li>
</ul>
</li>
</ul>


<a name="Energy-Bottlenecks"></a>
<h3>Energy Bottlenecks</h3>

<p><img src="https://rishijeet.github.io/images/2025/Screenshot%202025-07-26%20at%208.46.11%E2%80%AFPM.png" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><strong>Infrastructure Constraints</strong>: The U.S. power grid faces challenges in congestion, reliability, and transmission capacity. Current grid upgrades are insufficient to meet AI-driven demand, with new transmission line construction dropping from 4,000 miles in 2013 to 1,000 miles annually today.<a href="https://www.energypolicy.columbia.edu/projecting-the-electricity-demand-growth-of-generative-ai-large-language-models-in-the-us/"></a><a href="https://www.forbes.com/sites/arielcohen/2024/05/23/ai-is-pushing-the-world-towards-an-energy-crisis/"></a></li>
<li><strong>Energy Source Limitations</strong>: Renewable energy (solar, wind) is intermittent, requiring expensive storage solutions or backup gas/diesel generators, which conflict with zero-carbon goals. Nuclear power, while reliable, takes nearly a decade to scale, making it a medium-term solution.<a href="https://www.mckinsey.com/industries/private-capital/our-insights/how-data-centers-and-the-energy-sector-can-sate-ais-hunger-for-power"></a><a href="https://energy.mit.edu/news/the-multi-faceted-challenge-of-powering-ai/"></a></li>
<li><strong>Geographic Challenges</strong>: Data centers are concentrated in regions like Northern Virginia (consuming electricity equivalent to 800,000 homes), straining local grids and causing price hikes for residents.<a href="https://www.forbes.com/sites/arielcohen/2024/05/23/ai-is-pushing-the-world-towards-an-energy-crisis/"></a></li>
</ul>


<a name="Shaping-the-Future-Energy-Landscape"></a>
<h2>Shaping the Future Energy Landscape</h2>

<a name="Strategies-to-Meet-Demand"></a>
<h3>Strategies to Meet Demand</h3>

<p><img src="https://rishijeet.github.io/images/2025/Screenshot%202025-07-26%20at%208.46.26%E2%80%AFPM.png" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><strong>Renewable Energy Investments</strong>: Companies like Microsoft, Google, and Amazon are investing heavily in renewables. Microsoft’s 10.5 GW deal and Google’s $75 billion AI infrastructure budget signal a shift toward carbon-free energy, though intermittency remains a challenge.<a href="https://www.energypolicy.columbia.edu/projecting-the-electricity-demand-growth-of-generative-ai-large-language-models-in-the-us/"></a><a href="https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/"></a></li>
<li><strong>Nuclear Power Revival</strong>: Hyperscalers are turning to nuclear energy for reliable, high-capacity power. Microsoft’s Three Mile Island deal and Meta’s exploration of nuclear options in Louisiana highlight this trend. Small modular reactors and geothermal energy are also being evaluated.<a href="https://energy.mit.edu/news/the-multi-faceted-challenge-of-powering-ai/"></a><a href="https://www.rand.org/pubs/research_reports/RRA3572-1.html"></a></li>
<li><strong>Energy Efficiency</strong>: Innovations like Google’s 40% reduction in data center energy use through AI-driven cooling and more efficient chips (e.g., DeepSeek’s potential efficiency gains) could mitigate demand growth. Shared data centers and cloud computing can further reduce energy waste.<a href="https://www.weforum.org/stories/2024/04/how-to-manage-ais-energy-demand-today-tomorrow-and-in-the-future/"></a></li>
<li><strong>Grid Flexibility</strong>: Duke University’s report suggests that existing U.S. grid “headroom” could support 100 GW of new data center capacity if consumption is managed during peak hours. This requires data centers to adopt flexible load scheduling.<a href="https://www.cfr.org/blog/america-may-not-need-massive-energy-build-out-power-ai-revolution"></a></li>
</ul>


<a name="Economic-and-Social-Impacts"></a>
<h3>Economic and Social Impacts</h3>

<p><img src="https://rishijeet.github.io/images/2025/Screenshot%202025-07-26%20at%208.46.38%E2%80%AFPM.png" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><strong>Cost Increases</strong>: The $500 billion+ investment in data center infrastructure could lead to higher electricity bills for consumers, as utilities pass on grid upgrade costs. Meta’s Louisiana project, for instance, may raise rates after 15 years if gas turbines remain in use.<a href="https://www.technologyreview.com/2025/05/20/1116272/ai-natural-gas-data-centers-energy-power-plants/"></a></li>
<li><strong>Geopolitical Implications</strong>: If U.S. energy constraints persist, companies may build data centers abroad (e.g., Malaysia), risking national security and AI leadership. Schmidt’s emphasis on energy as a bottleneck underscores the need for domestic investment to maintain competitiveness.<a href="https://www.rand.org/pubs/research_reports/RRA3572-1.html"></a></li>
<li><strong>Environmental Concerns</strong>: AI’s energy demands could double data center carbon emissions by 2030, with a “social cost” of $125-140 billion unless mitigated by renewables or nuclear power. Natural gas plants, planned to meet immediate needs, could lock in emissions for decades.<a href="https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030"></a><a href="https://www.technologyreview.com/2025/05/20/1116272/ai-natural-gas-data-centers-energy-power-plants/"></a></li>
</ul>


<a name="Policy-and-Innovation-Needs"></a>
<h3>Policy and Innovation Needs</h3>

<ul>
<li><strong>Government Action</strong>: President Biden’s Executive Order (January 2025) aims to accelerate AI infrastructure development by leasing federal lands for gigawatt-scale data centers powered by clean energy. The Defense Production Act could address energy shortfalls.<a href="https://rpower1.com/articles/the-power-of-ai-building-the-energy-infrastructure-for-americas-ai-revolution/"></a></li>
<li><strong>Infrastructure Upgrades</strong>: Over $800 billion in transmission and distribution investments are needed in Europe alone, with similar needs in the U.S. to support AI growth.<a href="https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand"></a></li>
<li><strong>Transparency</strong>: Researchers and the IEA call for greater transparency from AI companies on energy consumption to improve planning and mitigate environmental impacts.<a href="https://www.nature.com/articles/d41586-025-00616-z"></a><a href="https://www.iea.org/news/ai-is-set-to-drive-surging-electricity-demand-from-data-centres-while-offering-the-potential-to-transform-how-the-energy-sector-works"></a></li>
</ul>


<a name="Critical-Analysis"></a>
<h2>Critical Analysis</h2>

<ul>
<li><strong>Schmidt’s 92 GW Estimate</strong>: While ambitious, Schmidt’s projection aligns with estimates like RAND’s 68 GW by 2027 and Goldman Sachs’ 100 GW by 2030, though it assumes aggressive AI adoption. Duke University’s claim of existing grid capacity suggests this demand could be met without massive new infrastructure, but only with significant flexibility in data center operations.<a href="https://www.cfr.org/blog/america-may-not-need-massive-energy-build-out-power-ai-revolution"></a><a href="https://www.rand.org/pubs/research_reports/RRA3572-1.html"></a><a href="https://www.goldmansachs.com/insights/articles/ai-to-drive-165-increase-in-data-center-power-demand-by-2030"></a></li>
<li><strong>Uncertainties</strong>: Estimates vary widely due to unpredictable AI efficiency gains (e.g., DeepSeek’s potential), adoption rates, and infrastructure development timelines. Overbuilding natural gas plants risks stranded assets if AI demand slows.<a href="https://www.technologyreview.com/2025/05/20/1116272/ai-natural-gas-data-centers-energy-power-plants/"></a></li>
<li><strong>Environmental Trade-offs</strong>: The reliance on natural gas to meet immediate needs conflicts with zero-carbon goals, potentially locking in emissions for decades. Nuclear and renewable solutions are promising but face scalability and cost challenges.<a href="https://www.technologyreview.com/2025/05/20/1116272/ai-natural-gas-data-centers-energy-power-plants/"></a><a href="https://energy.mit.edu/news/the-multi-faceted-challenge-of-powering-ai/"></a></li>
<li><strong>Data Gaps</strong>: Lack of transparency from companies like OpenAI hinders accurate forecasting. More granular data on training and inference energy use is needed to refine projections.<a href="https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/"></a></li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>The AI revolution, driven by hyperscalers like Microsoft, Google, Meta, Amazon, and OpenAI, is pushing energy demands to unprecedented levels, with current U.S. data center consumption at 4.4% of national electricity and projected to reach 11-12% by 2030. Schmidt’s estimate of an additional 92 GW by 2035 underscores the scale of the challenge, requiring investments in renewables, nuclear power, and grid upgrades. While innovations in efficiency and flexible grid management offer hope, the risk of cost increases, environmental impacts, and geopolitical shifts looms large. To maintain AI leadership and sustainability, the U.S. must prioritize energy infrastructure development, transparency, and strategic policy interventions to balance growth with environmental and economic stability.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[From Text to Tokens: The Complete Guide to Tokenization in LLMs]]></title>
        <link href="https://rishijeet.github.io/blog/from-text-to-tokens-the-complete-guide-to-tokenization-in-llms/"/>
        <updated>2025-06-28T08:55:51+05:30</updated>
        <id>https://rishijeet.github.io/blog/from-text-to-tokens-the-complete-guide-to-tokenization-in-llms</id>
        <content type="html"><![CDATA[<p>In the ever-evolving field of artificial intelligence, large language models (LLMs) like GPT-4, Claude, Gemini, and LLaMA have reshaped how machines understand and generate human language. Behind the impressive capabilities of these models lies a deceptively simple but foundational step: <strong>tokenization</strong>.</p>

<p>In this blog, we will dive deep into the concept of tokenization, understand its types, why it&rsquo;s needed, the challenges it solves, how it works under the hood, and where it’s headed in the future. This is a one-stop technical deep-dive for anyone looking to fully grasp the backbone of language understanding in LLMs.</p>

<hr />

<a name="L-3c-strong-3e-What-is-Tokenization-3f--3c--2f-strong-3e-"></a>
<h2><strong>What is Tokenization?</strong></h2>

<p>At its core, tokenization is the process of converting raw text into smaller units called <strong>tokens</strong> that a language model can understand and process. These tokens can be:</p>

<ul>
<li>Characters</li>
<li>Words</li>
<li>Subwords</li>
<li>Byte-pair sequences</li>
<li>WordPieces</li>
<li>SentencePieces</li>
<li>Byte-level representations</li>
</ul>


<p>Each model has its own strategy, depending on design goals like efficiency, vocabulary size, multilingual handling, and memory constraints.</p>

<!--more-->


<p>For example, the sentence:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>"Tokenization is crucial for LLMs."</span></code></pre></td></tr></table></div></figure>


<p>May be tokenized as:</p>

<ul>
<li>Word-level: <code>["Tokenization", "is", "crucial", "for", "LLMs", "."]</code></li>
<li>Character-level: <code>["T", "o", "k", ..., "L", "L", "M", "s", "."]</code></li>
<li>Subword (BPE): <code>["Token", "ization", "is", "cru", "cial", "for", "LL", "Ms", "."]</code></li>
</ul>


<a name="Tokens"></a>
<h4>Tokens</h4>

<p><img src="https://rishijeet.github.io/images/2025/token.png" height="300" width="900" alt="Alt text" /></p>

<a name="Token-IDs"></a>
<h4>Token IDs</h4>

<p><img src="https://rishijeet.github.io/images/2025/tokenid.png" height="300" width="900" alt="Alt text" /></p>

<hr />

<a name="L-3c-strong-3e-Why-Tokenization-is-Needed-in-LLMs-3c--2f-strong-3e-"></a>
<h2><strong>Why Tokenization is Needed in LLMs</strong></h2>

<p>Language models operate over numbers (tensors), not raw strings. Before any neural network processes your prompt, the words must be:</p>

<ol>
<li><strong>Split into atomic units (tokens)</strong></li>
<li><strong>Mapped to numerical IDs (vocabulary embedding)</strong></li>
<li><strong>Fed into the model as vectors</strong></li>
</ol>


<p>Without tokenization:</p>

<ul>
<li>Models would struggle with infinite vocabulary.</li>
<li>Multilingual text and compound words would explode the vocabulary.</li>
<li>There would be no efficient way to control sequence length or positional encoding.</li>
</ul>


<hr />

<a name="L-3c-strong-3e-Types-of-Tokenization-Strategies-3c--2f-strong-3e-"></a>
<h2><strong>Types of Tokenization Strategies</strong></h2>

<a name="L-3c-strong-3e-Word-2d-Level-Tokenization-3c--2f-strong-3e-"></a>
<h3><strong>Word-Level Tokenization</strong></h3>

<p>Each word is a token. Simple but inefficient for:</p>

<ul>
<li>Unknown words (out-of-vocabulary issues)</li>
<li>Morphologically rich languages</li>
<li>Compound words</li>
</ul>


<p><strong>Example:</strong>
&ldquo;unhappiness&rdquo; → 1 token → [“unhappiness”]
If unseen during training, this is a problem.</p>

<hr />

<a name="L-3c-strong-3e-Character-2d-Level-Tokenization-3c--2f-strong-3e-"></a>
<h3><strong>Character-Level Tokenization</strong></h3>

<p>Each character is a token. Solves OOV issues but leads to longer sequences and loss of semantic granularity.</p>

<p><strong>Example:</strong>
&ldquo;unhappiness&rdquo; → [“u”, “n”, “h”, “a”, “p”, …]</p>

<hr />

<a name="L-3c-strong-3e-Subword-Tokenization-3c--2f-strong-3e-"></a>
<h3><strong>Subword Tokenization</strong></h3>

<p>Breaks words into frequent subword units using statistical techniques like:</p>

<ul>
<li><strong>Byte Pair Encoding (BPE)</strong> – used by GPT-2, GPT-3</li>
<li><strong>WordPiece</strong> – used by BERT</li>
<li><strong>Unigram Language Model</strong> – used by SentencePiece (T5, LLaMA)</li>
</ul>


<p><strong>Example (BPE):</strong>
&ldquo;unhappiness&rdquo; → [“un”, “happi”, “ness”]</p>

<p><strong>Benefits:</strong></p>

<ul>
<li>Handles unknown words gracefully</li>
<li>Reduces vocabulary size</li>
<li>Efficient for multilingual models</li>
</ul>


<hr />

<a name="L-3c-strong-3e-Byte-2d-Level-Tokenization-3c--2f-strong-3e-"></a>
<h3><strong>Byte-Level Tokenization</strong></h3>

<p>Tokenizes text at the byte level, including UTF-8 encodings.</p>

<p>Used by models like GPT-3.5/4 to handle raw binary inputs and emojis robustly.</p>

<p><strong>Example:</strong>
“🔥” → byte sequence → [240, 159, 148, 165]</p>

<hr />

<a name="L-3c-strong-3e-SentencePiece-3c--2f-strong-3e-"></a>
<h3><strong>SentencePiece</strong></h3>

<p>A library that trains subword models using BPE or Unigram LM on raw text. Used in multilingual LLMs like T5, mT5.</p>

<p>It allows training on raw text without pre-tokenization (no need for whitespace-based splitting).</p>

<hr />

<a name="L-3c-strong-3e-How-Tokenization-Works:-Under-the-Hood-3c--2f-strong-3e-"></a>
<h2><strong>How Tokenization Works: Under the Hood</strong></h2>

<a name="L-3c-strong-3e-Training-a-Tokenizer-3c--2f-strong-3e-"></a>
<h3><strong>Training a Tokenizer</strong></h3>

<p>During tokenizer training, the process involves:</p>

<ul>
<li>Reading a large corpus</li>
<li>Building frequency tables of substrings</li>
<li>Iteratively merging the most frequent substrings</li>
<li>Forming a vocabulary of tokens</li>
<li>Saving a tokenizer model (vocab + merge rules)</li>
</ul>


<a name="L-3c-strong-3e-Encoding-3c--2f-strong-3e-"></a>
<h3><strong>Encoding</strong></h3>

<p>At inference or training:</p>

<ul>
<li>Input string → split into substrings based on learned merges</li>
<li>Tokens → mapped to numerical IDs via the vocabulary</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2Tokenizer</span>
</span><span class='line'>
</span><span class='line'><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">&quot;gpt2&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s">&quot;Tokenization is powerful.&quot;</span><span class="p">)</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span><span class='line'><span class="c"># Output: [&#39;Token&#39;, &#39;ization&#39;, &#39;Ġis&#39;, &#39;Ġpowerful&#39;, &#39;.&#39;]</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>Ġ</code> indicates a space in GPT-2 tokenizers.</p>

<hr />

<a name="L-3c-strong-3e-Tokenization-and-Model-Limits-3c--2f-strong-3e-"></a>
<h2><strong>Tokenization and Model Limits</strong></h2>

<p>Most LLMs have a context window defined in <strong>tokens</strong>, not characters. For instance:</p>

<ul>
<li>GPT-3.5: 4,096 tokens</li>
<li>GPT-4 (o4): 128,000 tokens</li>
<li>Claude 3 Opus: \~200,000 tokens</li>
</ul>


<p>So, 1000 words of English ≈ 750 tokens.</p>

<p>This is crucial for prompt design, summarization, RAG (Retrieval Augmented Generation), and efficient inference.</p>

<a name="L-3c-strong-3e-Challenges-and-Trade-2d-offs-3c--2f-strong-3e-"></a>
<h2><strong>Challenges and Trade-offs</strong></h2>

<table style="width:100%; border-collapse: collapse; text-align: left; font-family: sans-serif;">
  <thead style="background-color: #f2f2f2;">
    <tr>
      <th style="border: 1px solid #ddd; padding: 12px;">Challenge</th>
      <th style="border: 1px solid #ddd; padding: 12px;">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">OOV (Out-of-Vocabulary)</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Especially for word-level tokenization</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">Token inflation</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Some languages (e.g., Chinese, Japanese) produce more tokens</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">Inconsistency</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Subword boundaries may not align with morphemes</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">Efficiency vs Accuracy</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Smaller tokens = longer sequences = more compute</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">Encoding Bias</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Tokenizers trained on certain scripts or corpora may underperform on others</td>
    </tr>
  </tbody>
</table>


<a name="L-3c-strong-3e-Tokenization-in-Multilingual-and-Code-Models-3c--2f-strong-3e-"></a>
<h2><strong>Tokenization in Multilingual and Code Models</strong></h2>

<a name="L-3c-strong-3e-Multilingual-Tokenization-3c--2f-strong-3e-"></a>
<h3><strong>Multilingual Tokenization</strong></h3>

<ul>
<li>Unicode-aware models must handle multiple scripts (Latin, Devanagari, Arabic, etc.)</li>
<li>Token inflation can disadvantage languages like Hindi and Tamil</li>
<li>SentencePiece helps standardize across languages</li>
</ul>


<a name="L-3c-strong-3e-Code-Tokenization-3c--2f-strong-3e-"></a>
<h3><strong>Code Tokenization</strong></h3>

<ul>
<li>Code models (e.g., Codex, CodeBERT) often use language-specific tokenizers</li>
<li>Must preserve syntax, spacing, indentation, and even comments</li>
</ul>


<p>Example:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">say_hello</span><span class="p">():</span>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Hello&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>→ <code>[‘def’, ‘Ġsay’, ‘_’, ‘hello’, ‘()’, ‘:’, ‘Ġ’, ‘print’, ‘(”, ‘Hello’, ‘”)’]</code></p>

<hr />

<a name="L-3c-strong-3e-Compression-2c--Prompt-Engineering-2c--and-Token-Optimization-3c--2f-strong-3e-"></a>
<h2><strong>Compression, Prompt Engineering, and Token Optimization</strong></h2>

<p>Tokenization also directly affects:</p>

<ul>
<li><strong>Prompt length limits</strong> (compressed prompts → more room for data)</li>
<li><strong>Token cost in inference/billing</strong></li>
<li><strong>RAG performance</strong> (chunking based on tokens)</li>
<li><strong>Training data deduplication</strong> (token-based hashing)</li>
</ul>


<p>Optimizing prompts for fewer tokens can reduce cost and latency.</p>

<hr />

<a name="L-3c-strong-3e-Tokenization-vs.-Embeddings-3c--2f-strong-3e-"></a>
<h2><strong>Tokenization vs. Embeddings</strong></h2>

<p>It’s important to note:</p>

<ul>
<li><strong>Tokenization</strong> comes before embedding.</li>
<li>Token → token ID → embedding vector</li>
</ul>


<p>A poor tokenization scheme = noisy embeddings = reduced model performance.</p>

<hr />

<a name="L-3c-strong-3e-The-Future-of-Tokenization-in-LLMs-3c--2f-strong-3e-"></a>
<h2><strong>The Future of Tokenization in LLMs</strong></h2>

<a name="L-3c-strong-3e-Token-2d-Free-Models-3c--2f-strong-3e-"></a>
<h3><strong>Token-Free Models</strong></h3>

<p>Efforts like <strong>Charformer</strong> and <strong>Byte-level transformers</strong> aim to bypass static tokenization and learn from raw bytes or characters.</p>

<a name="L-3c-strong-3e-Neural-Tokenization-3c--2f-strong-3e-"></a>
<h3><strong>Neural Tokenization</strong></h3>

<p>Trainable tokenizers using neural nets to learn optimal segmentation dynamically.</p>

<a name="L-3c-strong-3e-Universal-Tokenizers-3c--2f-strong-3e-"></a>
<h3><strong>Universal Tokenizers</strong></h3>

<p>Tokenizers trained across modalities (text, image, code) using a common vocabulary to unify multimodal models.</p>

<a name="L-3c-strong-3e-Efficient-Context-Windows-3c--2f-strong-3e-"></a>
<h3><strong>Efficient Context Windows</strong></h3>

<p>With sliding-window and compression-based methods (e.g., Mamba, Hyena), token overhead may reduce for long contexts.</p>

<hr />

<a name="L-3c-strong-3e-Major-LLMs-and-Their-Tokenization-3c--2f-strong-3e-"></a>
<h2><strong>Major LLMs and Their Tokenization</strong></h2>

<table style="width:100%; border-collapse: collapse; text-align: left; font-family: sans-serif;">
  <thead style="background-color: #f2f2f2;">
    <tr>
      <th style="border: 1px solid #ddd; padding: 12px;">Model</th>
      <th style="border: 1px solid #ddd; padding: 12px;">Tokenizer</th>
      <th style="border: 1px solid #ddd; padding: 12px;">Type</th>
      <th style="border: 1px solid #ddd; padding: 12px;">Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">GPT-3/4</td>
      <td style="border: 1px solid #ddd; padding: 12px;">GPT2Tokenizer</td>
      <td style="border: 1px solid #ddd; padding: 12px;">BPE + byte</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Handles Unicode well</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">BERT</td>
      <td style="border: 1px solid #ddd; padding: 12px;">WordPiece</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Subword</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Requires pre-tokenization</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">RoBERTa</td>
      <td style="border: 1px solid #ddd; padding: 12px;">BPE (FairSeq)</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Subword</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Custom vocabulary</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">T5</td>
      <td style="border: 1px solid #ddd; padding: 12px;">SentencePiece</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Unigram LM</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Whitespace-free tokenization</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">LLaMA 2/3/4</td>
      <td style="border: 1px solid #ddd; padding: 12px;">SentencePiece</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Unigram LM</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Supports multiple languages</td>
    </tr>
    <tr>
      <td style="border: 1px solid #ddd; padding: 12px;">Claude</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Byte-level BPE</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Proprietary</td>
      <td style="border: 1px solid #ddd; padding: 12px;">Handles emojis and long context</td>
    </tr>
  </tbody>
</table>


<hr />

<a name="L-3c-strong-3e-Conclusion-3c--2f-strong-3e-"></a>
<h2><strong>Conclusion</strong></h2>

<p>Tokenization may appear trivial at first glance, but it&rsquo;s the hidden workhorse powering the language capabilities of every modern LLM. From enabling multilingual understanding to compressing long documents into tight prompts, tokenization determines what the model sees, learns, and generates.</p>

<p>As we step into an era of 1M+ token context windows, modality fusion, and instruction-following agents, tokenization will either evolve or be replaced by more fluid, learned representations.</p>

<p>But for now—and the foreseeable future—it remains a vital piece of the LLM puzzle.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Electric Illusion: The Rise and Fall of BluSmart]]></title>
        <link href="https://rishijeet.github.io/blog/electric-illusion-the-rise-and-fall-of-blusmart/"/>
        <updated>2025-06-15T20:38:26+05:30</updated>
        <id>https://rishijeet.github.io/blog/electric-illusion-the-rise-and-fall-of-blusmart</id>
        <content type="html"><![CDATA[<p>BluSmart was once a symbol of India&rsquo;s clean energy aspirations — an all-electric ride-hailing platform backed by marquee investors and government lenders. With its zero-emissions fleet and no-surge pricing model, it quickly gained popularity in cities like Delhi and Bengaluru.</p>

<p>But behind the scenes, the startup’s success story unraveled into one of the most serious corporate fraud cases in India’s startup ecosystem. At the center of this financial maze was <strong>Gensol Engineering Ltd</strong>, a publicly listed company, controlled by the same promoters behind BluSmart. The ₹262 crore scandal that emerged in 2025 now implicates not just BluSmart, but Gensol’s board, finances, and investors.</p>

<p><img src="https://rishijeet.github.io/images/2025/blusmart-logo.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<!--more-->


<a name="L-3c-strong-3e-BluSmart-e2--80--99-s-Meteoric-Rise-3c--2f-strong-3e-"></a>
<h3><strong>BluSmart’s Meteoric Rise</strong></h3>

<p>Founded in 2019, BluSmart positioned itself as India’s first all-electric ride-hailing startup. The platform scaled rapidly:</p>

<ul>
<li><strong>Fleet</strong>: 8,000+ electric vehicles by 2024</li>
<li><strong>Coverage</strong>: Operational in Delhi-NCR, Mumbai, and Bengaluru</li>
<li><strong>Funding</strong>: ₹486+ crore in equity and ₹978 crore in loans from government-owned lenders</li>
<li><strong>Backers</strong>: BP Ventures, Mayfield Fund, and IREDA &amp; PFC via Gensol Engineering</li>
</ul>


<p>BluSmart&rsquo;s asset-light model hinged on one key arrangement — vehicle procurement and leasing handled by <strong>Gensol EV Lease Pvt Ltd</strong>, a subsidiary of <strong>Gensol Engineering Ltd</strong>, which was also promoted by the Jaggi brothers.</p>

<p>This relationship became the foundation of the scandal.</p>

<hr />

<a name="L-3c-strong-3e-How-Gensol-Became-the-Nexus-of-Fund-Diversion-3c--2f-strong-3e-"></a>
<h3><strong>How Gensol Became the Nexus of Fund Diversion</strong></h3>

<p>Gensol Engineering Ltd, listed on the Indian stock exchange, was the entity through which public sector lenders like <strong>IREDA</strong> (Indian Renewable Energy Development Agency) and <strong>PFC</strong> (Power Finance Corporation) disbursed nearly ₹978 crore in loans for electric vehicle procurement.</p>

<p>Here&rsquo;s how the misuse played out:</p>

<a name="L1.--3c-strong-3e-Conflict-of-Interest-3c--2f-strong-3e-"></a>
<h4>1. <strong>Conflict of Interest</strong></h4>

<p>Anmol and Puneet Jaggi held leadership roles in both <strong>BluSmart</strong> and <strong>Gensol</strong>. This dual control allowed them to shift funds and assets across entities without independent checks. While Gensol was meant to procure and lease EVs to BluSmart, the actual disbursement and usage of funds were poorly documented.</p>

<a name="L2.--3c-strong-3e-Falsified-Board-Resolutions-3c--2f-strong-3e-"></a>
<h4>2. <strong>Falsified Board Resolutions</strong></h4>

<p>SEBI’s investigation revealed that board resolutions submitted to justify fund transfers from Gensol to other entities were <strong>forged</strong>. These resolutions claimed shareholder or board approvals that never took place.</p>

<a name="L3.--3c-strong-3e-Diversion-of-Funds-3c--2f-strong-3e-"></a>
<h4>3. <strong>Diversion of Funds</strong></h4>

<p>Out of the ₹978 crore loan sanctioned to Gensol for 6,400 EVs:</p>

<ul>
<li>Only <strong>4,704 EVs</strong> were procured.</li>
<li>Over <strong>₹262 crore</strong> could not be accounted for.</li>
<li><p>Some funds were redirected to purchase <strong>personal assets</strong>, including:</p>

<ul>
<li>A ₹50 crore luxury apartment at DLF Camellias, Gurugram</li>
<li>Golf equipment worth ₹26 lakh</li>
<li>Foreign trips and personal company expenses</li>
<li>Transfers to family members and promoter-controlled entities</li>
</ul>
</li>
</ul>


<a name="L4.--3c-strong-3e-Blurring-the-Lines-3c--2f-strong-3e-"></a>
<h4>4. <strong>Blurring the Lines</strong></h4>

<p>Because Gensol was the lender-facing entity and BluSmart was the consumer-facing app, the two were treated as distinct. However, in reality, the same core leadership ran both. This lack of separation allowed for:</p>

<ul>
<li>Overreporting of assets</li>
<li>Misleading investor communications</li>
<li>Obscuring of fund flows between listed and private companies</li>
</ul>


<a name="L5.--3c-strong-3e-Impact-on-Public-Markets-3c--2f-strong-3e-"></a>
<h4>5. <strong>Impact on Public Markets</strong></h4>

<p>Gensol Engineering’s stock plummeted over 85% following SEBI&rsquo;s interim order. Investors who trusted the company’s renewable energy mission were blindsided by its role in enabling a startup’s financial misconduct.</p>

<hr />

<a name="L-3c-strong-3e-Timeline-of-Events-3c--2f-strong-3e-"></a>
<h3><strong>Timeline of Events</strong></h3>

<div class="timeline-container">
  <div class="timeline">
    <div class="timeline-event">
      <div class="timeline-date">2019</div>
      <div class="timeline-content">BluSmart founded by Anmol and Puneet Jaggi</div>
    </div>
    <div class="timeline-event">
      <div class="timeline-date">2021–2024</div>
      <div class="timeline-content">₹978 crore disbursed to Gensol for EV procurement</div>
    </div>
    <div class="timeline-event">
      <div class="timeline-date">April 15, 2025</div>
      <div class="timeline-content">SEBI interim order reveals ₹262 crore fund diversion via Gensol</div>
    </div>
    <div class="timeline-event">
      <div class="timeline-date">April 17, 2025</div>
      <div class="timeline-content">BluSmart halts operations across all cities</div>
    </div>
    <div class="timeline-event">
      <div class="timeline-date">May 2025</div>
      <div class="timeline-content">Grant Thornton appointed for forensic audit of Gensol and BluSmart</div>
    </div>
    <div class="timeline-event">
      <div class="timeline-date">June 2025</div>
      <div class="timeline-content">Delhi High Court orders seizure of over 700 EVs leased by Gensol to BluSmart</div>
    </div>
  </div>
</div>




<style>
.timeline-container {
  max-width: 1000px;
  margin: 10px auto;
  padding: 20px;
  font-family: &#8216;Segoe UI&#8217;, sans-serif;
}

.timeline {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-between;
  border-left: 4px solid #049CDB;
  padding-left: 20px;
  position: relative;
}

.timeline-event {
  position: relative;
  width: 100%;
  margin-bottom: 30px;
  padding-left: 20px;
}

.timeline-event::before {
  content: &#8221;;
  position: absolute;
  left: -12px;
  top: 8px;
  background-color: #049CDB;
  border: 3px solid white;
  border-radius: 50%;
  height: 16px;
  width: 16px;
  z-index: 1;
}

.timeline-date {
  font-weight: bold;
  font-size: 16px;
  color: #049CDB;
  margin-bottom: 5px;
}

.timeline-content {
  background: #f8f9fa;
  padding: 12px 16px;
  border-left: 4px solid #049CDB;
  border-radius: 6px;
  box-shadow: 0 2px 4px rgba(0,0,0,0.05);
}
</style>


<hr />

<a name="L-3c-strong-3e-Consequences-of-the-Scam-3c--2f-strong-3e-"></a>
<h3><strong>Consequences of the Scam</strong></h3>

<p><strong>Investors and Markets</strong></p>

<ul>
<li>Gensol’s credibility as a listed renewable energy company is under threat.</li>
<li>Public lenders like PFC and IREDA face scrutiny for failing to detect misuse earlier.</li>
</ul>


<p><strong>Regulatory Oversight</strong></p>

<ul>
<li>SEBI’s action has prompted tighter surveillance of related-party transactions in startups.</li>
<li>The Ministry of Corporate Affairs (MCA) is reviewing whether more stringent cross-holding disclosures are required for startups using public debt.</li>
</ul>


<p><strong>Drivers and Users</strong></p>

<ul>
<li>Over 10,000 drivers, mostly from underserved backgrounds, lost income overnight.</li>
<li>BluSmart customers are still awaiting wallet refunds or app updates.</li>
</ul>


<p><strong>Future of BluSmart</strong></p>

<ul>
<li>Talks of reviving the company via an independent board or acquisition have emerged.</li>
<li>Some investors, including BP Ventures, may pursue legal action to recover their equity.</li>
</ul>


<hr />

<a name="L-3c-strong-3e-Lessons-from-Gensol-e2--80--93-BluSmart-Case-3c--2f-strong-3e-"></a>
<h3><strong>Lessons from Gensol–BluSmart Case</strong></h3>

<div class="lessons-section">
  <div class="lessons-grid">
    <div class="lesson-card">
      <h3 class="issue-title">Dual Leadership in Public/Private Firms</h3>
      <p class="lesson-text">Strong boundaries between promoter-led entities are essential.</p>
    </div>
    <div class="lesson-card">
      <h3 class="issue-title">Lack of Board Independence</h3>
      <p class="lesson-text">Board members should be empowered to question and audit all fund movements.</p>
    </div>
    <div class="lesson-card">
      <h3 class="issue-title">Weak Internal Controls</h3>
      <p class="lesson-text">Statutory audits must detect and flag multi-crore diversions early.</p>
    </div>
    <div class="lesson-card">
      <h3 class="issue-title">Misuse of Public Money</h3>
      <p class="lesson-text">Lending institutions need better tracking for disbursed capital.</p>
    </div>
  </div>
</div>




<style>
.lessons-section {
  max-width: 1100px;
  margin: 10px auto;
  padding: 20px;
  font-family: &#8216;Segoe UI&#8217;, sans-serif;
}


.lessons-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
  gap: 20px;
}

.lesson-card {
  border-left: 5px solid #049CDB;
  padding: 20px;
  border-radius: 8px;
  box-shadow: 0 2px 6px rgba(0,0,0,0.08);
  transition: transform 0.2s;
}

.lesson-card:hover {
  transform: translateY(-4px);
}

.issue-title {
  font-size: 18px;
  font-weight: bold;
  color: #049CDB;
  margin-bottom: 10px;
}

.lesson-text {
  font-size: 16px;
  color: #444;
  line-height: 1.5;
}
</style>


<hr />

<a name="L-3c-strong-3e-Conclusion-3c--2f-strong-3e-"></a>
<h3><strong>Conclusion</strong></h3>

<p>The BluSmart-Gensol scandal underscores a critical truth: governance is not optional. Innovation, sustainability, and market expansion are meaningless if built on opaque finances and related-party secrecy.</p>

<p>Gensol’s role in the BluSmart collapse shows how a listed company can be used as a conduit for private ambition if oversight is weak. As India’s startup ecosystem matures, this case should serve as a clear signal — accountability must scale along with vision.</p>

<p>BluSmart’s fall was not due to a lack of market demand or poor technology. It failed because of misaligned ethics, enabled by a public company that chose opacity over integrity.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[FTX Scandal 2023: Timeline, Facts, and Key Players]]></title>
        <link href="https://rishijeet.github.io/blog/ftx-scandal-2023-timeline/"/>
        <updated>2025-06-14T13:49:37+05:30</updated>
        <id>https://rishijeet.github.io/blog/ftx-scandal-2023-timeline</id>
        <content type="html"><![CDATA[<p>In the annals of modern financial history, few names have sparked as much controversy, disbelief, and chaos as <em>Futures Exchange (FTX)</em>. Once hailed as a shining star of the cryptocurrency world, FTX’s meteoric rise and catastrophic fall stunned investors, regulators, and the general public alike. By the end of 2023, the scandal surrounding FTX and its founder Sam Bankman-Fried had cemented its place as one of the largest and most complex financial frauds of the 21st century.</p>

<p>This blog dives into the rise and fall of FTX, examining the events that led to its collapse, the financial and human toll it took, and the key takeaways from a debacle that shook the entire crypto industry to its core.</p>

<p><img src="https://rishijeet.github.io/images/2025/ftx.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<hr />

<a name="The-Rise-of-FTX:-From-Start-2d-up-to-Crypto-Juggernaut"></a>
<h3>The Rise of FTX: From Start-up to Crypto Juggernaut</h3>

<p>FTX was founded in 2019 by Sam Bankman-Fried (commonly referred to as SBF), a former Wall Street quant with a background from MIT and a reputation for genius-level intellect. The exchange was created as a more sophisticated platform for cryptocurrency derivatives and quickly attracted traders looking for advanced features, high leverage, and innovative products.</p>

<p>By 2021, FTX had:</p>

<ul>
<li>Raised over <strong>\$1.8 billion</strong> from prominent investors including Sequoia Capital, SoftBank, and Tiger Global.</li>
<li>Claimed <strong>over 1 million users</strong> and processed billions of dollars in trades daily.</li>
<li>Achieved a staggering <strong>\$32 billion valuation</strong>, making it the <strong>third-largest crypto exchange</strong> globally.</li>
</ul>


<p>SBF’s influence extended well beyond the company. He was a frequent guest on financial talk shows, lobbied in Washington, and was dubbed the “JP Morgan of crypto” after bailing out other struggling crypto firms in 2022. But behind the charismatic image and philanthropic posturing was a house of cards waiting to collapse.</p>

<!--more-->


<p><img src="https://rishijeet.github.io/images/2025/ftx_revenue.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<hr />

<a name="The-Fall-Begins:-A-Leak-2c--a-Tweet-2c--and-a-Run-on-the-Bank"></a>
<h3>The Fall Begins: A Leak, a Tweet, and a Run on the Bank</h3>

<p>The trigger came in <strong>early November 2022</strong>, when <em>CoinDesk</em> published a leaked balance sheet from Alameda Research, a trading firm closely tied to FTX and also founded by SBF. The leak revealed that:</p>

<ul>
<li><strong>\$5.8 billion</strong> of Alameda’s assets were in <strong>FTT</strong>, the native token issued by FTX.</li>
<li>A large portion of Alameda&rsquo;s balance sheet was illiquid and backed by FTT, suggesting FTX and Alameda were dangerously intertwined.</li>
</ul>


<p>This revelation sparked panic in the market. <strong>Binance</strong>, FTX’s main rival, announced it would liquidate its <strong>\$530 million</strong> worth of FTT holdings.</p>

<p><img src="https://rishijeet.github.io/images/2025/FTX_token_price.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>What followed was a textbook “run on the bank.” Within <strong>72 hours</strong>, FTX customers tried to withdraw <strong>\$6 billion</strong>, exposing the exchange’s inability to meet withdrawal demands. On <strong>November 11, 2022</strong>, FTX, Alameda Research, and over 130 related entities filed for bankruptcy.</p>

<hr />

<a name="The-Aftermath:-Bankruptcy-2c--Arrests-2c--and-a-Trial"></a>
<h3>The Aftermath: Bankruptcy, Arrests, and a Trial</h3>

<p>The bankruptcy filings laid bare the chaos within FTX:</p>

<ul>
<li>An estimated <strong>\$8–10 billion</strong> in customer funds were <strong>missing</strong>.</li>
<li>FTX had <strong>no proper financial records</strong>, and assets were reportedly tracked in <strong>QuickBooks</strong>, a tool meant for small businesses.</li>
<li>The new CEO, <strong>John J. Ray III</strong> (who previously oversaw Enron’s liquidation), called FTX&rsquo;s management the worst he’d seen in his 40-year career.</li>
</ul>


<p>In <strong>December 2022</strong>, SBF was arrested in the Bahamas and extradited to the U.S. He was charged with <strong>eight counts</strong> of fraud, money laundering, and campaign finance violations.</p>

<p>During the 2023 trial:</p>

<ul>
<li>Testimonies from former FTX executives (including Caroline Ellison, CEO of Alameda and SBF’s former girlfriend) revealed deliberate misappropriation of customer funds.</li>
<li>Prosecutors showed that billions were siphoned from FTX to fund Alameda’s risky bets, luxury real estate, political donations (over <strong>\$90 million</strong>), and personal expenses.</li>
</ul>


<p>In <strong>November 2023</strong>, Sam Bankman-Fried was found <strong>guilty on all counts</strong>, facing a potential sentence of over <strong>110 years</strong> in prison. His sentencing is scheduled for <strong>March 2024</strong>.</p>

<hr />

<a name="The-Numbers-That-Define-the-Collapse"></a>
<h3>The Numbers That Define the Collapse</h3>

<style>
  .ftx-table {
    width: 100%;
    border-collapse: collapse;
    margin: 20px 0;
    font-family: Arial, sans-serif;
    font-size: 16px;
  }

  .ftx-table th, .ftx-table td {
    border: 1px solid #ddd;
    padding: 12px 16px;
    text-align: left;
  }

  .ftx-table th {
    background-color: #f4f4f4;
    font-weight: bold;
  }

  .ftx-table tr:nth-child(even) {
    background-color: #f9f9f9;
  }

  .ftx-table tr:hover {
    background-color: #f1f1f1;
  }
</style>




<table class="ftx-table">
  <thead>
    <tr>
      <th>Metric</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Peak Valuation of FTX</td>
      <td>$32 billion</td>
    </tr>
    <tr>
      <td>Customer Funds Missing</td>
      <td>~$8–10 billion</td>
    </tr>
    <tr>
      <td>Number of Users Affected</td>
      <td>Over 1 million</td>
    </tr>
    <tr>
      <td>Political Donations by SBF</td>
      <td>$90 million+</td>
    </tr>
    <tr>
      <td>Real Estate Purchases</td>
      <td>$300 million+</td>
    </tr>
    <tr>
      <td>Alameda Loan to SBF</td>
      <td>$1 billion+</td>
    </tr>
    <tr>
      <td>Legal and Bankruptcy Costs</td>
      <td>Estimated $200 million+</td>
    </tr>
  </tbody>
</table>


<hr />

<a name="Broader-Impact-on-Crypto-and-Beyond"></a>
<h3>Broader Impact on Crypto and Beyond</h3>

<p>FTX’s collapse sent shockwaves through the crypto ecosystem:</p>

<ul>
<li>Prices of major cryptocurrencies like Bitcoin and Ethereum dropped over <strong>20%</strong> in the weeks following the collapse.</li>
<li>Several crypto lending platforms and hedge funds with FTX exposure, including <strong>Genesis</strong> and <strong>BlockFi</strong>, filed for bankruptcy.</li>
<li>Investors lost trust in centralized exchanges, pushing many toward <strong>cold wallets</strong> and <strong>DeFi platforms</strong>.</li>
</ul>


<p>Regulators responded swiftly:</p>

<ul>
<li>U.S. Congress held hearings on crypto regulation.</li>
<li>The SEC and CFTC vowed tighter oversight of crypto platforms.</li>
<li>Discussions began around creating a federal framework for <strong>crypto custodianship</strong> and <strong>proof-of-reserves</strong>.</li>
</ul>


<hr />

<a name="Lessons-from-the-FTX-Scandal"></a>
<h3>Lessons from the FTX Scandal</h3>

<ol>
<li><p><strong>Charisma is not competence</strong>
SBF’s charm, intelligence, and philanthropic front masked serious mismanagement and fraudulent practices.</p></li>
<li><p><strong>Regulatory gaps need closing</strong>
FTX operated in a regulatory gray zone, exploiting jurisdictional loopholes to avoid scrutiny.</p></li>
<li><p><strong>Centralization without accountability is dangerous</strong>
Despite being a crypto exchange, FTX was run like a black box. There were no independent board members or external audits.</p></li>
<li><p><strong>Always follow the money</strong>
The FTX saga revealed the ease with which customer funds could be co-mingled and misused in the absence of checks and balances.</p></li>
</ol>


<hr />

<a name="Final-Thoughts"></a>
<h3>Final Thoughts</h3>

<p>FTX was not just a crypto story—it was a human story of unchecked power, blind trust, and systemic failure. It shook investor confidence and became a harsh reminder that, even in the futuristic world of blockchain, age-old rules of governance, transparency, and ethics cannot be ignored.</p>

<p>As the crypto industry tries to rebuild in the wake of this collapse, FTX will stand as a cautionary tale—a reminder that even billion-dollar empires can crumble when built on deception.</p>

<p>Let this not just be history, but a lesson for the future.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Smartcase Engine: A Modern Framework for Intelligent Case Management]]></title>
        <link href="https://rishijeet.github.io/blog/smartcase-engine-a-modern-framework-for-intelligent-case-management/"/>
        <updated>2025-05-27T22:54:42+05:30</updated>
        <id>https://rishijeet.github.io/blog/smartcase-engine-a-modern-framework-for-intelligent-case-management</id>
        <content type="html"><![CDATA[<p>In today&rsquo;s dynamic business environment, efficient case management is paramount. Enter <a href="https://github.com/rishijeet/smartcase-engine">Smartcase Engine</a>, an advanced case management framework designed to streamline complex case handling through real-time tracking, efficient workflows, and automated decision-making processes.</p>

<a name="What-is-Smartcase-Engine-3f-"></a>
<h2>What is Smartcase Engine?</h2>

<p>Smartcase Engine is a modular, microservices-based platform tailored for managing intricate case workflows. It offers:</p>

<ul>
<li><strong>Real-Time Case Tracking</strong>: Monitor cases as they progress through various stages.</li>
<li><strong>Efficient Workflows</strong>: Automate and optimize the sequence of tasks involved in case resolution.</li>
<li><strong>Automated Decision-Making</strong>: Leverage predefined rules and AI to make informed decisions without manual intervention.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/smartcase_engine.png" height="300" width="900" alt="Alt text" /><em>Source: <a href="https://github.com/rishijeet/smartcase-engine">Rishijeet Mishra&rsquo;s Blog</a></em></p>

<!--more-->


<a name="Deep-Dive:-Smartcase-Engine-Architecture"></a>
<h2>Deep Dive: Smartcase Engine Architecture</h2>

<p>At the heart of Smartcase Engine is a clean, extensible <strong>microservices-based architecture</strong> designed to support complex workflows in case/dispute management scenarios. The system is broken into discrete services that communicate via REST APIs and Kafka for event-driven interactions. This modular approach allows teams to scale and evolve components independently.</p>

<p>Let’s explore the core services that power this engine:</p>

<hr />

<a name="L-3c-strong-3e-Dispute-Intake-Service-3c--2f-strong-3e-"></a>
<h3><strong>Dispute Intake Service</strong></h3>

<p><strong>Purpose</strong>: This is the gateway to the system — the service responsible for accepting new cases or disputes.</p>

<p><strong>Responsibilities</strong>:</p>

<ul>
<li>Receive new dispute cases via API or event (Kafka).</li>
<li>Validate and enrich the incoming payload.</li>
<li>Generate a unique dispute ID.</li>
<li>Store initial metadata and emit an event to kick off downstream workflow.</li>
</ul>


<p><strong>Technical Highlights</strong>:</p>

<ul>
<li>Built using Java + Quarkus for lightweight runtime.</li>
<li>Connects to Kafka for emitting intake-completed events.</li>
<li>Persists initial data in a database (e.g., PostgreSQL or any pluggable DB).</li>
<li>Implements REST endpoints for manual intake testing or system integration.</li>
</ul>


<p><strong>Why it matters</strong>:
This service ensures that all disputes entering the system are properly structured and immediately traceable — forming the root of all subsequent orchestration.</p>

<hr />

<a name="L-3c-strong-3e-Dispute-Workflow-Service-3c--2f-strong-3e-"></a>
<h3><strong>Dispute Workflow Service</strong></h3>

<p><strong>Purpose</strong>: This is the <em>brain</em> of the engine, orchestrating the lifecycle of a dispute across multiple business stages.</p>

<p><strong>Responsibilities</strong>:</p>

<ul>
<li>Define and manage the state machine (or BPMN-style flow) for a dispute.</li>
<li>Trigger actions based on status updates (e.g., escalate, resolve, pause).</li>
<li>Call external services when required (e.g., fetch additional metadata, update agent queue).</li>
<li>Track state transitions and support retries/failures.</li>
</ul>


<p><strong>Technical Highlights</strong>:</p>

<ul>
<li>Uses a stateless orchestration model.</li>
<li>Integration with Kafka allows event-driven step progression.</li>
<li>Could be integrated with BPMN engines (like Camunda or Flowable) for visual modeling.</li>
</ul>


<p><strong>Why it matters</strong>:
This is the system&rsquo;s core engine. It allows Smartcase to define complex, non-linear workflows without hardcoding logic into the intake or agent UI layers.</p>

<hr />

<a name="L-3c-strong-3e-Dispute-Classification-Service-3c--2f-strong-3e-"></a>
<h3><strong>Dispute Classification Service</strong></h3>

<p><strong>Purpose</strong>: Adds intelligence to the process by classifying disputes into appropriate categories.</p>

<p><strong>Responsibilities</strong>:</p>

<ul>
<li>Use business rules or ML models to assign dispute types (e.g., &ldquo;billing error&rdquo;, &ldquo;fraud&rdquo;, &ldquo;product defect&rdquo;).</li>
<li>Optionally flag high-risk or high-priority disputes.</li>
<li>Feed classification results back into the workflow service to route the case accordingly.</li>
</ul>


<p><strong>Technical Highlights</strong>:</p>

<ul>
<li>Stateless classification service.</li>
<li>Integrates with a basic rule engine or external ML service (could be backed by Python/ONNX, or a local inference server).</li>
<li>Input: structured dispute metadata. Output: classification code or tag.</li>
</ul>


<p><strong>Why it matters</strong>:
Classification drives automation. By programmatically tagging and triaging disputes, Smartcase avoids human bottlenecks and supports intelligent queue assignment.</p>

<hr />

<a name="L-3c-strong-3e-Agent-UI-Service-3c--2f-strong-3e-"></a>
<h3><strong>Agent UI Service</strong></h3>

<p><strong>Purpose</strong>: The interface between human agents and the system.</p>

<p><strong>Responsibilities</strong>:</p>

<ul>
<li>Display dispute data and current status.</li>
<li>Allow agents to take actions (e.g., approve, reject, escalate).</li>
<li>Show workflow progression.</li>
<li>Track comments, attachments, and communication logs.</li>
</ul>


<p><strong>Technical Highlights</strong>:</p>

<ul>
<li>Frontend (typically in React or Angular).</li>
<li>Backend proxy or BFF layer in Quarkus serving data via REST.</li>
<li>Authenticated access with role-based views (agent, supervisor, auditor).</li>
<li>Pagination, search, filters, and sort capabilities to handle large volumes.</li>
</ul>


<p><strong>Why it matters</strong>:
No matter how automated the backend is, disputes often need human judgment. This UI is purpose-built for efficiency and transparency in resolution workflows.</p>

<hr />

<a name="L-3c-strong-3e-Dispute-Common-Module-3c--2f-strong-3e-"></a>
<h3><strong>Dispute Common Module</strong></h3>

<p><strong>Purpose</strong>: A shared library of core utilities and contracts.</p>

<p><strong>Responsibilities</strong>:</p>

<ul>
<li>Define POJOs (Plain Old Java Objects) and DTOs (Data Transfer Objects).</li>
<li>Common validation logic.</li>
<li>Central configuration definitions.</li>
<li>Shared Kafka event schema.</li>
<li>Error handling standards and API response models.</li>
</ul>


<p><strong>Technical Highlights</strong>:</p>

<ul>
<li>Packaged as a reusable JAR.</li>
<li>Imported by all services as a dependency.</li>
<li>Promotes DRY principles and API consistency.</li>
</ul>


<p><strong>Why it matters</strong>:
Microservices need to stay loosely coupled — but shared types and utilities must remain consistent. This module enforces a standard language across the ecosystem.</p>

<hr />

<a name="Optional-Add-2d-ons--28-Future-Ready-29-"></a>
<h3>Optional Add-ons (Future Ready)</h3>

<p>Depending on your scale and use case, Smartcase Engine can be extended with:</p>

<ul>
<li><strong>Notification Service</strong>: For sending SMS/email alerts to users or agents.</li>
<li><strong>Audit Logging</strong>: For compliance with financial or legal audits.</li>
<li><strong>Retry/Dead-letter Queue Mechanism</strong>: To gracefully handle transient failures.</li>
<li><strong>Observability Tools</strong>: Integrated with Prometheus, Grafana, and OpenTelemetry for distributed tracing.</li>
</ul>


<hr />

<a name="Deployment-and-Setup"></a>
<h2>Deployment and Setup</h2>

<p>Smartcase Engine is containerized using Docker, facilitating seamless deployment. Key scripts and configurations include:</p>

<ul>
<li><strong>Dockerfile</strong>: Defines the environment for each microservice.</li>
<li><strong>docker-compose.yml</strong>: Orchestrates multi-container deployments for local development and testing.</li>
<li><strong>build-and-deploy.sh</strong>: Automates the build and deployment process.</li>
<li><strong>start-services.sh</strong>: Initiates all services concurrently.</li>
</ul>


<p>To get started:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>git clone https://github.com/rishijeet/smartcase-engine.git
</span><span class='line'><span class="nb">cd </span>smartcase-engine
</span><span class='line'>chmod +x build-and-deploy.sh start-services.sh
</span><span class='line'>./build-and-deploy.sh
</span><span class='line'>./start-services.sh
</span></code></pre></td></tr></table></div></figure>


<a name="Testing-and-Validation"></a>
<h2>Testing and Validation</h2>

<p>Each microservice includes unit and integration tests to ensure reliability. The modular design allows for isolated testing, simplifying debugging and maintenance.</p>

<a name="Potential-Use-Cases"></a>
<h2>Potential Use Cases</h2>

<p>Smartcase Engine&rsquo;s versatility makes it suitable for various domains:</p>

<ul>
<li><strong>Financial Services</strong>: Automating dispute resolutions in banking and insurance.</li>
<li><strong>Customer Support</strong>: Managing customer complaints and service requests.</li>
<li><strong>Legal Case Management</strong>: Tracking legal cases, evidence, and proceedings.</li>
<li><strong>Healthcare</strong>: Handling patient grievances and administrative cases.</li>
</ul>


<a name="Contributing-to-Smartcase-Engine"></a>
<h2>Contributing to Smartcase Engine</h2>

<p>The project welcomes contributions from the developer community. To contribute:</p>

<ol>
<li>Fork the repository.</li>
<li>Create a new branch for your feature or bugfix.</li>
<li>Ensure code quality by running existing tests and adding new ones if necessary.</li>
<li>Submit a pull request with a clear description of your changes.</li>
</ol>


<a name="Further-Reading"></a>
<h2>Further Reading</h2>

<p>For more in-depth information:</p>

<ul>
<li><a href="https://github.com/rishijeet/smartcase-engine">Smartcase Engine GitHub Repository</a></li>
<li><a href="https://martinfowler.com/articles/microservices.html">Microservices Architecture</a></li>
<li><a href="https://docs.docker.com/">Docker Documentation</a></li>
<li><a href="https://www.omg.org/bpmn/">BPMN Standards</a></li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Smartcase Engine exemplifies how modern architectural principles can be harnessed to build robust, scalable, and efficient case management systems. Whether you&rsquo;re looking to streamline dispute resolutions or manage complex workflows, Smartcase Engine offers a solid foundation to build upon.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Model Context Protocol (MCP): The Backbone of Dynamic AI Workflows]]></title>
        <link href="https://rishijeet.github.io/blog/model-context-protocol-mcp-the-backbone-of-dynamic-ai-workflows/"/>
        <updated>2025-04-08T23:14:14+05:30</updated>
        <id>https://rishijeet.github.io/blog/model-context-protocol-mcp-the-backbone-of-dynamic-ai-workflows</id>
        <content type="html"><![CDATA[<p>As the AI landscape rapidly evolves, the demand for systems that support <strong>modular</strong>, <strong>context-aware</strong>, and <strong>efficient orchestration</strong> of models has grown. Enter the <strong>Model Context Protocol (MCP)</strong> — a rising standard that enables dynamic, multi-agent AI systems to exchange context, manage state, and chain model invocations intelligently.</p>

<p>In this article, we’ll explore what MCP is, why it matters, and how it’s becoming a key component in the infrastructure stack for advanced AI applications. We’ll also walk through a conceptual example of building an MCP-compatible server.</p>

<a name="What-is-the-Model-Context-Protocol--28-MCP-29--3f-"></a>
<h2>What is the Model Context Protocol (MCP)?</h2>

<p><strong>MCP</strong> is a protocol designed to manage the <strong>contextual state</strong> of AI models across requests in multi-agent, multi-model environments. It’s part of a broader effort to make LLMs (Large Language Models) more <strong>stateful</strong>, <strong>collaborative</strong>, and <strong>task-aware</strong>.</p>

<p>At its core, MCP provides:</p>

<ul>
<li>A way to <strong>pass and maintain context</strong> (like conversation history, task progress, or shared knowledge) across AI agents or model calls.</li>
<li>A standardized protocol to support <strong>chained inference</strong>, where multiple models collaborate on subtasks.</li>
<li>Support for <strong>stateful computation</strong>, which is critical in complex reasoning or long-running workflows.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/mcp_server" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<!--more-->


<a name="Why-is-MCP-Relevant-Now-3f-"></a>
<h2>Why is MCP Relevant Now?</h2>

<p>The growing interest in <strong>AI agents</strong>, <strong>function-calling APIs</strong>, and <strong>model interoperability</strong> has created a pressing need for something like MCP. Some trends driving MCP adoption include:</p>

<style>
  .trend-impact-table {
    width: 100%;
    border-collapse: collapse;
    font-family: Arial, sans-serif;
  }
  .trend-impact-table th,
  .trend-impact-table td {
    text-align: left;
    padding: 12px;
    border-bottom: 1px solid #ccc;
    vertical-align: top;
  }
  .trend-impact-table th {
    background-color: #f2f2f2;
    width: 25%;
  }
</style>




<table class="trend-impact-table">
  <thead>
    <tr>
      <th>Trend</th>
      <th>Impact</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Agentic Workflows</td>
      <td>Models need shared context to collaborate efficiently (e.g., ReAct, AutoGPT, BabyAGI).</td>
    </tr>
    <tr>
      <td>LLM Orchestration Frameworks</td>
      <td>Tools like LangChain, Semantic Kernel, and OpenDevin push for context-aware memory and model chaining.</td>
    </tr>
    <tr>
      <td>Open Model Ecosystems</td>
      <td>Efforts like Hugging Face&#8217;s Inference Endpoints, vLLM, and Modal want to standardize inference behavior.</td>
    </tr>
    <tr>
      <td>Retrieval-Augmented Generation (RAG)</td>
      <td>Persistent context and metadata handling are vital for grounded reasoning.</td>
    </tr>
  </tbody>
</table>


<p>Leading companies like <strong>OpenAI (via ChatGPT APIs)</strong>, <strong>Anthropic (via Claude’s memory)</strong>, and <strong>Mistral</strong> are integrating ideas from MCP implicitly, if not through standardized APIs.</p>

<a name="Core-Concepts-of-MCP"></a>
<h2>Core Concepts of MCP</h2>

<p>An MCP server typically supports the following concepts:</p>

<a name="L-3c-strong-3e-Model-Context-3c--2f-strong-3e-"></a>
<h3><strong>Model Context</strong></h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;session_id&quot;</span><span class="p">:</span> <span class="s2">&quot;abc-123&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;user_id&quot;</span><span class="p">:</span> <span class="s2">&quot;user-456&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;context&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;history&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>      <span class="p">{</span> <span class="nt">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="nt">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Generate a project plan.&quot;</span> <span class="p">},</span>
</span><span class='line'>      <span class="p">{</span> <span class="nt">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="nt">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Sure, here&#39;s a draft...&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="p">],</span>
</span><span class='line'>    <span class="nt">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;project_planning&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;dependencies&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;retrieval_plugin&quot;</span><span class="p">,</span> <span class="s2">&quot;summarizer_model&quot;</span><span class="p">]</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="L-3c-strong-3e-Model-Invocation-with-Context-3c--2f-strong-3e-"></a>
<h3><strong>Model Invocation with Context</strong></h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;What are the next steps?&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;context_ref&quot;</span><span class="p">:</span> <span class="s2">&quot;abc-123&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;metadata&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;requested_capability&quot;</span><span class="p">:</span> <span class="s2">&quot;planning.summarize&quot;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="L-3c-strong-3e-Chained-Outputs-and-Shared-State-3c--2f-strong-3e-"></a>
<h3><strong>Chained Outputs and Shared State</strong></h3>

<p>Each model contributes to a shared state, stored either in an in-memory store (like Redis) or a structured store (like Postgres + pgvector for embeddings).</p>

<a name="Building-a-Basic-MCP-Server"></a>
<h2>Building a Basic MCP Server</h2>

<p>Let’s outline what a minimal MCP-compatible server might look like using <strong>FastAPI</strong> and <strong>Redis</strong>.</p>

<a name="Basic-Server-with-Context-Store"></a>
<h3>Basic Server with Context Store</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">fastapi</span> <span class="kn">import</span> <span class="n">FastAPI</span><span class="p">,</span> <span class="n">Request</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">redis</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">uuid</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">json</span>
</span><span class='line'>
</span><span class='line'><span class="n">app</span> <span class="o">=</span> <span class="n">FastAPI</span><span class="p">()</span>
</span><span class='line'><span class="n">r</span> <span class="o">=</span> <span class="n">redis</span><span class="o">.</span><span class="n">Redis</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s">&#39;localhost&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">6379</span><span class="p">,</span> <span class="n">decode_responses</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="nd">@app.post</span><span class="p">(</span><span class="s">&quot;/invoke&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">async</span> <span class="k">def</span> <span class="nf">invoke_model</span><span class="p">(</span><span class="n">request</span><span class="p">:</span> <span class="n">Request</span><span class="p">):</span>
</span><span class='line'>    <span class="n">payload</span> <span class="o">=</span> <span class="n">await</span> <span class="n">request</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</span><span class='line'>    <span class="n">context_ref</span> <span class="o">=</span> <span class="n">payload</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;context_ref&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">input_text</span> <span class="o">=</span> <span class="n">payload</span><span class="p">[</span><span class="s">&quot;input&quot;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">model</span> <span class="o">=</span> <span class="n">payload</span><span class="p">[</span><span class="s">&quot;model&quot;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># Load context</span>
</span><span class='line'>    <span class="n">context</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">context_ref</span><span class="p">))</span> <span class="k">if</span> <span class="n">context_ref</span> <span class="k">else</span> <span class="p">{}</span>
</span><span class='line'>    <span class="n">history</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;history&quot;</span><span class="p">,</span> <span class="p">[])</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># Simulate model response</span>
</span><span class='line'>    <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s">&quot;role&quot;</span><span class="p">:</span> <span class="s">&quot;user&quot;</span><span class="p">,</span> <span class="s">&quot;content&quot;</span><span class="p">:</span> <span class="n">input_text</span><span class="p">})</span>
</span><span class='line'>    <span class="n">response</span> <span class="o">=</span> <span class="n">f</span><span class="s">&quot;Simulated response to: {input_text}&quot;</span>
</span><span class='line'>    <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s">&quot;role&quot;</span><span class="p">:</span> <span class="s">&quot;assistant&quot;</span><span class="p">,</span> <span class="s">&quot;content&quot;</span><span class="p">:</span> <span class="n">response</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># Save updated context</span>
</span><span class='line'>    <span class="n">new_context_ref</span> <span class="o">=</span> <span class="n">context_ref</span> <span class="ow">or</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span>
</span><span class='line'>    <span class="n">r</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">new_context_ref</span><span class="p">,</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span><span class="s">&quot;history&quot;</span><span class="p">:</span> <span class="n">history</span><span class="p">}))</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="p">{</span><span class="s">&quot;output&quot;</span><span class="p">:</span> <span class="n">response</span><span class="p">,</span> <span class="s">&quot;context_ref&quot;</span><span class="p">:</span> <span class="n">new_context_ref</span><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Add-Capability-Metadata"></a>
<h3>Add Capability Metadata</h3>

<p>Enhance the server to log requested capabilities and dependency resolution (e.g., invoking tools or submodels).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">capability</span> <span class="o">=</span> <span class="n">payload</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;metadata&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&quot;requested_capability&quot;</span><span class="p">)</span>
</span><span class='line'><span class="n">log_event</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">session_id</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">capability</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<hr />

<a name="MCP-vs-Alternatives"></a>
<h2>MCP vs Alternatives</h2>

<p>MCP aims to serve as the <strong>underlying protocol</strong>, while frameworks like LangChain act as <strong>developer tooling on top</strong>.</p>

<style>
  .comparison-table {
    width: 100%;
    border-collapse: collapse;
    font-family: Arial, sans-serif;
  }
  .comparison-table th,
  .comparison-table td {
    text-align: center;
    padding: 12px;
    border-bottom: 1px solid #ccc;
    width: 20%;
  }
  .comparison-table th {
    background-color: #f2f2f2;
  }
</style>




<table class="comparison-table">
  <thead>
    <tr>
      <th>Feature</th>
      <th>MCP</th>
      <th>LangChain</th>
      <th>Semantic Kernel</th>
      <th>ChatML (OpenAI)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Context Persistence</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td>Partial</td>
    </tr>
    <tr>
      <td>Model-Agnostic</td>
      <td>✅</td>
      <td>❌<br><small>(Python-specific)</small></td>
      <td>✅</td>
      <td>❌</td>
    </tr>
    <tr>
      <td>Stateful Memory</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td>Partial</td>
    </tr>
    <tr>
      <td>Chaining Support</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td>❌</td>
    </tr>
    <tr>
      <td>Explicit Protocol</td>
      <td>✅</td>
      <td>❌</td>
      <td>❌</td>
      <td>✅<br><small>(format only)</small></td>
    </tr>
  </tbody>
</table>


<a name="Adoption-and-Ecosystem-Signals"></a>
<h2>Adoption and Ecosystem Signals</h2>

<ul>
<li><strong>LangChain and LlamaIndex</strong>: Moving towards standardizing memory interfaces with composable context.</li>
<li><strong>OpenAI’s Assistant API</strong>: Explicitly supports persistent threads, similar to MCP session_id and shared memory.</li>
<li><strong>Anthropic&rsquo;s Memory Plans</strong>: Incorporates long-term memory slots, resembling MCP’s context model.</li>
<li><strong>Meta’s Multi-Agent Research (2024)</strong>: Proposes architectures that are context-routing centric — aligning with MCP’s goals.</li>
</ul>


<a name="Challenges-and-Future-Directions"></a>
<h2>Challenges and Future Directions</h2>

<a name="Technical-Challenges"></a>
<h3>Technical Challenges</h3>

<ul>
<li>Efficient context storage and retrieval at scale.</li>
<li>Dynamic resolution of capabilities and tool invocation.</li>
<li>Real-time chaining with latency constraints.</li>
</ul>


<a name="What-e2--80--99-s-Next-3f-"></a>
<h3>What’s Next?</h3>

<ul>
<li><strong>Open spec for MCP</strong>: Standardization akin to OpenAPI or GraphQL.</li>
<li><strong>Plugin Interop</strong>: Tool APIs that conform to context-aware interfaces.</li>
<li><strong>LLMOps Integration</strong>: Tracking usage, debugging flows, and observability in agentic systems.</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>The <strong>Model Context Protocol</strong> is a foundational building block for the next wave of <strong>AI-native applications</strong>. It abstracts and manages the complexity of context, model chaining, and agent collaboration — enabling AI systems that behave less like stateless endpoints and more like intelligent software agents.</p>

<p>As the AI ecosystem matures, MCP (whether explicitly named or not) will become central to orchestrating rich, multi-turn, multi-model AI systems.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[High-Flyer: Pioneering AI in Finance]]></title>
        <link href="https://rishijeet.github.io/blog/high-flyer-pioneering-ai-in-finance/"/>
        <updated>2025-03-30T20:13:12+05:30</updated>
        <id>https://rishijeet.github.io/blog/high-flyer-pioneering-ai-in-finance</id>
        <content type="html"><![CDATA[<p>In the rapidly evolving landscape of artificial intelligence (AI), China&rsquo;s DeepSeek has emerged as a formidable contender, challenging established players and redefining industry standards. This ascent is deeply intertwined with High-Flyer, an AI-driven quantitative hedge fund whose strategic investments and visionary leadership have propelled DeepSeek to the forefront of AI innovation.</p>

<p><img src="https://rishijeet.github.io/images/2025/deepseek.jpg" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>Founded in February 2016 by Liang Wenfeng, High-Flyer—officially known as Hangzhou Huanfang Technology Ltd Co.—quickly distinguished itself in the financial sector by leveraging AI models for investment decisions. By late 2017, AI systems managed the majority of High-Flyer&rsquo;s trading activities, solidifying its reputation as a leader in AI-driven stock trading. The firm&rsquo;s portfolio burgeoned to an impressive 100 billion yuan (approximately $13.79 billion), underscoring the efficacy of its AI-centric strategies.</p>

<!--more-->


<p><img src="https://rishijeet.github.io/images/2025/high_flyer.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Strategic-Investments-in-Computing-Power"></a>
<h2>Strategic Investments in Computing Power</h2>

<p>Anticipating the critical role of computational resources in AI advancement, Liang Wenfeng initiated substantial investments in high-performance hardware. Between 2020 and 2021, High-Flyer constructed two AI supercomputing clusters comprising Nvidia&rsquo;s A100 graphics processing units (GPUs). The first cluster, operational in 2020, integrated 1,100 A100 chips at a cost of 200 million yuan.
The subsequent year saw the completion of a second, more expansive cluster with approximately 10,000 A100 chips, representing a 1 billion yuan investment. These strategic acquisitions occurred prior to the U.S. government&rsquo;s 2022 restrictions on exporting advanced chips to China, positioning High-Flyer advantageously amid tightening technological embargoes.</p>

<p><img src="https://rishijeet.github.io/images/2025/quant_china.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Transition-to-Artificial-General-Intelligence--28-AGI-29-"></a>
<h2>Transition to Artificial General Intelligence (AGI)</h2>

<p>In 2023, High-Flyer announced a pivotal shift towards pursuing artificial general intelligence (AGI), aiming to develop autonomous systems capable of outperforming humans in most economically valuable tasks. This initiative led to the establishment of DeepSeek as an independent research entity dedicated to exploring the essence of AGI. Liang Wenfeng assumed a leadership role in DeepSeek, guiding its strategic direction and research endeavors.</p>

<p><img src="https://rishijeet.github.io/images/2025/hedge_fund_mania.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p><img src="https://rishijeet.github.io/images/2025/high_flyer_return.avif" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="DeepSeek-27-s-Breakthroughs-and-Industry-Impact"></a>
<h2>DeepSeek&rsquo;s Breakthroughs and Industry Impact</h2>

<p>DeepSeek&rsquo;s trajectory has been marked by a series of groundbreaking AI models:</p>

<ul>
<li><p><strong>DeepSeek-V2 (May 2024):</strong> This chatbot model gained widespread acclaim in China for its cost-efficiency and superior performance, outperforming offerings from major tech companies such as ByteDance, Tencent, Baidu, and Alibaba. Its release triggered a price war, compelling competitors to significantly reduce prices on their AI models.</p></li>
<li><p><strong>DeepSeek-V3 (December 2024):</strong> Building upon its predecessor, DeepSeek-V3 further enhanced capabilities and solidified DeepSeek&rsquo;s dominance in the AI sector.</p></li>
<li><p><strong>DeepSeek-R1 (January 2025):</strong> This reasoning model and its associated chatbot application marked DeepSeek&rsquo;s entry into the international market, challenging the prevailing assumption of U.S. dominance in AI.</p></li>
</ul>


<p>The sophistication of DeepSeek&rsquo;s models has garnered praise from Silicon Valley competitors, a first for a Chinese AI model. Notably, DeepSeek claims to have achieved these advancements using a fraction of the computing power deployed by leading U.S. firms, a revelation that contributed to a global selloff of tech shares.</p>

<a name="Navigating-Challenges-and-Future-Outlook"></a>
<h2>Navigating Challenges and Future Outlook</h2>

<p>Despite its rapid ascent, DeepSeek faces challenges, particularly concerning access to advanced computing hardware due to export restrictions. Liang Wenfeng has expressed concerns about the embargo on high-end chips, acknowledging it as a significant hurdle. Nevertheless, DeepSeek continues to innovate, relying on existing resources, efficiency improvements, and exploring domestic alternatives.</p>

<p>DeepSeek&rsquo;s success has also influenced China&rsquo;s financial markets. The Chinese stock market experienced a resurgence in investor interest, with equity issuance doubling in the first quarter of 2025 compared to the previous year, reaching $16.8 billion. This optimism is partly driven by the emergence of DeepSeek, which offers AI products at lower costs, encouraging global investors to reconsider China&rsquo;s potential despite ongoing trade tensions.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>DeepSeek&rsquo;s meteoric rise, underpinned by High-Flyer&rsquo;s strategic foresight and investment in AI, exemplifies China&rsquo;s growing prowess in the global AI landscape. By prioritizing research over immediate commercial profit and fostering a meritocratic environment, DeepSeek has not only achieved remarkable technological advancements but also challenged existing paradigms, signaling a shift towards a more diversified and competitive global AI ecosystem.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Buddhi: Pushing the Boundaries of Long-Context Open-Source AI]]></title>
        <link href="https://rishijeet.github.io/blog/buddhi-pushing-the-boundaries-of-long-context-open-source-ai/"/>
        <updated>2025-03-25T08:24:38+05:30</updated>
        <id>https://rishijeet.github.io/blog/buddhi-pushing-the-boundaries-of-long-context-open-source-ai</id>
        <content type="html"><![CDATA[<p>AI Planet has introduced Buddhi-128K-Chat-7B, an open-source chat model distinguished by its expansive 128,000-token context window. This advancement enables the model to process and retain extensive contextual information, enhancing its performance in tasks requiring deep context understanding.</p>

<p><img src="https://rishijeet.github.io/images/2025/buddhi.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Model-Architecture"></a>
<h2>Model Architecture</h2>

<p>Buddhi-128K-Chat-7B is fine-tuned from the Mistral-7B Instruct v0.2 base model, selected for its superior reasoning capabilities. The Mistral-7B architecture incorporates features such as Grouped-Query Attention and a Byte-fallback BPE tokenizer, originally supporting a maximum of 32,768 position embeddings. To extend this to 128K, the Yet another Rope Extension (YaRN) technique was employed, modifying positional embeddings to accommodate the increased context length.</p>

<!--more-->


<a name="Dataset-Composition"></a>
<h2>Dataset Composition</h2>

<p>The training dataset comprises three sections tailored for chat model development:</p>

<ul>
<li><strong>Stack Exchange Data</strong>: Consists of question-and-answer pairs, refined using the Mistral model to enhance
formatting for chat applications.</li>
<li><strong>PG19-Based Data with Alpaca Formatting</strong>: Utilizes the PG19 dataset as context, with question-answer pairs
generated by GPT-3.</li>
<li><strong>PG19-Based Data with GPT-4</strong>: Similar to the previous section but with question-answer pairs generated by GPT-4,
ensuring a diverse conversational scope.</li>
</ul>


<p>This strategic composition ensures comprehensive coverage of dialogue scenarios, optimizing the model&rsquo;s performance across various contexts.</p>

<a name="Benchmark-Performance"></a>
<h2>Benchmark Performance</h2>

<p>Buddhi-128K-Chat-7B has been evaluated using both short and long context benchmarks:</p>

<p><strong>Short Context Benchmarks</strong>: The model&rsquo;s performance on tasks like HellaSwag, ARC Challenge, MMLU, TruthfulQA, and Winogrande has been assessed, with metrics available on the Open LLM Leaderboard.</p>

<p><img src="https://rishijeet.github.io/images/2025/buddhi_bench.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p><strong>Long Context Benchmarks</strong>: Evaluations on datasets such as Banking77 have demonstrated the model&rsquo;s capability to handle extensive context effectively.</p>

<p><img src="https://rishijeet.github.io/images/2025/buddhi_bench_lc.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>These benchmarks indicate that Buddhi-128K-Chat-7B matches or surpasses other models in its size class, particularly in handling long-context scenarios.</p>

<a name="Inference-and-Hardware-Requirements"></a>
<h2>Inference and Hardware Requirements</h2>

<p>To utilize the full 128K context length, the following hardware specifications are recommended:</p>

<ul>
<li><strong>128K Context Length</strong>: Requires 80GB VRAM, with A100 GPUs preferred.</li>
<li><strong>32K Context Length</strong>: Requires 40GB VRAM, with A100 GPUs preferred.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/a100.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>For optimized inference, integrating vLLM, which employs Paged Attention to reduce memory footprint, is advisable. Additionally, bitsandbytes quantization can enable the model to run on GPUs with lower VRAM, such as T4 GPUs.</p>

<a name="Use-Cases-and-Applications"></a>
<h2>Use Cases and Applications</h2>

<p>The extended context window of Buddhi-128K-Chat-7B unlocks several practical applications:</p>

<ul>
<li><strong>Enhanced Memory and Recall</strong>: The model can reference earlier parts of a conversation, leading to more coherent and natural dialogues.</li>
<li><strong>Accurate Instruction Following</strong>: Capable of retaining and executing multi-step instructions without missing details.</li>
<li><strong>Efficient Workflow Automation</strong>: Suitable for processing large datasets in fields like legal document review and medical records analysis.</li>
<li><strong>Improved Coherence in Text Generation</strong>: Able to generate long-form content without losing context, ensuring consistency throughout the text.</li>
<li><strong>Deep Analysis and Insight Generation</strong>: Facilitates comprehensive analysis in research-intensive fields by understanding extensive documents in a single pass.</li>
</ul>


<p>While Buddhi-128K-Chat-7B offers significant advancements, it also presents challenges such as increased computational requirements and potential latency issues. Ongoing research and development are expected to address these limitations, further enhancing the model&rsquo;s efficiency and accessibility.</p>

<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>In conclusion, Buddhi-128K-Chat-7B represents a notable step forward in open-source chat models, offering an extended context window that enhances its applicability across various domains requiring deep contextual understanding.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Coca-Cola: A Legacy of Success, Controversy, and Resilience]]></title>
        <link href="https://rishijeet.github.io/blog/coca-cola-a-legacy-of-success/"/>
        <updated>2025-03-09T21:07:15+05:30</updated>
        <id>https://rishijeet.github.io/blog/coca-cola-a-legacy-of-success</id>
        <content type="html"><![CDATA[<p>Coca-Cola is one of the most iconic brands in the world, with a history spanning over a century. It has become synonymous with soft drinks, creating a massive global presence. This case study explores Coca-Cola’s success story, key crises, and scandals, as well as how the company has managed to remain a market leader for so long.</p>

<p><img src="https://rishijeet.github.io/images/2025/coca_cola.jpg" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="The-Success-Story"></a>
<h2>The Success Story</h2>

<a name="Origins-and-Early-Growth"></a>
<h3>Origins and Early Growth</h3>

<ul>
<li>Coca-Cola was invented in 1886 by Dr. John Stith Pemberton in Atlanta, Georgia.</li>
<li>The formula was later bought by Asa Candler, who aggressively marketed it and expanded distribution.</li>
<li>By 1895, Coca-Cola was sold across the United States.</li>
</ul>


<a name="Market-Domination"></a>
<h3>Market Domination</h3>

<ul>
<li>Coca-Cola became a household name through <strong>branding, advertising, and distribution</strong>.</li>
<li>By 1919, the company was sold to a group of investors for <strong>$25 million</strong>.</li>
<li>The introduction of the iconic <strong>contour bottle in 1915</strong> helped distinguish Coca-Cola from competitors.</li>
<li>The company’s famous Santa Claus campaign in the 1930s reinforced its association with happiness and celebration.</li>
<li>By the 1950s, Coca-Cola had expanded into more than <strong>100 countries</strong>.</li>
</ul>


<!--more-->


<a name="Product-Diversification"></a>
<h3>Product Diversification</h3>

<ul>
<li>In response to changing consumer preferences, Coca-Cola introduced products such as <strong>Diet Coke (1982), Coca-Cola Zero (2005), and Coca-Cola Life (2013)</strong>.</li>
<li>The company expanded into other beverage categories, acquiring <strong>Minute Maid (1960), Dasani (1999), and Costa Coffee (2018)</strong>.</li>
<li>Today, Coca-Cola owns over <strong>500 brands</strong> across more than <strong>200 countries</strong>.</li>
</ul>


<a name="Financial-Strength"></a>
<h3>Financial Strength</h3>

<ul>
<li>As of 2023, Coca-Cola’s annual revenue was <strong>$43 billion</strong>.</li>
<li>It holds a global market share of <strong>nearly 50%</strong> in the carbonated soft drinks industry.</li>
<li>The company spends <strong>over $4 billion annually</strong> on marketing and advertising.</li>
</ul>


<a name="Key-Facts--26-amp-3b--Figures"></a>
<h3>Key Facts &amp; Figures</h3>

<ul>
<li><strong>Founded:</strong> 1886</li>
<li><strong>Annual Revenue (2023):</strong> $43 billion</li>
<li><strong>Number of Countries Operated In:</strong> 200+</li>
<li><strong>Brands Owned:</strong> 500+</li>
<li><strong>Global Market Share (Soft Drinks):</strong> ~50%</li>
<li><strong>Annual Advertising Spend:</strong> $4 billion+</li>
<li><strong>Employees:</strong> 79,000+</li>
</ul>


<hr />

<a name="Major-Crises-and-Scandals"></a>
<h2>Major Crises and Scandals</h2>

<a name="The--22-New-Coke-22--Disaster--28-1985-29-"></a>
<h3>The &ldquo;New Coke&rdquo; Disaster (1985)</h3>

<ul>
<li>In 1985, Coca-Cola reformulated its flagship product, replacing it with &ldquo;New Coke.&rdquo;</li>
<li>The change sparked widespread backlash, with over <strong>400,000 complaints</strong> from customers.</li>
<li>Coca-Cola reintroduced the original formula as &ldquo;Coca-Cola Classic&rdquo; within <strong>79 days</strong>, turning the fiasco into a marketing triumph.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/new_coke.jpg" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Racial-Discrimination-Lawsuit--28-1999-29-"></a>
<h3>Racial Discrimination Lawsuit (1999)</h3>

<ul>
<li>Coca-Cola faced a <strong>$192.5 million settlement</strong> after being sued for racial discrimination in hiring and promotions.</li>
<li>The lawsuit led to significant changes in the company’s diversity and inclusion policies.</li>
</ul>


<a name="India-Pesticide-Controversy--28-2003-2d-2006-29-"></a>
<h3>India Pesticide Controversy (2003-2006)</h3>

<ul>
<li>A study in India found that Coca-Cola products contained pesticide residues <strong>24 times above European standards</strong>.</li>
<li>Sales dropped significantly in India, leading to factory closures and government scrutiny.</li>
<li>Coca-Cola later invested in <strong>water conservation projects</strong> and sustainability efforts to repair its image.</li>
</ul>


<a name="Water-Usage--26-amp-3b--Environmental-Concerns"></a>
<h3>Water Usage &amp; Environmental Concerns</h3>

<ul>
<li>Coca-Cola has faced criticism over excessive water usage, particularly in water-scarce regions.</li>
<li>In 2007, it pledged to become <strong>water neutral by 2020</strong>, a goal it claims to have met by replenishing <strong>100% of the water used</strong>.</li>
</ul>


<a name="Coca-2d-Cola-and-Health-Concerns"></a>
<h3>Coca-Cola and Health Concerns</h3>

<ul>
<li>The company has been accused of contributing to the global obesity crisis.</li>
<li>In 2015, reports emerged that Coca-Cola funded research downplaying the role of sugary drinks in obesity.</li>
<li>In response, Coca-Cola introduced <strong>low-sugar and no-sugar options</strong> and expanded its portfolio to include healthier beverages.</li>
</ul>


<hr />

<a name="Strategies-for-Long-2d-Term-Success"></a>
<h2>Strategies for Long-Term Success</h2>

<a name="Strong-Branding--26-amp-3b--Marketing"></a>
<h3>Strong Branding &amp; Marketing</h3>

<ul>
<li>Coca-Cola’s brand is valued at <strong>over $89 billion</strong>, making it one of the most recognized in the world.</li>
<li>The &ldquo;Share a Coke&rdquo; campaign (2011) personalized bottles, driving a <strong>2% increase in sales</strong>.</li>
</ul>


<a name="Global-Expansion--26-amp-3b--Localization"></a>
<h3>Global Expansion &amp; Localization</h3>

<ul>
<li>Coca-Cola adapts its products to regional tastes. In Japan, for instance, it sells <strong>green tea and coffee variants</strong>.</li>
<li>It has established a vast distribution network, ensuring availability in <strong>even the most remote areas</strong>.</li>
</ul>


<a name="Innovation--26-amp-3b--Product-Adaptation"></a>
<h3>Innovation &amp; Product Adaptation</h3>

<ul>
<li>The company has continuously introduced new beverages, including <strong>plant-based and functional drinks</strong>.</li>
<li>Investments in sustainability and health-focused products help maintain relevance in changing markets.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/coke_brands.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Crisis-Management--26-amp-3b--Adaptability"></a>
<h3>Crisis Management &amp; Adaptability</h3>

<ul>
<li>Coca-Cola’s ability to pivot quickly, such as during the &ldquo;New Coke&rdquo; crisis, has been key to maintaining customer trust.</li>
<li>Transparency and corporate social responsibility efforts have helped it recover from controversies.</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Coca-Cola’s longevity can be attributed to <strong>strong branding, global expansion, adaptability, and crisis management</strong>. Despite facing significant challenges, the company remains a market leader due to its ability to evolve and stay relevant in a changing world.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Case Study: The Collapse of Silicon Valley Bank]]></title>
        <link href="https://rishijeet.github.io/blog/case-study-the-collapse-of-silicon-valley-bank/"/>
        <updated>2025-03-09T11:48:11+05:30</updated>
        <id>https://rishijeet.github.io/blog/case-study-the-collapse-of-silicon-valley-bank</id>
        <content type="html"><![CDATA[<p>Silicon Valley Bank (SVB) was one of the largest banks catering to the startup and venture capital ecosystem in the United States. Its sudden collapse in March 2023 sent shockwaves through the financial sector, prompting government intervention and raising concerns about the stability of other regional banks. This case study explores the factors that led to SVB&rsquo;s failure, its impact, and key lessons learned.</p>

<p><img src="https://rishijeet.github.io/images/2025/svb.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Background-of-Silicon-Valley-Bank"></a>
<h2>Background of Silicon Valley Bank</h2>

<p>Founded in 1983, SVB grew into the 16th largest bank in the U.S., with assets exceeding $209 billion by the end of 2022. It specialized in serving technology startups, venture capital (VC) firms, and innovation-driven companies. SVB&rsquo;s business model relied heavily on deposit funding from these clients and investments in long-duration U.S. government bonds.</p>

<!--more-->


<a name="Growth-and-Success"></a>
<h3>Growth and Success</h3>

<ul>
<li>By 2021, SVB’s total assets grew by 215% compared to 2019.</li>
<li>It controlled nearly <strong>50% of all venture-backed startups’ deposits</strong> in the U.S.</li>
<li>A key player in the tech boom, SVB benefited from rising valuations, strong venture funding, and low interest rates.</li>
</ul>


<a name="The-Downfall:-Key-Factors-Leading-to-the-Collapse"></a>
<h2>The Downfall: Key Factors Leading to the Collapse</h2>

<a name="L-3c-strong-3e-Overreliance-on-Long-2d-Term-Bonds-3c--2f-strong-3e-"></a>
<h3><strong>Overreliance on Long-Term Bonds</strong></h3>

<p>SVB invested heavily in long-term U.S. Treasury bonds and mortgage-backed securities (MBS) to generate returns. However, these investments carried significant interest rate risk.</p>

<ul>
<li>By 2022, nearly <strong>57% of SVB’s total assets ($120 billion)</strong> were invested in securities, primarily long-duration bonds.</li>
<li>When interest rates rise, bond values fall, creating unrealized losses.</li>
</ul>


<a name="L-3c-strong-3e-Federal-Reserve-e2--80--99-s-Interest-Rate-Hikes-3c--2f-strong-3e-"></a>
<h3><strong>Federal Reserve’s Interest Rate Hikes</strong></h3>

<ul>
<li>The Federal Reserve raised interest rates <strong>11 times from March 2022 to March 2023</strong>, increasing the federal funds rate from <strong>0.25% to 4.75%</strong>.</li>
<li>The sharp rise in rates led to a <strong>$17 billion unrealized loss</strong> on SVB’s bond portfolio.</li>
<li>This devalued SVB’s assets, making it more vulnerable to liquidity pressures.</li>
</ul>


<a name="L-3c-strong-3e-Tech-Industry-Slowdown-and-Deposit-Flight-3c--2f-strong-3e-"></a>
<h3><strong>Tech Industry Slowdown and Deposit Flight</strong></h3>

<ul>
<li>As interest rates rose, venture capital funding declined <strong>by 31% in 2022</strong>, leading startups to withdraw deposits.</li>
<li>SVB’s deposits dropped from <strong>$198 billion in March 2022 to $165 billion by the end of 2022</strong>.</li>
</ul>


<a name="L-3c-strong-3e-Panic-and-Bank-Run--28-March-2023-29--3c--2f-strong-3e-"></a>
<h3><strong>Panic and Bank Run (March 2023)</strong></h3>

<ul>
<li>On <strong>March 8, 2023</strong>, SVB announced it had sold $21 billion worth of securities at a <strong>$1.8 billion loss</strong> and planned to raise $2.25 billion in new capital.</li>
<li>This triggered panic among VC firms and startups, leading to mass withdrawals of <strong>$42 billion in a single day</strong> (March 9).</li>
<li>On <strong>March 10, 2023</strong>, regulators shut down SVB, marking the <strong>largest U.S. bank failure since 2008</strong>.</li>
</ul>


<a name="Government-and-Market-Response"></a>
<h2>Government and Market Response</h2>

<a name="L-3c-strong-3e-FDIC-Intervention-3c--2f-strong-3e-"></a>
<h3><strong>FDIC Intervention</strong></h3>

<ul>
<li>The <strong>Federal Deposit Insurance Corporation (FDIC)</strong> took control of SVB, ensuring deposits up to <strong>$250,000</strong>.</li>
<li>On <strong>March 12, 2023</strong>, the U.S. government guaranteed all deposits, preventing wider contagion.</li>
</ul>


<a name="L-3c-strong-3e-Stock-Market-and-Banking-Sector-Impact-3c--2f-strong-3e-"></a>
<h3><strong>Stock Market and Banking Sector Impact</strong></h3>

<ul>
<li>Bank stocks plummeted, with <strong>First Republic Bank losing 70%</strong> of its value within days.</li>
<li>The <strong>KBW Bank Index</strong> (measuring U.S. bank performance) dropped <strong>18% in March 2023</strong>.</li>
<li>Global financial markets reacted sharply, fearing systemic risks.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/svb_stock.avif" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Key-Lessons-and-Takeaways"></a>
<h2>Key Lessons and Takeaways</h2>

<ul>
<li><p><strong>The Risk of Asset-Liability Mismatch</strong></p>

<ul>
<li>SVB’s heavy reliance on long-duration bonds while serving short-term depositors created a major mismatch, exposing
it to liquidity risk.</li>
</ul>
</li>
<li><p><strong>Interest Rate Sensitivity in Banking</strong></p>

<ul>
<li>Banks must proactively hedge against interest rate fluctuations, especially in a rising-rate environment.</li>
</ul>
</li>
<li><p><strong>The Power of Panic and Social Media</strong></p>

<ul>
<li>SVB’s collapse was exacerbated by rapid digital bank runs, fueled by panic-driven withdrawals coordinated through
social media and VC networks.</li>
</ul>
</li>
<li><p><strong>Regulatory and Risk Management Gaps</strong></p>

<ul>
<li>SVB was exempt from <strong>Dodd-Frank stress testing</strong> due to relaxed regulations in 2018.</li>
<li>Stricter oversight on regional banks could have mitigated risks.</li>
</ul>
</li>
</ul>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>The collapse of Silicon Valley Bank exposed vulnerabilities in the financial system, particularly for banks with concentrated deposit bases and interest rate exposure. While the FDIC’s intervention prevented a broader crisis, the incident underscored the need for robust risk management, diversified banking strategies, and stronger regulatory frameworks. SVB’s downfall serves as a cautionary tale for financial institutions navigating uncertain economic conditions.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Case Study: The Collapse of Credit Suisse]]></title>
        <link href="https://rishijeet.github.io/blog/case-study-the-collapse-of-credit-suisse/"/>
        <updated>2025-03-09T11:28:00+05:30</updated>
        <id>https://rishijeet.github.io/blog/case-study-the-collapse-of-credit-suisse</id>
        <content type="html"><![CDATA[<p>Credit Suisse, one of Switzerland’s most prestigious banks, fell from grace due to years of scandals, mismanagement, and financial instability. Once a symbol of Swiss banking excellence, the bank collapsed in 2023, forcing a historic takeover by UBS. This case study explores the major factors leading to Credit Suisse’s downfall, examining key financial data, regulatory failures, and market reactions.</p>

<p><img src="https://rishijeet.github.io/images/2025/credit_suisse.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="L-3c-strong-3e-Background-of-Credit-Suisse-3c--2f-strong-3e-"></a>
<h2><strong>Background of Credit Suisse</strong></h2>

<ul>
<li><strong>Founded</strong>: 1856</li>
<li><strong>Headquarters</strong>: Zurich, Switzerland</li>
<li><strong>Peak Market Capitalization</strong>: ~$96 billion (2007)</li>
<li><strong>Core Services</strong>: Investment banking, wealth management, asset management</li>
</ul>


<p>Credit Suisse was once among the most respected global banks, competing with giants like JPMorgan Chase, Goldman Sachs, and Deutsche Bank. However, a series of financial missteps and scandals weakened its standing in the banking industry.</p>

<!--more-->


<hr />

<a name="L-3c-strong-3e-Key-Events-Leading-to-the-Collapse-3c--2f-strong-3e-"></a>
<h2><strong>Key Events Leading to the Collapse</strong></h2>

<a name="L-3c-strong-3e-Archegos-Capital-Collapse--28-2021-29--3c--2f-strong-3e-"></a>
<h3><strong>Archegos Capital Collapse (2021)</strong></h3>

<p><strong>What Happened?</strong></p>

<ul>
<li>Archegos Capital, a highly leveraged hedge fund run by Bill Hwang, used complex financial instruments called <strong>total return swaps</strong> to take massive, concentrated positions in stocks like ViacomCBS.</li>
<li>When stock prices dropped, Archegos defaulted on margin calls, leading to <strong>$10 billion in combined losses</strong> across multiple banks.</li>
<li>Credit Suisse was <strong>the worst hit</strong>, losing <strong>$5.5 billion</strong>, compared to Nomura ($2 billion) and Goldman Sachs ($0 due to better risk management).</li>
</ul>


<p><strong>Impact:</strong></p>

<ul>
<li>Immediate <strong>stock price drop of 14%</strong>.</li>
<li>Credit Suisse&rsquo;s <strong>Chief Risk Officer and Head of Investment Banking resigned</strong>.</li>
<li><strong>Regulatory investigations</strong> into its risk oversight.</li>
</ul>


<hr />

<a name="L-3c-strong-3e-Greensill-Capital-Scandal--28-2021-29--3c--2f-strong-3e-"></a>
<h3><strong>Greensill Capital Scandal (2021)</strong></h3>

<p><strong>What Happened?</strong></p>

<ul>
<li>Greensill Capital, a supply-chain finance firm, collapsed in March 2021 after losing investor confidence.</li>
<li>Credit Suisse had <strong>$10 billion in exposure</strong> through supply chain finance funds that Greensill managed.</li>
<li>Investigations revealed that Credit Suisse had <strong>overlooked high-risk loans</strong> tied to Greensill’s questionable business model.</li>
</ul>


<p><strong>Impact:</strong></p>

<ul>
<li>Credit Suisse was forced to <strong>freeze $10 billion in client funds</strong>.</li>
<li>Investors filed lawsuits for <strong>mismanagement and negligence</strong>.</li>
<li>Further <strong>damage to its reputation and regulatory scrutiny</strong>.</li>
</ul>


<hr />

<a name="L-3c-strong-3e-Money-Laundering-and-Legal-Issues-3c--2f-strong-3e-"></a>
<h3><strong>Money Laundering and Legal Issues</strong></h3>

<p>Credit Suisse was repeatedly implicated in financial scandals:</p>

<ul>
<li><strong>2022: Cocaine Trafficking Case</strong> – Swiss courts found Credit Suisse guilty of <strong>failing to prevent money laundering</strong> for a Bulgarian cocaine cartel.</li>
<li><strong>2014-2022: U.S. Tax Evasion Scandals</strong> – The bank paid over <strong>$2.6 billion in fines</strong> for helping wealthy clients evade U.S. taxes.</li>
<li><strong>Mozambique “Tuna Bonds” Scandal</strong> – Credit Suisse arranged <strong>fraudulent loans worth $2 billion</strong>, leading to a national debt crisis in Mozambique.</li>
</ul>


<p><strong>Impact:</strong></p>

<ul>
<li>Legal fines exceeding <strong>$5 billion</strong> over a decade.</li>
<li>Loss of investor and client confidence.</li>
<li>Declining reputation and regulatory pressure.</li>
</ul>


<hr />

<a name="L-3c-strong-3e-2022-2d-2023-Liquidity-Crisis--26-amp-3b--Collapse-3c--2f-strong-3e-"></a>
<h3><strong>2022-2023 Liquidity Crisis &amp; Collapse</strong></h3>

<p><strong>What Happened?</strong></p>

<ul>
<li>In <strong>October 2022</strong>, rumors spread about Credit Suisse’s financial instability.</li>
<li>Wealthy clients <strong>withdrew $120 billion</strong> in Q4 2022 alone.</li>
<li>The bank’s stock <strong>plunged 75% in 2022</strong>.</li>
<li>The collapse of <strong>Silicon Valley Bank (SVB) in March 2023</strong> triggered a broader banking crisis, intensifying fears about Credit Suisse.</li>
<li><strong>Saudi National Bank</strong>, Credit Suisse’s largest investor (9.9% stake), <strong>refused to inject more capital</strong>, worsening the crisis.</li>
<li>The Swiss government intervened, brokering a <strong>$3.2 billion emergency takeover by UBS</strong> in March 2023.</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/cs_chart.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p><strong>Market Reaction:</strong></p>

<ul>
<li><strong>Credit Suisse stock hit an all-time low of $0.82 before the UBS takeover.</strong></li>
<li><strong>UBS share price surged</strong> as markets viewed the deal as a stabilization move.</li>
<li><strong>Swiss government guaranteed $9 billion in losses</strong> for UBS to absorb Credit Suisse’s assets.</li>
</ul>


<hr />

<a name="L-3c-strong-3e-Final-Collapse--26-amp-3b--UBS-Takeover-3c--2f-strong-3e-"></a>
<h2><strong>Final Collapse &amp; UBS Takeover</strong></h2>

<p>On <strong>March 19, 2023</strong>, the Swiss government orchestrated a forced merger between UBS and Credit Suisse:</p>

<ul>
<li><strong>UBS paid only $3.2 billion</strong>, a fraction of Credit Suisse’s former valuation.</li>
<li>Swiss authorities provided <strong>$100 billion in liquidity support</strong>.</li>
<li>The deal <strong>wiped out $17 billion in Credit Suisse&rsquo;s AT1 bonds</strong>, angering bondholders.</li>
<li>UBS’s market position strengthened, but <strong>thousands of jobs were cut</strong>.</li>
</ul>


<hr />

<a name="L-3c-strong-3e-Lessons-from-the-Credit-Suisse-Crisis-3c--2f-strong-3e-"></a>
<h2><strong>Lessons from the Credit Suisse Crisis</strong></h2>

<ul>
<li><p><strong>The Importance of Strong Risk Management</strong></p>

<ul>
<li>Credit Suisse’s exposure to <strong>highly leveraged entities (Archegos, Greensill)</strong> without proper risk controls was a
major factor in its downfall.</li>
</ul>
</li>
<li><p><strong>Reputation and Trust Are Everything in Banking</strong></p>

<ul>
<li>Multiple scandals (money laundering, tax evasion, fraud) eroded public trust, leading to <strong>massive client withdrawals</strong>.</li>
</ul>
</li>
<li><p><strong>Government Intervention in Financial Crises</strong></p>

<ul>
<li>Swiss regulators had to <strong>engineer an emergency UBS takeover</strong> to prevent systemic risk.</li>
</ul>
</li>
<li><p><strong>The End of a Banking Giant</strong></p>

<ul>
<li>A <strong>167-year-old institution collapsed</strong> due to poor management, excessive risk-taking, and legal troubles.</li>
<li><strong>UBS now dominates Swiss banking</strong>, marking a shift in global finance.</li>
</ul>
</li>
</ul>


<hr />

<a name="L-3c-strong-3e-Conclusion-3c--2f-strong-3e-"></a>
<h2><strong>Conclusion</strong></h2>

<p>The Credit Suisse crisis serves as a cautionary tale for banks worldwide. Despite being a globally significant institution, its failure to manage risks, handle scandals, and maintain client confidence led to its <strong>historic collapse in 2023</strong>. With tighter regulations and increased scrutiny, the banking sector must learn from this failure to avoid similar downfalls in the future.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[The Great Recession: A Tale of Boom]]></title>
        <link href="https://rishijeet.github.io/blog/the-great-recession-a-tale-of-boom/"/>
        <updated>2025-02-28T21:37:56+05:30</updated>
        <id>https://rishijeet.github.io/blog/the-great-recession-a-tale-of-boom</id>
        <content type="html"><![CDATA[<a name="L-3c-strong-3e-Prologue:-The-Illusion-of-Prosperity-3c--2f-strong-3e-"></a>
<h3><strong>Prologue: The Illusion of Prosperity</strong></h3>

<p>In the early 2000s, the United States and much of the Western world were riding high on a wave of economic prosperity. The stock market was booming, home prices were soaring, and credit was available to almost anyone who wanted it. The American Dream had never seemed more attainable. But beneath the surface, cracks were forming in the foundations of this seemingly unstoppable growth.</p>

<a name="L-3c-strong-3e-Act-1:-The-Bubble-Inflates--28-2000-2d-2006-29--3c--2f-strong-3e-"></a>
<h3><strong>Act 1: The Bubble Inflates (2000-2006)</strong></h3>

<p>The origins of the Great Recession can be traced back to a combination of financial deregulation, a booming housing market, and risky lending practices.</p>

<ul>
<li><strong>The Role of Subprime Mortgages:</strong>

<ul>
<li>Banks and financial institutions, encouraged by deregulation, began issuing high-risk loans to borrowers with poor credit histories.</li>
<li>The subprime mortgage market grew from <strong>8% of total mortgage originations in 2001 to over 20% by 2006</strong>.</li>
<li>Mortgage-backed securities (MBS) and collateralized debt obligations (CDOs) turned these risky loans into attractive investments.</li>
</ul>
</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/subprime.png" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><strong>The Role of the Federal Reserve:</strong>

<ul>
<li>In response to the dot-com bubble burst in 2000, the Federal Reserve lowered interest rates from <strong>6.5% in 2000 to 1% by 2003</strong>.</li>
<li>Cheap credit fueled an artificial boom in housing, encouraging speculative investments.</li>
</ul>
</li>
</ul>


<hr />

<ul>
<li><strong>Wall Street’s Greed and Financial Engineering:</strong>

<ul>
<li>Major banks and financial institutions, including Lehman Brothers, Bear Stearns, and AIG, aggressively pushed for the sale of MBS and CDOs.</li>
<li>Credit rating agencies, such as Moody’s and Standard &amp; Poor’s, assigned AAA ratings to these risky securities, falsely signaling their safety to investors.</li>
</ul>
</li>
</ul>


<!--more-->


<p>By 2006, home prices had risen by <strong>188% from 1997 levels</strong>, creating a housing bubble of epic proportions.</p>

<p><img src="https://rishijeet.github.io/images/2025/real_estate.jpg" height="300" width="900" alt="Alt text" /></p>

<a name="L-3c-strong-3e-Act-2:-The-Collapse-Begins--28-2007-2d-2008-29--3c--2f-strong-3e-"></a>
<h3><strong>Act 2: The Collapse Begins (2007-2008)</strong></h3>

<p>The tipping point arrived in 2007 when homeowners began defaulting on their subprime mortgages. The housing market, once thought to be invincible, started crumbling.</p>

<p><img src="https://rishijeet.github.io/images/2025/great_recession.png" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><strong>The First Domino Falls: Bear Stearns (March 2008)</strong>

<ul>
<li>Bear Stearns, a major investment bank, faced liquidity problems as its subprime-heavy hedge funds collapsed.</li>
<li>The Federal Reserve orchestrated its sale to JPMorgan Chase for <strong>just $2 per share</strong> (down from $172 a year earlier).</li>
</ul>
</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/bear_stearns.png" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><strong>Lehman Brothers: The Breaking Point (September 15, 2008)</strong>

<ul>
<li>Lehman Brothers, a 158-year-old financial giant, declared bankruptcy, marking the largest collapse in U.S. history with <strong>$639 billion in assets</strong>.</li>
<li>The Dow Jones Industrial Average plunged <strong>504 points in a single day</strong>, triggering panic in global markets.</li>
</ul>
</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/lehman_fall.png" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><strong>AIG and the Federal Bailout (September 16, 2008)</strong>

<ul>
<li>American International Group (AIG), which had insured trillions in MBS through credit default swaps, faced insolvency.</li>
<li>The U.S. government stepped in with an <strong>$85 billion bailout</strong>, later expanding it to <strong>$182 billion</strong>.</li>
</ul>
</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/aig_2007.jpg" height="300" width="900" alt="Alt text" /></p>

<ul>
<li><strong>Stock Market Collapse:</strong>

<ul>
<li>The S&amp;P 500 fell nearly <strong>57% from its peak in 2007 to its bottom in March 2009</strong>.</li>
<li>Unemployment soared from <strong>4.6% in 2007 to 10% by October 2009</strong>, with over <strong>8.7 million jobs lost</strong>.</li>
</ul>
</li>
</ul>


<p><img src="https://rishijeet.github.io/images/2025/stock_market_2007.png" height="300" width="900" alt="Alt text" /></p>

<a name="L-3c-strong-3e-Act-3:-Global-Domino-Effect--28-2008-2d-2010-29--3c--2f-strong-3e-"></a>
<h3><strong>Act 3: Global Domino Effect (2008-2010)</strong></h3>

<p>The crisis spread beyond the United States, leading to a worldwide recession.</p>

<ul>
<li><strong>Europe’s Banking Crisis:</strong>

<ul>
<li>Banks in the UK, Germany, and France faced massive losses due to exposure to U.S. mortgage securities.</li>
<li>Iceland’s banking system collapsed, forcing the government to seek a <strong>$4.6 billion bailout</strong>.</li>
</ul>
</li>
</ul>


<hr />

<ul>
<li><strong>China’s Response:</strong>

<ul>
<li>China launched a <strong>$586 billion stimulus package</strong>, investing in infrastructure and state-owned enterprises to
counter the slowdown.</li>
</ul>
</li>
</ul>


<hr />

<ul>
<li><strong>The Eurozone Debt Crisis:</strong>

<ul>
<li>Greece, Ireland, and Spain faced severe financial crises, requiring bailouts from the European Union and the International Monetary Fund (IMF).</li>
</ul>
</li>
</ul>


<a name="L-3c-strong-3e-Act-4:-Recovery-and-Reforms--28-2010-2d-Present-29--3c--2f-strong-3e-"></a>
<h3><strong>Act 4: Recovery and Reforms (2010-Present)</strong></h3>

<p>Governments around the world took aggressive steps to stabilize the economy.</p>

<ul>
<li><strong>The TARP Bailout (2008-2009):</strong>

<ul>
<li>The U.S. government introduced the <strong>$700 billion Troubled Asset Relief Program (TARP)</strong> to rescue failing banks.</li>
<li>Banks like Citigroup and Bank of America received significant funds, which were eventually repaid.</li>
</ul>
</li>
</ul>


<hr />

<ul>
<li><strong>Dodd-Frank Act (2010):</strong>

<ul>
<li>Introduced financial reforms, including the Volcker Rule, which restricted banks from engaging in risky investments.</li>
<li>Established the Consumer Financial Protection Bureau (CFPB) to oversee lending practices.</li>
</ul>
</li>
</ul>


<hr />

<ul>
<li><strong>Slow but Steady Recovery:</strong>

<ul>
<li>The U.S. GDP contracted by <strong>4.3% during the recession</strong>, but recovered by 2013.</li>
<li>By 2018, unemployment had fallen to <strong>3.7%</strong>, and stock markets hit record highs.</li>
</ul>
</li>
</ul>


<a name="L-3c-strong-3e-Epilogue:-Lessons-Learned-and-the-Road-Ahead-3c--2f-strong-3e-"></a>
<h3><strong>Epilogue: Lessons Learned and the Road Ahead</strong></h3>

<p>The Great Recession reshaped the global financial landscape. It exposed the dangers of excessive risk-taking, inadequate regulation, and blind faith in financial engineering.</p>

<p>Lesser-known facts:</p>

<ul>
<li>Lehman Brothers’ failure was partially due to a refusal from Barclays and the UK government to intervene.</li>
<li>At the height of the crisis, the U.S. Federal Reserve secretly loaned over $16 trillion to global banks to prevent a total collapse.</li>
<li>Warren Buffett described the financial derivatives market as &ldquo;financial weapons of mass destruction&rdquo; years before the crisis hit.</li>
</ul>


<p>While economies have largely recovered, new risks such as corporate debt bubbles and geopolitical tensions continue to pose challenges. The Great Recession serves as a stark reminder that financial stability is never guaranteed.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Case Study: Lipton – A Global Tea Powerhouse]]></title>
        <link href="https://rishijeet.github.io/blog/case-study-lipton-a-global-tea-powerhouse/"/>
        <updated>2025-02-26T18:16:23+05:30</updated>
        <id>https://rishijeet.github.io/blog/case-study-lipton-a-global-tea-powerhouse</id>
        <content type="html"><![CDATA[<p>In the bustling streets of Glasgow, Scotland, in the 1870s, a young, ambitious entrepreneur named Sir Thomas Lipton had a vision—to make tea, once a luxury for the elite, accessible to everyone. Little did he know that his dream would evolve into a global tea empire that would redefine the industry for generations to come.</p>

<p><img src="https://rishijeet.github.io/images/2025/lipton_logo.png" height="300" width="900" alt="Alt text" /></p>

<a name="L-3c-strong-3e-The-Humble-Beginnings-3c--2f-strong-3e-"></a>
<h2><strong>The Humble Beginnings</strong></h2>

<p>Thomas Lipton, born in 1848 to Irish immigrant parents, was no stranger to hard work. At the age of 15, he sailed to the United States, where he took up various jobs, including working in a grocery store. Observing the efficiency of American retail operations, he returned to Scotland with a dream of revolutionizing the food trade.</p>

<p>In 1871, at the age of 23, Lipton opened his first grocery store in Glasgow. He marketed his store as offering “the best goods at the cheapest prices,” a philosophy that won the hearts of working-class families. His business grew rapidly, and by the 1880s, he owned over 300 stores across Britain. But Lipton was always thinking bigger.</p>

<!--more-->


<p><img src="https://rishijeet.github.io/images/2025/lipton.png" height="300" width="900" alt="Alt text" /></p>

<a name="L-3c-strong-3e-Breaking-Into-the-Tea-Industry-3c--2f-strong-3e-"></a>
<h2><strong>Breaking Into the Tea Industry</strong></h2>

<p>During the late 19th century, tea was an expensive luxury, controlled by middlemen who inflated prices. Lipton saw an opportunity. Rather than relying on suppliers, he decided to cut out the middlemen and source tea directly from plantations in Ceylon (modern-day Sri Lanka). He bought vast tea estates, ensuring quality control and reducing costs.</p>

<p>To market his tea, Lipton leveraged his exceptional promotional skills. He sponsored hot air balloon events, used colorful advertisements, and even hired elephants to parade through London’s streets carrying Lipton Tea chests. His genius lay in making tea not just affordable but desirable.</p>

<a name="L-3c-strong-3e-Tea-for-the-Masses-3c--2f-strong-3e-"></a>
<h2><strong>Tea for the Masses</strong></h2>

<p>Lipton introduced the concept of pre-packaged tea, a revolutionary idea at the time. Until then, tea was sold loose, and quality varied. By branding and packaging his tea, he guaranteed consistency, making it more appealing to customers. His slogan, “Direct from the Tea Gardens to the Teapot,” became synonymous with freshness and affordability.</p>

<p>By 1890, Lipton Tea was a household name in Britain, and soon, it spread across Europe and America. He even earned a royal warrant as the official tea supplier to Queen Victoria—a remarkable feat for a man who started with a single grocery store.</p>

<a name="L-3c-strong-3e-Global-Expansion-and-Innovations-3c--2f-strong-3e-"></a>
<h2><strong>Global Expansion and Innovations</strong></h2>

<p>In the early 20th century, Lipton continued expanding, setting up distribution channels worldwide. One of the most significant milestones came in the 1950s when Lipton became part of the Unilever conglomerate, giving it access to unparalleled resources and global reach.</p>

<p>As consumer habits evolved, Lipton adapted. The introduction of tea bags in the 1950s and ready-to-drink iced tea in the 1990s revolutionized the industry. Lipton embraced health-conscious trends, launching green teas, herbal infusions, and organic blends.</p>

<a name="L-3c-strong-3e-Fun-Facts-and-Data-Points-3c--2f-strong-3e-"></a>
<h2><strong>Fun Facts and Data Points</strong></h2>

<ul>
<li><strong>Lipton Today</strong>: Sold in over <strong>110 countries</strong>, Lipton is one of the world’s most recognizable tea brands.</li>
<li><strong>Tea Production</strong>: Lipton sources tea from <strong>more than 600 tea estates</strong> worldwide.</li>
<li><strong>Environmental Commitment</strong>: Lipton has committed to <strong>100% Rainforest Alliance Certified tea</strong>, ensuring sustainable farming practices.</li>
<li><strong>Marketing Genius</strong>: In 1929, Lipton launched one of the first-ever radio commercials in America, setting the stage for modern advertising strategies.</li>
</ul>


<a name="L-3c-strong-3e-The-Legacy-of-Lipton-3c--2f-strong-3e-"></a>
<h2><strong>The Legacy of Lipton</strong></h2>

<p>From a single grocery store in Glasgow to a global powerhouse, Lipton’s journey is a testament to innovation, persistence, and an unyielding belief in making quality tea accessible to all. Sir Thomas Lipton’s legacy endures not just in every cup of Lipton tea enjoyed worldwide but in the very fabric of modern retail and branding strategies.</p>

<p>So, the next time you sip on a warm cup of Lipton tea, remember—you’re not just drinking tea; you’re tasting a rich history steeped in vision and ingenuity.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Using Explainable AI (XAI) in Fintech]]></title>
        <link href="https://rishijeet.github.io/blog/using-explainable-ai-xai-in-fintech/"/>
        <updated>2025-01-23T10:07:03+05:30</updated>
        <id>https://rishijeet.github.io/blog/using-explainable-ai-xai-in-fintech</id>
        <content type="html"><![CDATA[<a name="Introduction-to-Explainable-AI--28-XAI-29-"></a>
<h3>Introduction to Explainable AI (XAI)</h3>

<p>Explainable AI (XAI) refers to the subset of artificial intelligence focused on making the decisions and predictions of AI models understandable and interpretable to humans. As AI systems grow in complexity, particularly with the use of deep learning, their &ldquo;black-box&rdquo; nature poses challenges in trust, accountability, and regulatory compliance. XAI techniques aim to bridge this gap by providing insights into how AI models make decisions.</p>

<p><img src="https://rishijeet.github.io/images/2025/xai.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Key-Components-of-XAI"></a>
<h3>Key Components of XAI</h3>

<p><strong>Model Interpretability:</strong></p>

<ul>
<li>Ability to understand the inner workings of an AI model.</li>
<li>Examples: Decision trees, linear regression, and simple neural networks are inherently interpretable.</li>
</ul>


<p><strong>Post-Hoc Explanations:</strong></p>

<ul>
<li>Techniques that explain the decisions of black-box models without altering their architecture.</li>
<li>Examples: LIME (Local Interpretable Model-Agnostic Explanations), SHAP (SHapley Additive exPlanations).</li>
</ul>


<!--more-->


<p><strong>Feature Importance Analysis:</strong></p>

<ul>
<li>Quantifying the contribution of each feature to a model’s prediction.</li>
</ul>


<p><strong>Counterfactual Explanations:</strong></p>

<ul>
<li>Offering hypothetical scenarios that show how changes in input features could alter the outcome.</li>
</ul>


<p><strong>Visualization Tools:</strong></p>

<ul>
<li>Tools such as saliency maps, partial dependence plots, and heatmaps that help visualize model behavior.</li>
</ul>


<a name="Implementation-of-XAI-in-Fintech"></a>
<h3>Implementation of XAI in Fintech</h3>

<p>Fintech, characterized by high stakes and stringent regulatory environments, offers fertile ground for XAI adoption. Here’s how XAI can be implemented:</p>

<a name="L-3c-strong-3e-Credit-Scoring-and-Loan-Approvals-3c--2f-strong-3e-"></a>
<h4><strong>Credit Scoring and Loan Approvals</strong></h4>

<ul>
<li><strong>Current Challenge:</strong> Customers and regulators demand transparency in how creditworthiness is evaluated.</li>
<li><strong>XAI Application:</strong> Use SHAP or LIME to explain which features (e.g., income, credit history, spending patterns) most influenced a loan approval or denial.</li>
<li><strong>Implementation:</strong> Integrate these explanations into user-facing dashboards for customer clarity and internal audit purposes.</li>
</ul>


<a name="L-3c-strong-3e-Fraud-Detection-3c--2f-strong-3e-"></a>
<h4><strong>Fraud Detection</strong></h4>

<ul>
<li><strong>Current Challenge:</strong> Traditional fraud detection algorithms are opaque, leading to difficulties in understanding false positives/negatives.</li>
<li><strong>XAI Application:</strong> Deploy anomaly detection models with explainability layers, highlighting specific transaction attributes (e.g., unusual location, time, or amount) responsible for flagging a transaction.</li>
<li><strong>Implementation:</strong> Combine explainability with real-time alerts to reduce investigation times and enhance trust.</li>
</ul>


<a name="L-3c-strong-3e-Investment-Advisory-3c--2f-strong-3e-"></a>
<h4><strong>Investment Advisory</strong></h4>

<ul>
<li><strong>Current Challenge:</strong> Robo-advisors often use complex algorithms for portfolio optimization, which users might not fully trust.</li>
<li><strong>XAI Application:</strong> Explain allocation decisions by breaking down the influence of market trends, risk tolerance, and user preferences.</li>
<li><strong>Implementation:</strong> Include visual and textual explanations in advisory reports, enabling better customer understanding.</li>
</ul>


<a name="L-3c-strong-3e-Regulatory-Compliance-and-Auditing-3c--2f-strong-3e-"></a>
<h4><strong>Regulatory Compliance and Auditing</strong></h4>

<ul>
<li><strong>Current Challenge:</strong> Compliance with laws like GDPR and the EU’s AI Act requires understanding AI decision-making.</li>
<li><strong>XAI Application:</strong> Provide detailed audit trails and explanations of decisions to demonstrate adherence to regulations.</li>
<li><strong>Implementation:</strong> Develop frameworks for ongoing monitoring and documentation of AI behavior.</li>
</ul>


<a name="L-3c-strong-3e-Customer-Service-Chatbots-3c--2f-strong-3e-"></a>
<h4><strong>Customer Service Chatbots</strong></h4>

<ul>
<li><strong>Current Challenge:</strong> Chatbots driven by AI can sometimes provide inconsistent or unclear responses.</li>
<li><strong>XAI Application:</strong> Enhance chatbot transparency by showing the reasoning behind responses, such as past interactions or keyword significance.</li>
<li><strong>Implementation:</strong> Integrate explainability modules into chatbot systems to increase user satisfaction and trust.</li>
</ul>


<a name="Scope-of-XAI-in-Fintech-Over-the-Next-Few-Years"></a>
<h3>Scope of XAI in Fintech Over the Next Few Years</h3>

<p><strong>Enhanced Trust and Adoption:</strong></p>

<ul>
<li>As financial institutions increasingly adopt AI, explainability will become a differentiator for building customer trust.</li>
<li>Regulators will likely mandate XAI integration to ensure transparency and fairness.</li>
</ul>


<p><strong>Technological Advancements:</strong></p>

<ul>
<li>Emerging XAI tools will offer deeper insights with lower computational overhead.</li>
<li>Hybrid models combining interpretability and high performance will gain traction.</li>
</ul>


<p><strong>Personalized Financial Services:</strong></p>

<ul>
<li>With XAI, fintech companies can deliver highly personalized services while ensuring that users understand the logic behind recommendations.</li>
</ul>


<p><strong>Stronger Regulatory Compliance:</strong></p>

<ul>
<li>XAI will play a crucial role in satisfying evolving regulatory requirements, particularly in regions emphasizing ethical AI use.</li>
</ul>


<p><strong>Integration with Blockchain:</strong></p>

<ul>
<li>XAI can complement blockchain technology in fintech, offering transparency in both data lineage and AI-driven decision-making.</li>
</ul>


<p><strong>Risk Management and Fairness:</strong></p>

<ul>
<li>By identifying biases and vulnerabilities in models, XAI will enhance risk management and promote equitable AI systems.</li>
</ul>


<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>The intersection of XAI and fintech holds immense potential for revolutionizing financial services. By making AI
more transparent, interpretable, and accountable, fintech companies can address key challenges around trust,
fairness, and compliance. Over the next few years, the adoption of XAI will likely become a critical factor in
driving innovation and maintaining competitiveness in the fintech industry.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[MLX vs CUDA: A Detailed Technical Comparison]]></title>
        <link href="https://rishijeet.github.io/blog/mlx-vs-cuda-a-detailed-technical-comparison/"/>
        <updated>2025-01-21T07:45:30+05:30</updated>
        <id>https://rishijeet.github.io/blog/mlx-vs-cuda-a-detailed-technical-comparison</id>
        <content type="html"><![CDATA[<p>Machine learning frameworks and technologies continue to evolve, leading to the rise of competing platforms designed to maximize performance, flexibility, and ease of use for modern AI workloads. Two prominent frameworks, MLX (Machine Learning Exchange) and CUDA (Compute Unified Device Architecture), are often compared in terms of performance and functionality. This article provides a detailed exploration of the differences between MLX and CUDA, focusing on their architecture, usability, and benchmarking scores.</p>

<a name="L-3c-strong-3e-What-is-CUDA-3f--3c--2f-strong-3e-"></a>
<h3><strong>What is CUDA?</strong></h3>

<p>CUDA is a parallel computing platform and programming model developed by NVIDIA, specifically designed for NVIDIA GPUs. It allows developers to use C, C++, Fortran, and Python to write applications that can leverage GPU acceleration. CUDA provides low-level access to the GPU hardware, enabling high performance for applications like deep learning, scientific computing, and high-performance simulations.</p>

<p><img src="https://rishijeet.github.io/images/2025/cuda.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>Key features of CUDA:</p>

<ul>
<li><strong>Low-level optimization</strong>: Offers direct control over GPU memory and thread management.</li>
<li><strong>Rich ecosystem</strong>: Integrated with libraries like cuDNN, NCCL, and TensorRT.</li>
<li><strong>Highly mature</strong>: Over a decade of optimizations and wide industry adoption.</li>
</ul>


<!--more-->


<a name="L-3c-strong-3e-What-is-MLX-3f--3c--2f-strong-3e-"></a>
<h3><strong>What is MLX?</strong></h3>

<p>MLX (Machine Learning Exchange) is an emerging platform that abstracts machine learning and deep learning workflows. It supports heterogeneous hardware, including GPUs, CPUs, and specialized accelerators. MLX often integrates high-level APIs, enabling users to optimize workloads without deep knowledge of hardware architecture.</p>

<p><img src="https://rishijeet.github.io/images/2025/mlx.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<p>Key features of MLX:</p>

<ul>
<li><strong>Cross-platform support</strong>: Runs on multiple hardware types.</li>
<li><strong>High-level abstraction</strong>: Simplifies model training and deployment.</li>
<li><strong>Integration-friendly</strong>: Works well with TensorFlow, PyTorch, and ONNX.</li>
</ul>


<a name="L-3c-strong-3e-Architecture-3c--2f-strong-3e-"></a>
<h2><strong>Architecture</strong></h2>

<ul>
<li><p><strong>CUDA</strong>:</p>

<ul>
<li>CUDA provides fine-grained control over GPU execution.</li>
<li>Thread and memory management are handled explicitly, giving developers the ability to maximize performance through detailed tuning.</li>
<li>Works exclusively on NVIDIA GPUs, leveraging specialized hardware like Tensor Cores.</li>
</ul>
</li>
<li><p><strong>MLX</strong>:</p>

<ul>
<li>MLX abstracts the underlying hardware, making it easier for developers to build models without focusing on device-specific optimizations.</li>
<li>Supports a variety of hardware, including GPUs (NVIDIA, AMD), CPUs, and emerging accelerators like TPUs.</li>
<li>Focuses on portability over deep hardware-specific optimizations.</li>
</ul>
</li>
</ul>


<a name="L-3c-strong-3e-Performance-Benchmarks-3c--2f-strong-3e-"></a>
<h2><strong>Performance Benchmarks</strong></h2>

<p>Benchmarking was conducted to evaluate the performance of MLX and CUDA on several machine learning workloads. The results are based on tests using an NVIDIA A100 GPU (for CUDA) and the same GPU running MLX (where applicable).</p>

<p><img src="https://rishijeet.github.io/images/2025/cuda_mlx_benchmark.png" height="300" width="900" alt="Alt text" /></p>

<p>The performance benchmark chart above highlights the comparison between CUDA and MLX for training throughput and inference latency across three tasks: Image Classification, Object Detection, and Transformer Models.</p>

<ul>
<li>Training Throughput: CUDA consistently achieves higher throughput (bars on the left for each task), demonstrating
its fine-grained optimization for NVIDIA GPUs.</li>
<li>Inference Latency: CUDA also exhibits lower latency (lines with green markers) compared to MLX (lines with red
markers), showcasing its efficiency in real-time workloads.
This visualization emphasizes CUDA&rsquo;s advantage in both raw performance and latency, particularly on NVIDIA GPUs, while MLX offers competitive results with a broader hardware compatibility.

<a name="L-3c-strong-3e-Key-Observations-3c--2f-strong-3e-"></a>
<h3><strong>Key Observations</strong></h3></li>
<li>CUDA consistently outperformed MLX in raw throughput and latency due to its hardware-specific optimizations and direct access to NVIDIA GPU architecture.</li>
<li>MLX’s performance was competitive, particularly for workflows prioritizing hardware-agnostic support.</li>
<li>The performance gap was more pronounced in tasks involving fine-grained GPU operations, such as training BERT or running YOLOv5.</li>
</ul>


<a name="L-3c-strong-3e-Energy-Efficiency-3c--2f-strong-3e-"></a>
<h3><strong>Energy Efficiency</strong></h3>

<p>Energy consumption was measured for both frameworks during the benchmarks.
<img src="https://rishijeet.github.io/images/2025/cuda_mlx_efficiency.png" height="300" width="900" alt="Alt text" /></p>

<p>Here is the graphical representation of the energy efficiency comparison between CUDA and MLX. It highlights:</p>

<ul>
<li>The average power consumption (W) for each framework (shown as bars).</li>
<li>The energy efficiency (images/sec/W) (shown as a line plot).</li>
</ul>


<p>CUDA demonstrated better energy efficiency due to optimized GPU utilization and reduced overhead.</p>

<a name="L-3c-strong-3e-Use-Cases-3c--2f-strong-3e-"></a>
<h2><strong>Use Cases</strong></h2>

<ul>
<li><p><strong>CUDA</strong>:</p>

<ul>
<li>Ideal for applications requiring peak performance, such as autonomous vehicles, financial modeling, and real-time simulations.</li>
<li>Suitable for research and production environments where NVIDIA GPUs are the standard.</li>
</ul>
</li>
<li><p><strong>MLX</strong>:</p>

<ul>
<li>Best suited for teams working across heterogeneous hardware environments or those prioritizing ease of use.</li>
<li>Effective for organizations building portable machine learning solutions for diverse infrastructure.</li>
</ul>
</li>
</ul>


<a name="L-3c-strong-3e-Conclusion-3c--2f-strong-3e-"></a>
<h2><strong>Conclusion</strong></h2>

<p>CUDA remains the gold standard for GPU-accelerated machine learning, offering unparalleled performance and efficiency. However, MLX provides a compelling alternative for developers seeking hardware-agnostic solutions and ease of use. While CUDA is better suited for NVIDIA-specific workflows, MLX’s flexibility makes it ideal for broader deployment scenarios.</p>

<p>Ultimately, the choice between MLX and CUDA depends on your specific requirements: if peak performance on NVIDIA GPUs is critical, CUDA is the clear choice. For portability and simplicity, MLX offers significant advantages.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Apache Airflow Architecture: A Detailed Overview]]></title>
        <link href="https://rishijeet.github.io/blog/apache-airflow-architecture-a-detailed-overview/"/>
        <updated>2024-10-08T09:35:07+05:30</updated>
        <id>https://rishijeet.github.io/blog/apache-airflow-architecture-a-detailed-overview</id>
        <content type="html"><![CDATA[<p>Apache Airflow is a powerful open-source platform used to programmatically author, schedule, and monitor workflows. It is designed for complex data engineering tasks, pipeline automation, and orchestrating multiple processes. This article will break down Airflow&rsquo;s architecture and provide a code example to help you understand how to work with it.</p>

<p><img src="https://rishijeet.github.io/images/2024/apache_airflow.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="Key-Concepts-in-Airflow"></a>
<h3>Key Concepts in Airflow</h3>

<p>Before diving into the architecture, let’s go over some important Airflow concepts:</p>

<ul>
<li><strong>DAG (Directed Acyclic Graph)</strong>: The core abstraction in Airflow. A DAG represents a workflow, organized as a set of tasks that can be scheduled and executed.</li>
<li><strong>Operator</strong>: A specific task within a DAG. There are various types of operators, including PythonOperator, BashOperator, and others.</li>
<li><strong>Task</strong>: An individual step in a workflow.</li>
<li><strong>Executor</strong>: Responsible for running tasks on the worker nodes.</li>
<li><strong>Scheduler</strong>: Determines when DAGs and their tasks should run.</li>
<li><strong>Web Server</strong>: Provides a UI for monitoring DAGs and tasks.</li>
<li><strong>Metadata Database</strong>: Stores information about the DAGs and their run status.</li>
</ul>


<!--more-->


<p>Now that we&rsquo;ve introduced these basic concepts, let’s look at Airflow’s architecture in detail.</p>

<a name="Airflow-Architecture"></a>
<h2>Airflow Architecture</h2>

<p>The Airflow architecture is based on a distributed model where different components handle specific responsibilities. The primary components are:</p>

<a name="L-3c-strong-3e-Scheduler-3c--2f-strong-3e-"></a>
<h3><strong>Scheduler</strong></h3>

<p>The Scheduler is the heart of Airflow. It is responsible for determining when a task should run based on the scheduling interval defined in a DAG. It monitors all active DAGs and adds tasks to the execution queue.</p>

<ul>
<li><strong>DAG Parsing</strong>: The scheduler continuously parses DAG files to check for changes or new DAGs.</li>
<li><strong>Task Queueing</strong>: It places tasks that need execution in a queue.</li>
</ul>


<a name="L-3c-strong-3e-Executor-3c--2f-strong-3e-"></a>
<h3><strong>Executor</strong></h3>

<p>The Executor is responsible for running the tasks that the scheduler assigns to it. Different types of executors can be used, depending on the scale and complexity of the environment.</p>

<ul>
<li><strong>SequentialExecutor</strong>: Useful for development and debugging, but can only run one task at a time.</li>
<li><strong>LocalExecutor</strong>: Runs tasks in parallel on the local machine.</li>
<li><strong>CeleryExecutor</strong>: Uses Celery and Redis or RabbitMQ to run tasks in parallel across multiple worker nodes.</li>
</ul>


<a name="L-3c-strong-3e-Workers-3c--2f-strong-3e-"></a>
<h3><strong>Workers</strong></h3>

<p>Workers are the machines where the tasks are executed. In larger deployments, workers are distributed across multiple machines to handle high workloads efficiently. Workers receive tasks from the executor and execute them.</p>

<a name="L-3c-strong-3e-Web-Server-3c--2f-strong-3e-"></a>
<h3><strong>Web Server</strong></h3>

<p>The Web Server provides an interface for users to monitor and manage the execution of workflows. This is built on Flask and provides a rich UI to visualize DAGs, track task statuses, logs, etc.</p>

<a name="L-3c-strong-3e-Metadata-Database-3c--2f-strong-3e-"></a>
<h3><strong>Metadata Database</strong></h3>

<p>Airflow uses a relational database (e.g., PostgreSQL, MySQL) as the metadata store. It holds details about DAGs, task instances, users, connections, variables, and other essential metadata.</p>

<a name="L-3c-strong-3e-Flower-3c--2f-strong-3e-"></a>
<h3><strong>Flower</strong></h3>

<p>Flower is an optional component that can be used with the CeleryExecutor to monitor worker nodes and tasks in real-time.</p>

<a name="L-3c-strong-3e-Message-Broker--28-For-CeleryExecutor-29--3c--2f-strong-3e-"></a>
<h3><strong>Message Broker (For CeleryExecutor)</strong></h3>

<p>In a setup using CeleryExecutor, a message broker (RabbitMQ, Redis) is used to manage communication between the scheduler, executor, and workers.</p>

<a name="L-3c-strong-3e-DagBag-3c--2f-strong-3e-"></a>
<h3><strong>DagBag</strong></h3>

<p>DagBag is the collection of all the DAGs that are active and ready to be scheduled by the scheduler. Every time a new DAG file is added or updated, it is added to the DagBag for execution.</p>

<a name="Typical-Workflow"></a>
<h2>Typical Workflow</h2>

<ol>
<li><strong>Authoring DAGs</strong>: DAGs are Python scripts that define the workflow. The user defines a set of tasks (using operators) and their dependencies.</li>
<li><strong>Scheduler Monitoring</strong>: The scheduler parses the DAGs and determines when they should be run based on the defined scheduling intervals (e.g., daily, hourly).</li>
<li><strong>Task Queuing</strong>: Tasks that are ready for execution are placed in a queue by the scheduler.</li>
<li><strong>Execution by Workers</strong>: The executor pulls tasks from the queue and assigns them to worker nodes for execution.</li>
<li><strong>Task Tracking</strong>: As tasks are executed, the metadata database is updated with the task status (e.g., success, failure).</li>
<li><strong>Monitoring via Web UI</strong>: The status of DAGs and tasks can be monitored in real-time using the web server.</li>
</ol>


<a name="Code-Example"></a>
<h2>Code Example</h2>

<p>Let’s create a basic DAG that uses a PythonOperator to run a Python function.</p>

<a name="DAG-Definition"></a>
<h3>DAG Definition</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span><span class="p">,</span> <span class="n">datetime</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">airflow.operators.python_operator</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Define a simple Python function to be used in the DAG</span>
</span><span class='line'><span class="k">def</span> <span class="nf">my_task</span><span class="p">():</span>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Hello from Apache Airflow!&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Define default arguments for the DAG</span>
</span><span class='line'><span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
</span><span class='line'>    <span class="s">&#39;owner&#39;</span><span class="p">:</span> <span class="s">&#39;airflow&#39;</span><span class="p">,</span>
</span><span class='line'>    <span class="s">&#39;depends_on_past&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
</span><span class='line'>    <span class="s">&#39;start_date&#39;</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2024</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span>
</span><span class='line'>    <span class="s">&#39;email_on_failure&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
</span><span class='line'>    <span class="s">&#39;email_on_retry&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
</span><span class='line'>    <span class="s">&#39;retries&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span><span class='line'>    <span class="s">&#39;retry_delay&#39;</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Initialize the DAG</span>
</span><span class='line'><span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
</span><span class='line'>    <span class="s">&#39;my_first_dag&#39;</span><span class="p">,</span>
</span><span class='line'>    <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
</span><span class='line'>    <span class="n">description</span><span class="o">=</span><span class="s">&#39;A simple DAG&#39;</span><span class="p">,</span>
</span><span class='line'>    <span class="n">schedule_interval</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
</span><span class='line'><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Define a PythonOperator that will run the Python function</span>
</span><span class='line'><span class="n">task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
</span><span class='line'>    <span class="n">task_id</span><span class="o">=</span><span class="s">&#39;print_hello&#39;</span><span class="p">,</span>
</span><span class='line'>    <span class="n">python_callable</span><span class="o">=</span><span class="n">my_task</span><span class="p">,</span>
</span><span class='line'>    <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">,</span>
</span><span class='line'><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Breakdown-of-the-Code"></a>
<h3>Breakdown of the Code</h3>

<ul>
<li><strong>DAG Definition</strong>: We start by defining the DAG, including its <code>start_date</code>, schedule, and default arguments.</li>
<li><strong>PythonOperator</strong>: The <code>PythonOperator</code> is used to run the Python function <code>my_task</code> as a task in the DAG.</li>
<li><strong>Scheduling</strong>: In this case, the DAG is scheduled to run once per day.</li>
</ul>


<a name="Running-the-DAG"></a>
<h3>Running the DAG</h3>

<ol>
<li>Place the DAG file in your Airflow DAGs folder (typically located at <code>/airflow/dags</code>).</li>
<li>Start the Airflow scheduler using the command:
<code>bash
airflow scheduler
</code></li>
<li>Access the Airflow UI by starting the web server:
<code>bash
airflow webserver
</code>
Navigate to <code>localhost:8080</code> to monitor and trigger your DAG.</li>
</ol>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Apache Airflow is a flexible and scalable platform for orchestrating workflows. Its modular architecture—comprising the scheduler, workers, web server, and metadata database—makes it ideal for managing complex data pipelines in distributed environments. The ability to define DAGs using Python, combined with its rich set of operators and scheduling capabilities, provides a powerful way to automate data workflows.</p>

<p>The provided code example shows how simple it is to define and run a task using PythonOperator. As you scale up, Airflow supports a range of executors and message brokers to handle more complex, distributed workloads efficiently.</p>

<p>By understanding Airflow&rsquo;s architecture and seeing a basic example in action, you&rsquo;re well on your way to using Airflow to manage and automate workflows in your projects.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Ktor: A Lightweight Framework for Building Asynchronous Web Applications]]></title>
        <link href="https://rishijeet.github.io/blog/ktor-a-lightweight-framework-for-building-asynchronous-web-applications/"/>
        <updated>2024-08-24T13:13:46+05:30</updated>
        <id>https://rishijeet.github.io/blog/ktor-a-lightweight-framework-for-building-asynchronous-web-applications</id>
        <content type="html"><![CDATA[<p>Ktor is a Kotlin-based framework developed by JetBrains for building asynchronous web applications and microservices. Unlike many traditional frameworks, Ktor is designed to be lightweight and flexible, allowing developers to create highly customized applications without unnecessary overhead. Whether you&rsquo;re building a simple web server, a RESTful API, or a fully-fledged microservice, Ktor provides the tools you need while embracing Kotlin&rsquo;s expressive syntax.</p>

<p>In this blog, we’ll dive into what makes Ktor unique, explore its features, and walk through a basic example to illustrate its capabilities.
<img src="https://rishijeet.github.io/images/2024/ktor.webp" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="What-Makes-Ktor-Unique-3f-"></a>
<h2>What Makes Ktor Unique?</h2>

<a name="L-3c-strong-3e-Kotlin-First-3c--2f-strong-3e-"></a>
<h3><strong>Kotlin First</strong></h3>

<p>Ktor is built specifically for Kotlin, taking full advantage of Kotlin’s language features, such as coroutines, to provide a smooth and idiomatic experience. This tight integration with Kotlin allows for concise and expressive code.</p>

<a name="L-3c-strong-3e-Asynchronous-by-Design-3c--2f-strong-3e-"></a>
<h3><strong>Asynchronous by Design</strong></h3>

<p>Ktor is asynchronous at its core, leveraging Kotlin’s coroutines to handle multiple requests efficiently without blocking threads. This makes Ktor particularly suitable for high-performance applications that need to handle many simultaneous connections.</p>

<a name="L-3c-strong-3e-Modular-Architecture-3c--2f-strong-3e-"></a>
<h3><strong>Modular Architecture</strong></h3>

<p>Ktor is highly modular, allowing developers to include only the components they need. Whether you require authentication, session management, or templating, you can easily add or remove features as necessary, keeping your application lightweight.</p>

<!--more-->


<a name="L-3c-strong-3e-Flexibility-3c--2f-strong-3e-"></a>
<h3><strong>Flexibility</strong></h3>

<p>Ktor provides a high degree of flexibility in defining routes, handling requests, and responding to clients. This flexibility allows developers to build applications that fit their specific needs without being constrained by the framework.</p>

<a name="L-3c-strong-3e-Minimal-Configuration-3c--2f-strong-3e-"></a>
<h3><strong>Minimal Configuration</strong></h3>

<p>Ktor is designed to be simple to set up with minimal configuration. You can get a basic web server running with just a few lines of code, making it ideal for rapid development and prototyping.</p>

<a name="Setting-Up-a-Ktor-Project"></a>
<h2>Setting Up a Ktor Project</h2>

<p>Let’s walk through creating a simple Ktor application. We’ll start by setting up the project and then build a basic web server with some routing.</p>

<a name="Project-Setup"></a>
<h3>Project Setup</h3>

<p>To start, create a new Gradle project and add the following dependencies to your <code>build.gradle.kts</code> file:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='kotlin'><span class='line'><span class="n">plugins</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">kotlin</span><span class="p">(</span><span class="s">&quot;jvm&quot;</span><span class="p">)</span> <span class="n">version</span> <span class="s">&quot;1.8.0&quot;</span>
</span><span class='line'>    <span class="n">application</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">application</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">mainClass</span><span class="p">.</span><span class="k">set</span><span class="p">(</span><span class="s">&quot;com.example.ApplicationKt&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">repositories</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">mavenCentral</span><span class="p">()</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">dependencies</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">implementation</span><span class="p">(</span><span class="s">&quot;io.ktor:ktor-server-core:2.2.1&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">implementation</span><span class="p">(</span><span class="s">&quot;io.ktor:ktor-server-netty:2.2.1&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">implementation</span><span class="p">(</span><span class="s">&quot;io.ktor:ktor-server-html-builder:2.2.1&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">implementation</span><span class="p">(</span><span class="s">&quot;ch.qos.logback:logback-classic:1.4.3&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">testImplementation</span><span class="p">(</span><span class="s">&quot;io.ktor:ktor-server-tests:2.2.1&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">testImplementation</span><span class="p">(</span><span class="s">&quot;org.jetbrains.kotlin:kotlin-test-junit:1.8.0&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Example:-Creating-a-Simple-Ktor-Web-Server"></a>
<h3>Example: Creating a Simple Ktor Web Server</h3>

<p>Now that the project is set up, let’s create a simple web server that responds to basic HTTP requests.</p>

<a name="Basic-Server-Setup"></a>
<h4>Basic Server Setup</h4>

<p>Create a new Kotlin file, <code>Application.kt</code>, and add the following code:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='kotlin'><span class='line'><span class="k">package</span> <span class="nn">com.example</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.application.*</span>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.http.*</span>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.response.*</span>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.request.*</span>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.routing.*</span>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.server.engine.embeddedServer</span>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.server.netty.Netty</span>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.features.ContentNegotiation</span>
</span><span class='line'><span class="k">import</span> <span class="nn">io.ktor.serialization.gson</span>
</span><span class='line'>
</span><span class='line'><span class="k">fun</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">embeddedServer</span><span class="p">(</span><span class="n">Netty</span><span class="p">,</span> <span class="n">port</span> <span class="p">=</span> <span class="m">8080</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">module</span><span class="p">()</span>
</span><span class='line'>    <span class="p">}.</span><span class="n">start</span><span class="p">(</span><span class="n">wait</span> <span class="p">=</span> <span class="k">true</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">fun</span> <span class="nf">Application</span><span class="p">.</span><span class="n">module</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">install</span><span class="p">(</span><span class="n">ContentNegotiation</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">gson</span> <span class="p">{</span>
</span><span class='line'>            <span class="n">setPrettyPrinting</span><span class="p">()</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="n">routing</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">get</span><span class="p">(</span><span class="s">&quot;/&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>            <span class="n">call</span><span class="p">.</span><span class="n">respondText</span><span class="p">(</span><span class="s">&quot;Hello, Rishijeet!&quot;</span><span class="p">,</span> <span class="n">ContentType</span><span class="p">.</span><span class="n">Text</span><span class="p">.</span><span class="n">Plain</span><span class="p">)</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>        <span class="k">get</span><span class="p">(</span><span class="s">&quot;/json&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>            <span class="k">val</span> <span class="py">data</span> <span class="p">=</span> <span class="n">mapOf</span><span class="p">(</span><span class="s">&quot;message&quot;</span> <span class="n">to</span> <span class="s">&quot;Hello, JSON!&quot;</span><span class="p">)</span>
</span><span class='line'>            <span class="n">call</span><span class="p">.</span><span class="n">respond</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>        <span class="n">post</span><span class="p">(</span><span class="s">&quot;/submit&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>            <span class="k">val</span> <span class="py">post</span> <span class="p">=</span> <span class="n">call</span><span class="p">.</span><span class="n">receive</span><span class="p">&lt;</span><span class="n">Map</span><span class="p">&lt;</span><span class="n">String</span><span class="p">,</span> <span class="n">String</span><span class="p">&gt;&gt;()</span>
</span><span class='line'>            <span class="n">call</span><span class="p">.</span><span class="n">respond</span><span class="p">(</span><span class="n">mapOf</span><span class="p">(</span><span class="s">&quot;status&quot;</span> <span class="n">to</span> <span class="s">&quot;Received&quot;</span><span class="p">,</span> <span class="s">&quot;data&quot;</span> <span class="n">to</span> <span class="n">post</span><span class="p">))</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Code-Breakdown"></a>
<h3>Code Breakdown</h3>

<ul>
<li><p><strong>embeddedServer(Netty, port = 8080)</strong>: This line starts an embedded Netty server on port 8080. Ktor supports multiple engines like Netty, Jetty, and Tomcat, but Netty is commonly used for its performance and ease of use.</p></li>
<li><p><strong>ContentNegotiation</strong>: This feature is installed to automatically handle JSON serialization and deserialization using Gson, making it easy to work with JSON payloads.</p></li>
<li><p><strong>Routing</strong>: The <code>routing</code> block defines the various routes that the server will respond to:</p>

<ul>
<li><strong>GET <code>/</code></strong>: Responds with a simple &ldquo;Hello, Rishijeet!&rdquo; message in plain text.</li>
<li><strong>GET <code>/json</code></strong>: Responds with a JSON object containing a message.</li>
<li><strong>POST <code>/submit</code></strong>: Receives a JSON payload and responds with the same data, confirming that the server received it.</li>
</ul>
</li>
</ul>


<a name="Running-the-Server"></a>
<h3>Running the Server</h3>

<p>Run the server by executing the main function in <code>Application.kt</code>. Once the server is running, you can test the endpoints using a browser or tools like <code>curl</code> or Postman.</p>

<a name="Example-Requests"></a>
<h4>Example Requests</h4>

<ul>
<li><strong>GET Request to <code>/</code></strong>:</li>
</ul>


<pre><code class="``bash">  curl http://localhost:8080/
</code></pre>

<p>  <strong>Response</strong>: <code>Hello, Rishijeet!</code></p>

<ul>
<li><strong>GET Request to <code>/json</code></strong>:</li>
</ul>


<pre><code class="``bash">  curl http://localhost:8080/json
</code></pre>

<p>  <strong>Response</strong>:</p>

<pre><code class="``json">  {
    "message": "Hello, JSON!"
  }
</code></pre>

<ul>
<li><strong>POST Request to <code>/submit</code></strong>:</li>
</ul>


<pre><code class="``bash">  curl -X POST -H "Content-Type: application/json" -d '{"name": "Ktor", "type": "framework"}' http://localhost:8080/submit
</code></pre>

<p>  <strong>Response</strong>:</p>

<pre><code class="``json">  {
    "status": "Received",
    "data": {
      "name": "Ktor",
      "type": "framework"
    }
  }
</code></pre>

<a name="Advanced-Features-in-Ktor"></a>
<h3>Advanced Features in Ktor</h3>

<p>Ktor also provides more advanced features that make it suitable for production-ready applications:</p>

<a name="L-3c-strong-3e-Authentication-3c--2f-strong-3e-"></a>
<h4><strong>Authentication</strong></h4>

<p>Ktor supports various authentication mechanisms, including session-based, JWT, OAuth, and more. You can easily add authentication to your routes to secure your application.</p>

<a name="L-3c-strong-3e-WebSockets-3c--2f-strong-3e-"></a>
<h4><strong>WebSockets</strong></h4>

<p>Ktor has built-in support for WebSockets, enabling real-time communication between the server and clients.</p>

<a name="L-3c-strong-3e-Content-Negotiation-and-Serialization-3c--2f-strong-3e-"></a>
<h4><strong>Content Negotiation and Serialization</strong></h4>

<p>Ktor’s flexible content negotiation allows you to work with multiple formats (JSON, XML, etc.) and serialization libraries (Gson, Kotlinx.serialization).</p>

<a name="L-3c-strong-3e-HTTP-Client-3c--2f-strong-3e-"></a>
<h4><strong>HTTP Client</strong></h4>

<p>Ktor also includes an HTTP client, making it easy to send HTTP requests from within your application. This is particularly useful when integrating with other services or APIs.</p>

<a name="Example:-Securing-Routes-with-Authentication"></a>
<h3>Example: Securing Routes with Authentication</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='kotlin'><span class='line'><span class="n">install</span><span class="p">(</span><span class="n">Authentication</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">basic</span><span class="p">(</span><span class="n">name</span> <span class="p">=</span> <span class="s">&quot;auth&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">realm</span> <span class="p">=</span> <span class="s">&quot;Ktor Server&quot;</span>
</span><span class='line'>        <span class="n">validate</span> <span class="p">{</span> <span class="n">credentials</span> <span class="p">-&gt;</span>
</span><span class='line'>            <span class="k">if</span> <span class="p">(</span><span class="n">credentials</span><span class="p">.</span><span class="n">name</span> <span class="p">==</span> <span class="s">&quot;user&quot;</span> <span class="p">&amp;&amp;</span> <span class="n">credentials</span><span class="p">.</span><span class="n">password</span> <span class="p">==</span> <span class="s">&quot;password&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>                <span class="n">UserIdPrincipal</span><span class="p">(</span><span class="n">credentials</span><span class="p">.</span><span class="n">name</span><span class="p">)</span>
</span><span class='line'>            <span class="p">}</span> <span class="k">else</span> <span class="k">null</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">routing</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">authenticate</span><span class="p">(</span><span class="s">&quot;auth&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">get</span><span class="p">(</span><span class="s">&quot;/secure&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>            <span class="n">call</span><span class="p">.</span><span class="n">respondText</span><span class="p">(</span><span class="s">&quot;You are authenticated!&quot;</span><span class="p">,</span> <span class="n">ContentType</span><span class="p">.</span><span class="n">Text</span><span class="p">.</span><span class="n">Plain</span><span class="p">)</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Example:-WebSocket-Communication"></a>
<h3>Example: WebSocket Communication</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='kotlin'><span class='line'><span class="n">routing</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">webSocket</span><span class="p">(</span><span class="s">&quot;/chat&quot;</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">for</span> <span class="p">(</span><span class="n">frame</span> <span class="k">in</span> <span class="n">incoming</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>            <span class="k">when</span> <span class="p">(</span><span class="n">frame</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>                <span class="k">is</span> <span class="n">Frame</span><span class="p">.</span><span class="n">Text</span> <span class="p">-&gt;</span> <span class="n">send</span><span class="p">(</span><span class="n">Frame</span><span class="p">.</span><span class="n">Text</span><span class="p">(</span><span class="s">&quot;Server received: ${frame.readText()}&quot;</span><span class="p">))</span>
</span><span class='line'>            <span class="p">}</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Conclusion"></a>
<h2>Conclusion</h2>

<p>Ktor is a powerful and flexible framework for building asynchronous web applications in Kotlin. Its Kotlin-first approach, coupled with features like modularity, asynchronous processing, and minimal configuration, makes it an excellent choice for developers looking to build lightweight and high-performance web applications.</p>

<p>Whether you’re building a simple API, a microservice, or a real-time application with WebSockets, Ktor provides the tools you need while allowing for a high degree of customization. As the Kotlin ecosystem continues to grow, Ktor is likely to become even more popular among developers seeking a modern, efficient web framework.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Vert.x: The Reactive Toolkit for Modern Applications]]></title>
        <link href="https://rishijeet.github.io/blog/vert-dot-x-the-reactive-toolkit-for-modern-applications/"/>
        <updated>2024-08-03T23:22:56+05:30</updated>
        <id>https://rishijeet.github.io/blog/vert-dot-x-the-reactive-toolkit-for-modern-applications</id>
        <content type="html"><![CDATA[<p>In the realm of modern web applications, responsiveness and scalability are paramount. Vert.x, a toolkit for building reactive applications on the JVM, stands out due to its performance and flexibility. Vert.x is polyglot, allowing developers to use multiple languages such as Java, JavaScript, Groovy, Ruby, Kotlin, and Scala. Its non-blocking nature and event-driven architecture make it an excellent choice for developing high-throughput, low-latency applications.</p>

<p>In this blog, we&rsquo;ll explore the unique aspects of Vert.x, how it leverages the reactive programming model, and provide examples to illustrate its capabilities.
<img src="https://rishijeet.github.io/images/2024/vertx.png" height="300" width="900" alt="Alt text" /><em>Source: Internet</em></p>

<a name="What-Makes-Vert.x-Unique-3f-"></a>
<h2>What Makes Vert.x Unique?</h2>

<a name="L-3c-strong-3e-Polyglot-Support-3c--2f-strong-3e-"></a>
<h3><strong>Polyglot Support</strong></h3>

<p>Vert.x allows developers to write applications in multiple languages, providing flexibility and enabling teams to use the best language for their needs.</p>

<a name="L-3c-strong-3e-Event-2d-Driven-and-Non-2d-Blocking-3c--2f-strong-3e-"></a>
<h3><strong>Event-Driven and Non-Blocking</strong></h3>

<p>Vert.x uses a non-blocking, event-driven model, allowing it to handle many concurrent connections with minimal threads. This leads to better resource utilization and scalability.</p>

<a name="L-3c-strong-3e-Reactive-Programming-3c--2f-strong-3e-"></a>
<h3><strong>Reactive Programming</strong></h3>

<p>Vert.x embraces reactive programming principles, making it easier to build responsive, resilient, and elastic applications. It integrates seamlessly with reactive libraries like RxJava and Reactor.</p>

<a name="L-3c-strong-3e-Verticles-and-Event-Bus-3c--2f-strong-3e-"></a>
<h3><strong>Verticles and Event Bus</strong></h3>

<p>Vert.x applications are composed of Verticles, which are units of deployment and concurrency. The Event Bus facilitates communication between Verticles, enabling a highly decoupled architecture.</p>

<!--more-->


<a name="L-3c-strong-3e-Module-System-3c--2f-strong-3e-"></a>
<h3><strong>Module System</strong></h3>

<p>Vert.x offers a powerful module system, allowing for easy reuse and deployment of components.</p>

<a name="Getting-Started-with-Vert.x"></a>
<h2>Getting Started with Vert.x</h2>

<p>Let&rsquo;s walk through setting up a simple Vert.x application and explore its features.</p>

<a name="Example:-Setting-Up-a-Vert.x-Project"></a>
<h3>Example: Setting Up a Vert.x Project</h3>

<a name="Project-Structure"></a>
<h4>Project Structure</h4>

<p>We&rsquo;ll create a basic Vert.x application in Java. Ensure you have Maven or Gradle installed.</p>

<a name="Maven-Project-Setup"></a>
<h4>Maven Project Setup</h4>

<p><strong>pom.xml:</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;project</span> <span class="na">xmlns=</span><span class="s">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="na">xmlns:xsi=</span><span class="s">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span>
</span><span class='line'>    <span class="na">xsi:schemaLocation=</span><span class="s">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;modelVersion&gt;</span>4.0.0<span class="nt">&lt;/modelVersion&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;groupId&gt;</span>com.example<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;artifactId&gt;</span>vertx-demo<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>    <span class="nt">&lt;version&gt;</span>1.0-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;properties&gt;</span>
</span><span class='line'>        <span class="nt">&lt;maven.compiler.source&gt;</span>11<span class="nt">&lt;/maven.compiler.source&gt;</span>
</span><span class='line'>        <span class="nt">&lt;maven.compiler.target&gt;</span>11<span class="nt">&lt;/maven.compiler.target&gt;</span>
</span><span class='line'>        <span class="nt">&lt;vertx.version&gt;</span>4.3.4<span class="nt">&lt;/vertx.version&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/properties&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;dependencies&gt;</span>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>io.vertx<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>vertx-core<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${vertx.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>        <span class="nt">&lt;dependency&gt;</span>
</span><span class='line'>            <span class="nt">&lt;groupId&gt;</span>io.vertx<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;artifactId&gt;</span>vertx-web<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>            <span class="nt">&lt;version&gt;</span>${vertx.version}<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/dependency&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/dependencies&gt;</span>
</span><span class='line'>
</span><span class='line'>    <span class="nt">&lt;build&gt;</span>
</span><span class='line'>        <span class="nt">&lt;plugins&gt;</span>
</span><span class='line'>            <span class="nt">&lt;plugin&gt;</span>
</span><span class='line'>                <span class="nt">&lt;groupId&gt;</span>org.apache.maven.plugins<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>                <span class="nt">&lt;artifactId&gt;</span>maven-compiler-plugin<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>                <span class="nt">&lt;version&gt;</span>3.8.1<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;/plugin&gt;</span>
</span><span class='line'>            <span class="nt">&lt;plugin&gt;</span>
</span><span class='line'>                <span class="nt">&lt;groupId&gt;</span>io.fabric8<span class="nt">&lt;/groupId&gt;</span>
</span><span class='line'>                <span class="nt">&lt;artifactId&gt;</span>docker-maven-plugin<span class="nt">&lt;/artifactId&gt;</span>
</span><span class='line'>                <span class="nt">&lt;version&gt;</span>0.34.1<span class="nt">&lt;/version&gt;</span>
</span><span class='line'>            <span class="nt">&lt;/plugin&gt;</span>
</span><span class='line'>        <span class="nt">&lt;/plugins&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/build&gt;</span>
</span><span class='line'><span class="nt">&lt;/project&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Example:-Creating-a-Simple-HTTP-Server"></a>
<h3>Example: Creating a Simple HTTP Server</h3>

<a name="Main-Verticle"></a>
<h4>Main Verticle</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">example</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.AbstractVerticle</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.Vertx</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.ext.web.Router</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.ext.web.RoutingContext</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MainVerticle</span> <span class="kd">extends</span> <span class="n">AbstractVerticle</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">Router</span> <span class="n">router</span> <span class="o">=</span> <span class="n">Router</span><span class="o">.</span><span class="na">router</span><span class="o">(</span><span class="n">vertx</span><span class="o">);</span>
</span><span class='line'>        <span class="n">router</span><span class="o">.</span><span class="na">route</span><span class="o">(</span><span class="s">&quot;/&quot;</span><span class="o">).</span><span class="na">handler</span><span class="o">(</span><span class="k">this</span><span class="o">::</span><span class="n">handleRoot</span><span class="o">);</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">createHttpServer</span><span class="o">()</span>
</span><span class='line'>             <span class="o">.</span><span class="na">requestHandler</span><span class="o">(</span><span class="n">router</span><span class="o">)</span>
</span><span class='line'>             <span class="o">.</span><span class="na">listen</span><span class="o">(</span><span class="mi">8888</span><span class="o">,</span> <span class="n">result</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>                 <span class="k">if</span> <span class="o">(</span><span class="n">result</span><span class="o">.</span><span class="na">succeeded</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>                     <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Server started on port 8888&quot;</span><span class="o">);</span>
</span><span class='line'>                 <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
</span><span class='line'>                     <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Failed to start server: &quot;</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="na">cause</span><span class="o">());</span>
</span><span class='line'>                 <span class="o">}</span>
</span><span class='line'>             <span class="o">});</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">handleRoot</span><span class="o">(</span><span class="n">RoutingContext</span> <span class="n">context</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">context</span><span class="o">.</span><span class="na">response</span><span class="o">()</span>
</span><span class='line'>               <span class="o">.</span><span class="na">putHeader</span><span class="o">(</span><span class="s">&quot;content-type&quot;</span><span class="o">,</span> <span class="s">&quot;text/plain&quot;</span><span class="o">)</span>
</span><span class='line'>               <span class="o">.</span><span class="na">end</span><span class="o">(</span><span class="s">&quot;Hello, Rishijeet!&quot;</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">Vertx</span> <span class="n">vertx</span> <span class="o">=</span> <span class="n">Vertx</span><span class="o">.</span><span class="na">vertx</span><span class="o">();</span>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">MainVerticle</span><span class="o">());</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This simple Vert.x application sets up an HTTP server that listens on port 8888 and responds with &ldquo;Hello, Rishijeet!&rdquo;
when the root URL is accessed.</p>

<a name="Example:-Deploying-Verticles"></a>
<h3>Example: Deploying Verticles</h3>

<p>Vert.x applications are composed of Verticles. You can deploy multiple Verticles, enabling a modular and scalable architecture.</p>

<a name="Worker-Verticle"></a>
<h4>Worker Verticle</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">example</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.AbstractVerticle</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.Promise</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WorkerVerticle</span> <span class="kd">extends</span> <span class="n">AbstractVerticle</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">(</span><span class="n">Promise</span><span class="o">&lt;</span><span class="n">Void</span><span class="o">&gt;</span> <span class="n">startPromise</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">setPeriodic</span><span class="o">(</span><span class="mi">1000</span><span class="o">,</span> <span class="n">id</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Worker Verticle: &quot;</span> <span class="o">+</span> <span class="n">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getName</span><span class="o">());</span>
</span><span class='line'>        <span class="o">});</span>
</span><span class='line'>        <span class="n">startPromise</span><span class="o">.</span><span class="na">complete</span><span class="o">();</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Deploying-Verticles"></a>
<h4>Deploying Verticles</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">example</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.Vertx</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MainApp</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">Vertx</span> <span class="n">vertx</span> <span class="o">=</span> <span class="n">Vertx</span><span class="o">.</span><span class="na">vertx</span><span class="o">();</span>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">MainVerticle</span><span class="o">());</span>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">WorkerVerticle</span><span class="o">());</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Example:-Using-the-Event-Bus"></a>
<h3>Example: Using the Event Bus</h3>

<p>The Event Bus allows Verticles to communicate asynchronously.</p>

<a name="Sender-Verticle"></a>
<h4>Sender Verticle</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">example</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.AbstractVerticle</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.Vertx</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SenderVerticle</span> <span class="kd">extends</span> <span class="n">AbstractVerticle</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">eventBus</span><span class="o">().</span><span class="na">send</span><span class="o">(</span><span class="s">&quot;example.address&quot;</span><span class="o">,</span> <span class="s">&quot;Hello from SenderVerticle!&quot;</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">Vertx</span> <span class="n">vertx</span> <span class="o">=</span> <span class="n">Vertx</span><span class="o">.</span><span class="na">vertx</span><span class="o">();</span>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">SenderVerticle</span><span class="o">());</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Receiver-Verticle"></a>
<h4>Receiver Verticle</h4>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">example</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.AbstractVerticle</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">io.vertx.core.Vertx</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">ReceiverVerticle</span> <span class="kd">extends</span> <span class="n">AbstractVerticle</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">start</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">eventBus</span><span class="o">().</span><span class="na">consumer</span><span class="o">(</span><span class="s">&quot;example.address&quot;</span><span class="o">,</span> <span class="n">message</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Received message: &quot;</span> <span class="o">+</span> <span class="n">message</span><span class="o">.</span><span class="na">body</span><span class="o">());</span>
</span><span class='line'>        <span class="o">});</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">Vertx</span> <span class="n">vertx</span> <span class="o">=</span> <span class="n">Vertx</span><span class="o">.</span><span class="na">vertx</span><span class="o">();</span>
</span><span class='line'>        <span class="n">vertx</span><span class="o">.</span><span class="na">deployVerticle</span><span class="o">(</span><span class="k">new</span> <span class="nf">ReceiverVerticle</span><span class="o">());</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>Vert.x offers a powerful and flexible toolkit for building modern, reactive applications. Its unique features, including polyglot support, non-blocking event-driven architecture, and the Event Bus, make it an excellent choice for high-throughput, low-latency applications. By leveraging Verticles and the reactive programming model, developers can build scalable, maintainable, and efficient applications.</p>

<p>Understanding the power of Vert.x and how to use its features effectively can significantly improve the responsiveness and scalability of your applications. Whether you&rsquo;re building microservices, real-time web applications, or IoT solutions, Vert.x provides the tools you need to succeed.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Exploring Coroutines: Concurrency Made Easy]]></title>
        <link href="https://rishijeet.github.io/blog/exploring-coroutines-concurrency-made-easy/"/>
        <updated>2024-08-03T18:29:50+05:30</updated>
        <id>https://rishijeet.github.io/blog/exploring-coroutines-concurrency-made-easy</id>
        <content type="html"><![CDATA[<p>Concurrency is a critical aspect of modern software development, enabling applications to perform multiple tasks simultaneously. Traditional approaches to concurrency, such as threads, often come with complexity and overhead. Coroutines offer a powerful alternative by providing a simpler, more efficient way to handle concurrent operations. In this blog, we&rsquo;ll delve into the world of coroutines, explore what makes them unique, and provide examples to illustrate their usage. We&rsquo;ll also discuss alternative concurrency models and their trade-offs.</p>

<a name="What-Are-Coroutines-3f-"></a>
<h2>What Are Coroutines?</h2>

<p>Coroutines are a concurrency primitive that allows functions to pause execution and resume later, enabling non-blocking asynchronous code execution. Unlike traditional threads, coroutines are lightweight, have minimal overhead, and do not require OS-level context switching.</p>

<a name="Key-Features-of-Coroutines"></a>
<h3>Key Features of Coroutines</h3>

<ol>
<li><strong>Lightweight</strong>: Coroutines are more lightweight than threads, allowing you to run thousands of coroutines simultaneously without significant performance impact.</li>
<li><strong>Non-Blocking</strong>: Coroutines enable non-blocking asynchronous code execution, which is crucial for I/O-bound and network-bound tasks.</li>
<li><strong>Structured Concurrency</strong>: Coroutines support structured concurrency, making it easier to manage the lifecycle of concurrent tasks.</li>
<li><strong>Suspend Functions</strong>: Functions can be suspended and resumed at a later time, allowing for more readable and maintainable asynchronous code.</li>
</ol>


<a name="Coroutines-in-Kotlin"></a>
<h2>Coroutines in Kotlin</h2>

<p>Kotlin is one of the languages that has built-in support for coroutines, making it a popular choice for modern asynchronous programming. Let&rsquo;s explore coroutines in Kotlin with some examples.</p>

<!--more-->


<a name="Example:-Basic-Coroutine"></a>
<h3>Example: Basic Coroutine</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='kotlin'><span class='line'><span class="k">import</span> <span class="nn">kotlinx.coroutines.*</span>
</span><span class='line'>
</span><span class='line'><span class="k">fun</span> <span class="nf">main</span><span class="p">()</span> <span class="p">=</span> <span class="n">runBlocking</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">launch</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">delay</span><span class="p">(</span><span class="m">1000L</span><span class="p">)</span>
</span><span class='line'>        <span class="n">println</span><span class="p">(</span><span class="s">&quot;Rishijeet!&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Hello,&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In this example, <code>runBlocking</code> starts a coroutine and blocks the main thread until the coroutine completes. The
<code>launch</code> function starts a new coroutine that delays for 1 second and then prints &ldquo;Rishijeet!&rdquo;. Meanwhile, &ldquo;Hello,&rdquo; is
printed immediately.</p>

<a name="Example:-Structured-Concurrency"></a>
<h3>Example: Structured Concurrency</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='kotlin'><span class='line'><span class="k">import</span> <span class="nn">kotlinx.coroutines.*</span>
</span><span class='line'>
</span><span class='line'><span class="k">fun</span> <span class="nf">main</span><span class="p">()</span> <span class="p">=</span> <span class="n">runBlocking</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="py">job</span> <span class="p">=</span> <span class="n">launch</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">doWork</span><span class="p">()</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Waiting for work to complete...&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">job</span><span class="p">.</span><span class="n">join</span><span class="p">()</span>
</span><span class='line'>    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Work completed!&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">suspend</span> <span class="k">fun</span> <span class="nf">doWork</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">delay</span><span class="p">(</span><span class="m">2000L</span><span class="p">)</span>
</span><span class='line'>    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Work in progress...&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This example demonstrates structured concurrency. The <code>doWork</code> function is a suspend function that simulates work with a 2-second delay. The <code>launch</code> function starts a coroutine that runs <code>doWork</code>, and <code>job.join()</code> waits for the coroutine to complete.</p>

<a name="Example:-Async-and-Await"></a>
<h3>Example: Async and Await</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='kotlin'><span class='line'><span class="k">import</span> <span class="nn">kotlinx.coroutines.*</span>
</span><span class='line'>
</span><span class='line'><span class="k">fun</span> <span class="nf">main</span><span class="p">()</span> <span class="p">=</span> <span class="n">runBlocking</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="py">deferred</span> <span class="p">=</span> <span class="n">async</span> <span class="p">{</span>
</span><span class='line'>        <span class="n">computeValue</span><span class="p">()</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Waiting for result...&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="k">val</span> <span class="py">result</span> <span class="p">=</span> <span class="n">deferred</span><span class="p">.</span><span class="n">await</span><span class="p">()</span>
</span><span class='line'>    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Result: $result&quot;</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="n">suspend</span> <span class="k">fun</span> <span class="nf">computeValue</span><span class="p">():</span> <span class="n">Int</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">delay</span><span class="p">(</span><span class="m">1000L</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="m">42</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In this example, the <code>async</code> function starts a coroutine that computes a value asynchronously. The <code>await</code> function suspends the coroutine until the result is available.</p>

<a name="Alternatives-to-Coroutines"></a>
<h2>Alternatives to Coroutines</h2>

<p>While coroutines offer many advantages, there are other concurrency models to consider. Each has its own trade-offs and use cases.</p>

<a name="L-3c-strong-3e-Threads-3c--2f-strong-3e-"></a>
<h3><strong>Threads</strong></h3>

<p>Threads are the traditional approach to concurrency. They are managed by the OS and provide true parallelism but come with significant overhead and complexity.</p>

<p><strong>Example: Threads in Java</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">ThreadExample</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">Thread</span> <span class="n">thread</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Thread</span><span class="o">(()</span> <span class="o">-&gt;</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">try</span> <span class="o">{</span>
</span><span class='line'>                <span class="n">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">1000</span><span class="o">);</span>
</span><span class='line'>                <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Rishijeet!&quot;</span><span class="o">);</span>
</span><span class='line'>            <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">InterruptedException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>                <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
</span><span class='line'>            <span class="o">}</span>
</span><span class='line'>        <span class="o">});</span>
</span><span class='line'>        <span class="n">thread</span><span class="o">.</span><span class="na">start</span><span class="o">();</span>
</span><span class='line'>        <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Hello,&quot;</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="L-3c-strong-3e-Reactive-Programming-3c--2f-strong-3e-"></a>
<h3><strong>Reactive Programming</strong></h3>

<p>Reactive programming, using libraries like RxJava or Reactor, is another approach to concurrency. It is based on the Observer pattern and provides powerful abstractions for asynchronous programming.</p>

<p><strong>Example: RxJava</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">import</span> <span class="nn">io.reactivex.Observable</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">RxJavaExample</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">Observable</span><span class="o">.</span><span class="na">just</span><span class="o">(</span><span class="s">&quot;Hello, Rishijeet!&quot;</span><span class="o">)</span>
</span><span class='line'>                  <span class="o">.</span><span class="na">delay</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="n">TimeUnit</span><span class="o">.</span><span class="na">SECONDS</span><span class="o">)</span>
</span><span class='line'>                  <span class="o">.</span><span class="na">subscribe</span><span class="o">(</span><span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">::</span><span class="n">println</span><span class="o">);</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<a name="L-3c-strong-3e-Async-2f-Await--28-Promises-29--3c--2f-strong-3e-"></a>
<h3><strong>Async/Await (Promises)</strong></h3>

<p>Async/await is a popular pattern in languages like JavaScript and Python. It simplifies asynchronous code by allowing it to be written in a synchronous style.</p>

<p><strong>Example: Async/Await in JavaScript</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">function</span> <span class="nx">delay</span><span class="p">(</span><span class="nx">ms</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="k">new</span> <span class="nx">Promise</span><span class="p">(</span><span class="nx">resolve</span> <span class="o">=&gt;</span> <span class="nx">setTimeout</span><span class="p">(</span><span class="nx">resolve</span><span class="p">,</span> <span class="nx">ms</span><span class="p">));</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="nx">async</span> <span class="kd">function</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s2">&quot;Hello,&quot;</span><span class="p">);</span>
</span><span class='line'>    <span class="nx">await</span> <span class="nx">delay</span><span class="p">(</span><span class="mi">1000</span><span class="p">);</span>
</span><span class='line'>    <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s2">&quot;Rishijeet!&quot;</span><span class="p">);</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="nx">main</span><span class="p">();</span>
</span></code></pre></td></tr></table></div></figure>


<a name="Conclusion"></a>
<h3>Conclusion</h3>

<p>Coroutines offer a powerful and efficient way to handle concurrency, providing simplicity and performance advantages over traditional threads. They are particularly well-suited for I/O-bound and network-bound tasks, enabling non-blocking asynchronous code execution. While there are alternative concurrency models like threads, reactive programming, and async/await, coroutines stand out for their lightweight nature and structured concurrency.</p>

<p>Kotlin&rsquo;s built-in support for coroutines makes it an excellent choice for modern asynchronous programming. By leveraging coroutines, developers can write more readable, maintainable, and efficient concurrent code.</p>

<p>Understanding the various concurrency models and their trade-offs allows developers to choose the best approach for their specific use cases. Whether using coroutines, threads, reactive programming, or async/await, the key is to find the right balance between simplicity, performance, and scalability.</p>
]]></content>
    </entry>
    
</feed>
